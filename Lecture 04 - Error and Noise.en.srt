1
00:00:00,000 --> 00:00:00,570


2
00:00:00,570 --> 00:00:03,270
ANNOUNCER: The following program
is brought to you by Caltech.

3
00:00:03,270 --> 00:00:16,400


4
00:00:16,400 --> 00:00:19,310
YASER ABU-MOSTAFA: Welcome back.

5
00:00:19,310 --> 00:00:24,120
Last time, we talked about
linear models.

6
00:00:24,120 --> 00:00:29,630
And linear models share what we
would refer to as the signal,

7
00:00:29,630 --> 00:00:31,530
which is this formula.

8
00:00:31,530 --> 00:00:37,020
It's a linear sum involving the input
variables and weights, that can be put

9
00:00:37,020 --> 00:00:38,660
in vector form.

10
00:00:38,660 --> 00:00:43,600
And all linear models, in one form or
another, have that as their basic

11
00:00:43,600 --> 00:00:44,990
building block.

12
00:00:44,990 --> 00:00:49,680
And you can have a classification linear
system, like the perceptron,

13
00:00:49,680 --> 00:00:54,220
that uses that signal and takes the
sign of it to make a decision,

14
00:00:54,220 --> 00:00:55,940
+1 or -1.

15
00:00:55,940 --> 00:00:59,300
Or you can take something like
regression, which is real-valued, that

16
00:00:59,300 --> 00:01:05,050
takes the signal as it is
and has that as output.

17
00:01:05,050 --> 00:01:08,720
We looked at the linear regression
algorithm, which was a particularly

18
00:01:08,720 --> 00:01:10,430
easy algorithm.

19
00:01:10,430 --> 00:01:15,450
All it does, it takes the inputs and
puts them in a particular matrix form,

20
00:01:15,450 --> 00:01:19,840
and so the outputs. That's the inputs
and outputs of the data set.

21
00:01:19,840 --> 00:01:24,420
And then, by computing this very simple
formula, in one shot, it can

22
00:01:24,420 --> 00:01:29,830
get you the optimal value
of the weight vector.

23
00:01:29,830 --> 00:01:36,550
If you look at linear models, you can
think of them as an economy car.

24
00:01:36,550 --> 00:01:42,490
They get you where you want to go, and
they don't consume a lot of gas.

25
00:01:42,490 --> 00:01:46,720
You may not be very proud of them,
but they actually do the job.

26
00:01:46,720 --> 00:01:49,860
If you want a luxury car, wait
until we get to support

27
00:01:49,860 --> 00:01:51,650
vector machines.

28
00:01:51,650 --> 00:01:54,530
And you have to pay the
price for that.

29
00:01:54,530 --> 00:01:58,450
However, for linear models, it
is remarkable how often they

30
00:01:58,450 --> 00:02:00,060
succeed on their own.

31
00:02:00,060 --> 00:02:03,150
And they are sufficient to get
you the learning performance

32
00:02:03,150 --> 00:02:04,740
that you want.

33
00:02:04,740 --> 00:02:10,910
So I urge you to give linear models
in general more attention than you

34
00:02:10,910 --> 00:02:12,150
would otherwise give.

35
00:02:12,150 --> 00:02:15,970
And try to use them when you face
a learning problem first, and see if they

36
00:02:15,970 --> 00:02:18,950
will actually achieve what you want.

37
00:02:18,950 --> 00:02:22,930
To strengthen linear models even
further, we introduced nonlinear

38
00:02:22,930 --> 00:02:24,700
transformation.

39
00:02:24,700 --> 00:02:29,970
And the idea behind it is that the
signal is not only linear in x, which

40
00:02:29,970 --> 00:02:33,370
is what you would think of as the reason
we call these linear systems.

41
00:02:33,370 --> 00:02:37,370
But actually, they're linear
in w, the vector.

42
00:02:37,370 --> 00:02:41,590
And the reason this is important is
because learning actually modifies w

43
00:02:41,590 --> 00:02:46,180
in the learning process until it gets to
the optimal one, while x, which you

44
00:02:46,180 --> 00:02:49,410
usually think of as a variable, is
actually a bunch of constants, which

45
00:02:49,410 --> 00:02:51,590
are the data set that
are handed to you.

46
00:02:51,590 --> 00:02:55,290
So the linearity in w
is the key point.

47
00:02:55,290 --> 00:02:59,840
And if you take x and transform it in
any way you form to another vector z,

48
00:02:59,840 --> 00:03:05,380
in a very nonlinear way if you want,
this will still preserve this

49
00:03:05,380 --> 00:03:07,500
linearity, the linearity in w.

50
00:03:07,500 --> 00:03:09,310
Obviously, it will not be linear in x.

51
00:03:09,310 --> 00:03:12,390
And that's all that matters for you to
apply the machinery that we got

52
00:03:12,390 --> 00:03:16,170
here, like the simple linear
regression algorithm.

53
00:03:16,170 --> 00:03:21,970
And we took an example where we had the
two variables x_1 and x_2, and we

54
00:03:21,970 --> 00:03:25,200
transformed them nonlinearly to
x_1 squared and x_2 squared.

55
00:03:25,200 --> 00:03:31,040
And we found that this case, the
transformation helps us separate the

56
00:03:31,040 --> 00:03:33,630
data, where if we worked in
the original space, we

57
00:03:33,630 --> 00:03:36,300
would not be able to.

58
00:03:36,300 --> 00:03:44,410
This time, I'm going to talk
about error and noise.

59
00:03:44,410 --> 00:03:49,930
And these are practical considerations
that we have to take, when we consider

60
00:03:49,930 --> 00:03:51,720
real-life problems.

61
00:03:51,720 --> 00:03:56,500
And we're going to modify the learning
diagram that we have, by incorporating

62
00:03:56,500 --> 00:03:59,960
the notion of error and
the notion of noise.

63
00:03:59,960 --> 00:04:03,690
And I will do that for the
bulk of the lecture.

64
00:04:03,690 --> 00:04:07,380
However, my starting point will be to
wrap up the nonlinear transformation

65
00:04:07,380 --> 00:04:10,240
that we started last time.

66
00:04:10,240 --> 00:04:13,700
So let's look at what
we had last time.

67
00:04:13,700 --> 00:04:15,120
We had this space.

68
00:04:15,120 --> 00:04:16,510
Let me magnify it a little bit.

69
00:04:16,510 --> 00:04:20,839


70
00:04:20,839 --> 00:04:24,650
This space is the original X space.

71
00:04:24,650 --> 00:04:26,930
And the origin is in the middle.

72
00:04:26,930 --> 00:04:30,850
And you have these points,
which are your data set.

73
00:04:30,850 --> 00:04:33,900
And each point belongs to that space.

74
00:04:33,900 --> 00:04:38,240
And as you realize, there is really no
way of separating the blue from the

75
00:04:38,240 --> 00:04:43,020
red using a line, which is
what linear models do.

76
00:04:43,020 --> 00:04:49,100
And the idea for us was: let's
do a nonlinear transformation.

77
00:04:49,100 --> 00:04:51,510
We called it phi.

78
00:04:51,510 --> 00:04:54,960
And if you look at what happened here--
let's look at both of them at

79
00:04:54,960 --> 00:04:56,380
the same time--

80
00:04:56,380 --> 00:04:58,580
this is where you took x_1 squared.

81
00:04:58,580 --> 00:05:01,550
So this is x_1, and this is x_2.

82
00:05:01,550 --> 00:05:03,700
And that transformation
here was x_1 squared.

83
00:05:03,700 --> 00:05:07,700
So this would be x_1 squared, and this
is x2 squared, which we're going

84
00:05:07,700 --> 00:05:10,420
to label as z.

85
00:05:10,420 --> 00:05:15,170
So the transformation is you take every
point in the sample space x_n,

86
00:05:15,170 --> 00:05:17,730
you put it through a transformation
phi, and you get the

87
00:05:17,730 --> 00:05:19,370
corresponding point z_n.

88
00:05:19,370 --> 00:05:22,525
And now, you are working in the feature
space, or the nonlinear space

89
00:05:22,525 --> 00:05:23,920
Z.

90
00:05:23,920 --> 00:05:28,300
When we did this, we realized that a data
set like this can become linearly

91
00:05:28,300 --> 00:05:30,930
separable in the new space.

92
00:05:30,930 --> 00:05:35,890
And that allows us to apply the
linear model algorithm here.

93
00:05:35,890 --> 00:05:44,620
And when you do that, you will get
a separating boundary here.

94
00:05:44,620 --> 00:05:49,030
And that separating boundary is applied
by applying your simple linear

95
00:05:49,030 --> 00:05:52,090
model, like linear regression-- in this
case, linear classification, the

96
00:05:52,090 --> 00:05:53,360
perceptron--

97
00:05:53,360 --> 00:05:58,840
to the data in the Z space.

98
00:05:58,840 --> 00:06:00,250
So that's what we get.

99
00:06:00,250 --> 00:06:02,160
But we are not working in the Z space.

100
00:06:02,160 --> 00:06:04,820
When I give you a test
point, it will be x.

101
00:06:04,820 --> 00:06:07,490
And you have managed to separate
things in the Z space.

102
00:06:07,490 --> 00:06:11,350
Well, the way you do it is you
go back to the input space.

103
00:06:11,350 --> 00:06:14,100
And as you realize, I'm
using the "inverse",

104
00:06:14,100 --> 00:06:15,140
between quotation,

105
00:06:15,140 --> 00:06:15,870
transformation.

106
00:06:15,870 --> 00:06:19,220
Because the transformation, in principle,
may not have an inverse.

107
00:06:19,220 --> 00:06:22,620
There are some points in the Z space
that may not be a mapping of any point

108
00:06:22,620 --> 00:06:25,960
in X, and some points in the Z space
which may be the mapping of

109
00:06:25,960 --> 00:06:27,310
more than one point.

110
00:06:27,310 --> 00:06:30,410
And therefore, in spite of the fact that
phi is a mapping, a function,

111
00:06:30,410 --> 00:06:33,410
phi -1, as we call it, is not.

112
00:06:33,410 --> 00:06:38,710
But when you apply this, figuratively,
what you're going to get is

113
00:06:38,710 --> 00:06:42,850
a separating surface in the X
space, that is not linear.

114
00:06:42,850 --> 00:06:46,510
And that was obtained by applying
purely linear methods.

115
00:06:46,510 --> 00:06:54,450
And therefore, you can classify a new
point by applying g of x, which would

116
00:06:54,450 --> 00:06:59,930
be the hypothesis that's defined here,
the linear one, which happens to have

117
00:06:59,930 --> 00:07:00,720
that formula.

118
00:07:00,720 --> 00:07:04,630
So you look at the diagram
all together.

119
00:07:04,630 --> 00:07:10,710
And this is basically the cycle you have,
when you're doing the nonlinear

120
00:07:10,710 --> 00:07:11,650
transformation.

121
00:07:11,650 --> 00:07:17,740
You take the data set, transform it,
classify it, and interpret it.

122
00:07:17,740 --> 00:07:21,270
In reality, when you get the new x, what
you're going to do, you are going

123
00:07:21,270 --> 00:07:23,550
to take the new x, wherever
it might be.

124
00:07:23,550 --> 00:07:25,020
You're going to transform it.

125
00:07:25,020 --> 00:07:28,750
And then look here where it lies,
and classify it accordingly.

126
00:07:28,750 --> 00:07:30,460
It's a very simple procedure.

127
00:07:30,460 --> 00:07:33,950
And as you can see, although we are
illustrating it here in a case where

128
00:07:33,950 --> 00:07:36,950
you're going from two-dimensional
to two-dimensional, you could in

129
00:07:36,950 --> 00:07:41,140
principle go from two-dimensional to 100
dimensional, with highly nonlinear

130
00:07:41,140 --> 00:07:43,470
coordinates, and the same
principle will apply.

131
00:07:43,470 --> 00:07:46,370
You will be classifying here, with
a hyperplane in that case.

132
00:07:46,370 --> 00:07:48,960
And then, this surface would
be very, very complicated--

133
00:07:48,960 --> 00:07:50,890
could be completely jagged
and whatnot.

134
00:07:50,890 --> 00:07:55,050
And that enables you to implement
a lot of sophisticated surfaces.

135
00:07:55,050 --> 00:08:01,370
So let's look at the nonlinear
transformation and ask ourselves, what

136
00:08:01,370 --> 00:08:05,610
transforms to what, to make sure
that all the notions are clear.

137
00:08:05,610 --> 00:08:08,830
The first thing is the input point x.

138
00:08:08,830 --> 00:08:12,765
This is a single point that is
represented by its coordinates x_1 up

139
00:08:12,765 --> 00:08:17,470
to x_d, together with the mandatory
constant x_0 which equals 1 that

140
00:08:17,470 --> 00:08:19,000
takes care of the threshold term.

141
00:08:19,000 --> 00:08:23,660
This is a general representation
of a point in the X space.

142
00:08:23,660 --> 00:08:25,880
What does this transform to?

143
00:08:25,880 --> 00:08:29,050
I'd like you to think before
I give the answer.

144
00:08:29,050 --> 00:08:32,980
Well, it transforms to a z.

145
00:08:32,980 --> 00:08:34,570
That is a vector.

146
00:08:34,570 --> 00:08:36,650
Each of these coordinates,

147
00:08:36,650 --> 00:08:38,090
let's say, z_1,

148
00:08:38,090 --> 00:08:43,333
is a nonlinear function, potentially
nonlinear function, of all of the x's,

149
00:08:43,333 --> 00:08:46,180
so of the entire vector x.

150
00:08:46,180 --> 00:08:50,650
For example, this could
be x_1 x_2 e to the x_3.

151
00:08:50,650 --> 00:08:54,760
The next one would be 1 over
x_2 times x_3 cubed.

152
00:08:54,760 --> 00:08:56,100
Whatever it is.

153
00:08:56,100 --> 00:09:02,890
And you can go on and on and on,
and there is really no limit.

154
00:09:02,890 --> 00:09:07,820
So if we thought of linear methods
here as an economy car,

155
00:09:07,820 --> 00:09:10,090
this could be a truck.

156
00:09:10,090 --> 00:09:13,170
This could be actually an 18-wheeler.

157
00:09:13,170 --> 00:09:17,260
And we must be proud of that, because
with such a simple method, we are able

158
00:09:17,260 --> 00:09:20,080
to create such a strong machine.

159
00:09:20,080 --> 00:09:25,190
But be careful, because you may
not be able to drive it.

160
00:09:25,190 --> 00:09:27,990
And if you do the wrong transformation,

161
00:09:27,990 --> 00:09:30,640
you will end up crashing--

162
00:09:30,640 --> 00:09:33,600
in this case, generalization-wise
crashing.

163
00:09:33,600 --> 00:09:36,320
That is, although you did everything
right, and you did this

164
00:09:36,320 --> 00:09:39,810
transformation, and this is a powerful
machine, you don't know how to drive

165
00:09:39,810 --> 00:09:43,560
the powerful machine, and you end up
with very poor generalization.

166
00:09:43,560 --> 00:09:47,760
And we need the theory in order to get
our driver's license. That will tell us

167
00:09:47,760 --> 00:09:51,670
what to do in order to be able
to drive this machine.

168
00:09:51,670 --> 00:09:54,950
So that is x.

169
00:09:54,950 --> 00:09:58,640
Now, what do x_1 up to x_N go to?

170
00:09:58,640 --> 00:10:01,390
Remember, this is the data set,
the inputs of the data set.

171
00:10:01,390 --> 00:10:05,330
Each of these guys, by itself, is a full
vector x that has all of these

172
00:10:05,330 --> 00:10:06,210
coordinates.

173
00:10:06,210 --> 00:10:08,440
So this is the data set we have.

174
00:10:08,440 --> 00:10:10,930
What does it transform to?

175
00:10:10,930 --> 00:10:13,540
Not surprisingly, z_1 up to z_N.

176
00:10:13,540 --> 00:10:15,060
So you end up with the same
number of points.

177
00:10:15,060 --> 00:10:16,050
That is obvious.

178
00:10:16,050 --> 00:10:17,800
And each of them is a vector.

179
00:10:17,800 --> 00:10:20,140
And each vector can be very
long, according to the

180
00:10:20,140 --> 00:10:22,350
transformation you chose.

181
00:10:22,350 --> 00:10:24,830
Next one--

182
00:10:24,830 --> 00:10:25,510
the labels.

183
00:10:25,510 --> 00:10:28,330
The data set comes with inputs
and outputs, right?

184
00:10:28,330 --> 00:10:30,810
So the inputs I did
the transformation--

185
00:10:30,810 --> 00:10:34,880
what do y_1 up to y_N transform to?

186
00:10:34,880 --> 00:10:38,950
Well, they transform to y_1 up to y_N.

187
00:10:38,950 --> 00:10:40,420
These are untouched.

188
00:10:40,420 --> 00:10:41,180
These are the values.

189
00:10:41,180 --> 00:10:42,670
They are not touched.

190
00:10:42,670 --> 00:10:43,780
And these are the ones we learn.

191
00:10:43,780 --> 00:10:47,840
If it's classification, they are +1
or -1, exactly the same way

192
00:10:47,840 --> 00:10:49,700
they were there before.

193
00:10:49,700 --> 00:10:52,970
How about the weights?

194
00:10:52,970 --> 00:10:57,520
When we use linear models,
we have a weight vector.

195
00:10:57,520 --> 00:11:02,470
So when we are in the X space here,
what are the weights?

196
00:11:02,470 --> 00:11:06,980
The answer is that there are no weights
in the X space when you do

197
00:11:06,980 --> 00:11:08,670
a nonlinear transformation.

198
00:11:08,670 --> 00:11:11,850
The weights are done in the Z space.

199
00:11:11,850 --> 00:11:15,230
And I labeled the weights
here as w tilde.

200
00:11:15,230 --> 00:11:18,900
And I'm using tilde as nonlinear,
so that you remember

201
00:11:18,900 --> 00:11:20,530
it's a nonlinear space.

202
00:11:20,530 --> 00:11:22,990
And everything here is tilde.

203
00:11:22,990 --> 00:11:24,710
So this is w tilde.

204
00:11:24,710 --> 00:11:26,130
And if you look here
at the dimension--

205
00:11:26,130 --> 00:11:26,940
you may have not seen it.

206
00:11:26,940 --> 00:11:28,930
Let me magnify it.

207
00:11:28,930 --> 00:11:31,660
The dimensionality here
is also d tilde.

208
00:11:31,660 --> 00:11:35,260
So whenever we need to distinguish
between z and x, we will add tilde to

209
00:11:35,260 --> 00:11:40,020
the z counterpart, so that you are not
confused about which is which.

210
00:11:40,020 --> 00:11:42,840
So we have those weights.

211
00:11:42,840 --> 00:11:46,190
And finally, you ask yourself:
I've done all of this machinery.

212
00:11:46,190 --> 00:11:48,620
Could you please tell me, what
is the hypothesis that I'm

213
00:11:48,620 --> 00:11:50,590
delivering to my customer?

214
00:11:50,590 --> 00:11:53,955
We're still calling it g of
x, the final hypothesis of

215
00:11:53,955 --> 00:11:55,630
your learning process.

216
00:11:55,630 --> 00:12:01,450
And it happens to be exactly the
same way, except in Z space.

217
00:12:01,450 --> 00:12:06,580
You take the linear form here, and
take the sign, and that would be your

218
00:12:06,580 --> 00:12:07,620
hypothesis.

219
00:12:07,620 --> 00:12:11,580
Except it's a little bit annoying,
because this is g of x, and you're

220
00:12:11,580 --> 00:12:14,420
telling me this is w tilde transposed

221
00:12:14,420 --> 00:12:15,170
times z.

222
00:12:15,170 --> 00:12:16,550
Where is x?

223
00:12:16,550 --> 00:12:19,370
Don't worry. Here is x.

224
00:12:19,370 --> 00:12:21,390
What z is, is the transformation of x.

225
00:12:21,390 --> 00:12:25,140
When you want to evaluate this for
any x, all you need to do is plug into

226
00:12:25,140 --> 00:12:27,480
this formula, and you are ready to go.

227
00:12:27,480 --> 00:12:32,140
That's the entire story of the
nonlinear transformation.

228
00:12:32,140 --> 00:12:35,990
Now, with that out of the way, let's go
to the main topic of the day, which

229
00:12:35,990 --> 00:12:38,750
are error measures and noisy targets.

230
00:12:38,750 --> 00:12:41,860
When we face a real learning problem,
we will realize that there

231
00:12:41,860 --> 00:12:46,230
are components, practical components in
real life, that we have not fully

232
00:12:46,230 --> 00:12:47,920
taken into consideration.

233
00:12:47,920 --> 00:12:51,330
And what I'm going to do, I'm going to
take the learning diagram, which we

234
00:12:51,330 --> 00:12:53,110
introduced in the first lecture.

235
00:12:53,110 --> 00:12:56,990
And then, I'm going to adjust it
according to these practical components,

236
00:12:56,990 --> 00:13:02,430
until we get the final general form of
the supervised learning diagram.

237
00:13:02,430 --> 00:13:06,220
That will take us through both topics,
which are the error measures and the

238
00:13:06,220 --> 00:13:07,990
noisy targets.

239
00:13:07,990 --> 00:13:13,860
Here is the learning diagram in
case you forgot what it was.

240
00:13:13,860 --> 00:13:15,170
That's where we left it.

241
00:13:15,170 --> 00:13:18,240
Let's see what it looks like.

242
00:13:18,240 --> 00:13:20,420
Remember, it's a pretty
simple diagram.

243
00:13:20,420 --> 00:13:21,630
And we built it from scratch.

244
00:13:21,630 --> 00:13:24,790
I need to rebuild it, in order for
you to realize that I'm not just

245
00:13:24,790 --> 00:13:26,480
flashing a jungle on you.

246
00:13:26,480 --> 00:13:27,770
It has a sense.

247
00:13:27,770 --> 00:13:29,250
This is what we're trying to learn.

248
00:13:29,250 --> 00:13:31,890
It's an unknown target function,
represented to

249
00:13:31,890 --> 00:13:33,750
us by training examples.

250
00:13:33,750 --> 00:13:37,010
We have a learning algorithm that will
take these examples and produce the

251
00:13:37,010 --> 00:13:38,120
final hypothesis.

252
00:13:38,120 --> 00:13:39,670
All of this is nice.

253
00:13:39,670 --> 00:13:42,290
We said that the learning algorithm
is picking the hypothesis from the

254
00:13:42,290 --> 00:13:43,480
hypothesis set.

255
00:13:43,480 --> 00:13:47,540
And we said that this is a convenient
technicality that has no loss of

256
00:13:47,540 --> 00:13:48,470
generality.

257
00:13:48,470 --> 00:13:51,290
So we accepted that we will always
have a hypothesis set.

258
00:13:51,290 --> 00:13:53,780
And then, we went into the
feasibility of learning.

259
00:13:53,780 --> 00:13:56,750
And we realized that for that to
happen, we need to introduce

260
00:13:56,750 --> 00:14:01,250
a probability distribution on X, any
probability distribution, and generate

261
00:14:01,250 --> 00:14:04,780
the points x_1 up to x_N, which constitute
the inputs to the training

262
00:14:04,780 --> 00:14:08,990
examples, using this probability
distribution independently.

263
00:14:08,990 --> 00:14:11,400
Once you do that, you get the
benefit of Hoeffding.

264
00:14:11,400 --> 00:14:13,580
And you can make a statement that
you're going to do something

265
00:14:13,580 --> 00:14:16,020
out-of-sample that is reflected
by the in-sample.

266
00:14:16,020 --> 00:14:18,380
That's where we stood.

267
00:14:18,380 --> 00:14:22,640
So this is the diagram we are going
to be modifying piece by piece.

268
00:14:22,640 --> 00:14:25,360
Let's talk about error measures,
the first notion.

269
00:14:25,360 --> 00:14:29,860
Error measures try to answer
the following question:

270
00:14:29,860 --> 00:14:36,080
what does it mean for h
to approximate f?

271
00:14:36,080 --> 00:14:37,390
You have two functions.

272
00:14:37,390 --> 00:14:39,640
And you say, this is a good
approximation, this is a bad

273
00:14:39,640 --> 00:14:40,250
approximation.

274
00:14:40,250 --> 00:14:43,370
Is it a qualitative statement,
or is it quantitative?

275
00:14:43,370 --> 00:14:44,460
It is quantitative.

276
00:14:44,460 --> 00:14:48,270
And because it's quantitative, we are
going to define an error measure that

277
00:14:48,270 --> 00:14:53,490
measures how well, or how
badly, h approximates f.

278
00:14:53,490 --> 00:15:01,160
So the error measure will
be defined as E of two guys.

279
00:15:01,160 --> 00:15:03,920
And these will be h and f.

280
00:15:03,920 --> 00:15:09,090
It returns a number for any
two functions you plug in.

281
00:15:09,090 --> 00:15:10,860
One of them will be the
target function.

282
00:15:10,860 --> 00:15:13,250
One of them will be a hypothesis
of interest.

283
00:15:13,250 --> 00:15:16,940
And you ask yourself, how well, or
how badly in this case, does

284
00:15:16,940 --> 00:15:18,240
h approximate f?

285
00:15:18,240 --> 00:15:19,060
And you get an error.

286
00:15:19,060 --> 00:15:23,260
If the error is 0, then h perfectly
reflects f, and you're home free.

287
00:15:23,260 --> 00:15:27,060
If there's an error, then maybe you need
to look for another h that has

288
00:15:27,060 --> 00:15:27,930
smaller error.

289
00:15:27,930 --> 00:15:31,560
So that formalizes the question of
search, of the learning algorithm, into

290
00:15:31,560 --> 00:15:34,210
minimizing an error function.

291
00:15:34,210 --> 00:15:35,490
We call it error function.

292
00:15:35,490 --> 00:15:38,780
And we call this error measure. It is
neither a measure in the measure

293
00:15:38,780 --> 00:15:40,310
theoretic sense, or a function--

294
00:15:40,310 --> 00:15:41,650
this is actually a functional.

295
00:15:41,650 --> 00:15:43,340
But we are not worrying about that.

296
00:15:43,340 --> 00:15:45,930
We just take these objects
and return a number.

297
00:15:45,930 --> 00:15:47,590
And we refer to it as a function.

298
00:15:47,590 --> 00:15:51,230
And we talk about error measure in the
sense of the English word "measure",

299
00:15:51,230 --> 00:15:53,030
not the mathematical "measure".

300
00:15:53,030 --> 00:16:01,050
So the error function, in principle,
returns a number

301
00:16:01,050 --> 00:16:02,920
for a pair of functions.

302
00:16:02,920 --> 00:16:06,550
But it is almost always defined
in terms of difference on

303
00:16:06,550 --> 00:16:07,970
a particular point.

304
00:16:07,970 --> 00:16:10,310
And then, you put these
points together.

305
00:16:10,310 --> 00:16:12,590
That's the pointwise definition.

306
00:16:12,590 --> 00:16:18,320
In this case, you define a small e
that goes with a capital E that also

307
00:16:18,320 --> 00:16:20,090
takes two arguments.

308
00:16:20,090 --> 00:16:25,430
And these two arguments are the value
of h at a particular point, and the

309
00:16:25,430 --> 00:16:27,990
value of f at the same point.

310
00:16:27,990 --> 00:16:28,740
That makes sense.

311
00:16:28,740 --> 00:16:29,920
I'm trying to compare functions.

312
00:16:29,920 --> 00:16:32,720
I want them to be the same
on the same point.

313
00:16:32,720 --> 00:16:35,950
Therefore, if I compare them for every
point this way, then I will get

314
00:16:35,950 --> 00:16:36,720
something meaningful.

315
00:16:36,720 --> 00:16:40,610
And then, I will need to do something
about the different e's, small e's,

316
00:16:40,610 --> 00:16:42,576
that will get me the big E.

317
00:16:42,576 --> 00:16:46,610
Although this is not strictly
required by the definition-- you could

318
00:16:46,610 --> 00:16:50,970
have a crazy error function that does
not reduce to corresponding points.

319
00:16:50,970 --> 00:16:54,070
But invariably, this is what
you're going to do.

320
00:16:54,070 --> 00:16:56,150
Have we seen this before?

321
00:16:56,150 --> 00:16:58,070
Yes, we have.

322
00:16:58,070 --> 00:16:59,970
Remember the squared error?

323
00:16:59,970 --> 00:17:02,450
How do we formalize it in this sense?

324
00:17:02,450 --> 00:17:08,410
We can say that the error in this case
is h of x minus f of x squared.

325
00:17:08,410 --> 00:17:11,310
That's what we did, and that is indeed
an error function that measures the

326
00:17:11,310 --> 00:17:12,450
difference between the two.

327
00:17:12,450 --> 00:17:15,920
And indeed, if the error is 0, it means
that h of x equals f of x, and

328
00:17:15,920 --> 00:17:18,368
we have exactly what we want.

329
00:17:18,368 --> 00:17:21,839
We also saw it before, although we
didn't explicitly talk about it in

330
00:17:21,839 --> 00:17:24,410
those terms, when we talked
about binary error.

331
00:17:24,410 --> 00:17:28,280
When we had perceptrons, every point
could be either right or wrong.

332
00:17:28,280 --> 00:17:32,540
And that doesn't look like
a quantitative error function.

333
00:17:32,540 --> 00:17:33,910
It's binary.

334
00:17:33,910 --> 00:17:37,830
However, you can also put it
in those terms as follows.

335
00:17:37,830 --> 00:17:41,390
We agreed this notion-- let
me magnify it for you.

336
00:17:41,390 --> 00:17:46,400
This notation, which is the funny
bracket, means that you return 1 if

337
00:17:46,400 --> 00:17:49,410
the statement enclosed here is true.

338
00:17:49,410 --> 00:17:51,410
And you return 0 if it is false.

339
00:17:51,410 --> 00:17:52,990
That's a standard notation.

340
00:17:52,990 --> 00:17:55,870
So if you take this as your error
function, what will happen?

341
00:17:55,870 --> 00:18:01,440
If h of x equals f of x, then this
statement is false, and you return 0.

342
00:18:01,440 --> 00:18:03,030
So the error is 0, good.

343
00:18:03,030 --> 00:18:05,230
And if this statement is
true, you return 1.

344
00:18:05,230 --> 00:18:07,380
And indeed, in that case,
you're making an error.

345
00:18:07,380 --> 00:18:09,540
So it's a binary error
because of this.

346
00:18:09,540 --> 00:18:14,560
And if you take it as a formal error, and
do the rest of the development to

347
00:18:14,560 --> 00:18:19,220
get the other one, the big E for the
global function, you will find that

348
00:18:19,220 --> 00:18:22,260
this is exactly what we did when we were
talking about frequency of error

349
00:18:22,260 --> 00:18:23,070
and probability of error.

350
00:18:23,070 --> 00:18:25,130
That will become clear in a moment.

351
00:18:25,130 --> 00:18:28,390
Now, let's move from
the pointwise--

352
00:18:28,390 --> 00:18:30,510
you define it on one
point in the space--

353
00:18:30,510 --> 00:18:34,610
to define the error function, 
capital E, on the entire space.

354
00:18:34,610 --> 00:18:39,080
The way it is done is that the
overall error, which has this

355
00:18:39,080 --> 00:18:44,650
notation, will always be the average
of pointwise errors.

356
00:18:44,650 --> 00:18:47,290
So you take these pointwise
errors and average them.

357
00:18:47,290 --> 00:18:50,710
And all we need to do is articulate
what we mean by "average" in

358
00:18:50,710 --> 00:18:52,180
order to get that.

359
00:18:52,180 --> 00:18:56,330
So let's look at the in-sample error.

360
00:18:56,330 --> 00:18:59,530
When we have the in-sample error,
this is the formula for it.

361
00:18:59,530 --> 00:19:06,130
And now, you think of in-sample error as
the in-sample version of this.

362
00:19:06,130 --> 00:19:10,690
Because now, we are going to use the
pointwise error that goes with that

363
00:19:10,690 --> 00:19:15,480
error function, or that error measure,
in defining the in-sample error.

364
00:19:15,480 --> 00:19:21,040
If you take a single point from your
training set, you would be having

365
00:19:21,040 --> 00:19:25,210
n going from 1 to N, so one of them
generically is n.

366
00:19:25,210 --> 00:19:28,150
And I'm putting it in red, because
that's what we are going to average

367
00:19:28,150 --> 00:19:29,380
with respect to.

368
00:19:29,380 --> 00:19:32,550
You compute this error measure
whatever it may be, squared error,

369
00:19:32,550 --> 00:19:34,940
binary error, any other error
you can think of.

370
00:19:34,940 --> 00:19:36,650
And now, you get the average.

371
00:19:36,650 --> 00:19:39,980
And average in that case will be the
simple average, which is 1 over N over

372
00:19:39,980 --> 00:19:42,750
that, over the sum.

373
00:19:42,750 --> 00:19:46,540
This is indeed consistent with what
we thought of as the training error.

374
00:19:46,540 --> 00:19:49,820
And if you go back to the binary error,
which is the funny error, and

375
00:19:49,820 --> 00:19:53,000
you look at what this formula will
return, it will return exactly the

376
00:19:53,000 --> 00:19:57,890
frequency of error in
the sample, correct?

377
00:19:57,890 --> 00:20:01,780
Now let's go for
out-of-sample error.

378
00:20:01,780 --> 00:20:05,920
Again, the out-of-sample error is
the out-of-sample version of this

379
00:20:05,920 --> 00:20:07,900
error measure.

380
00:20:07,900 --> 00:20:11,880
Now, in this case, the point is
a general point in the space.

381
00:20:11,880 --> 00:20:15,540
So we are labeling it as x in general,
without any label.

382
00:20:15,540 --> 00:20:19,920
This could be any point in the space
that is picked from

383
00:20:19,920 --> 00:20:22,370
X, which is the input space.

384
00:20:22,370 --> 00:20:27,520
And in order to get an average in that
case, what you do is you get the

385
00:20:27,520 --> 00:20:31,230
expected value, in this case
with respect to x.

386
00:20:31,230 --> 00:20:33,840
So that is the average for
the out-of-sample case.

387
00:20:33,840 --> 00:20:38,200
And again, if you take the binary error,
and you take the expected value

388
00:20:38,200 --> 00:20:42,660
of this, this would be identically the
probability of error overall.

389
00:20:42,660 --> 00:20:46,240
And we are using the probability
distribution over the input space X, in

390
00:20:46,240 --> 00:20:48,540
order to compute this quantity.

391
00:20:48,540 --> 00:20:53,270
That's how we get from a definition
that you invoke on a single point, to

392
00:20:53,270 --> 00:20:57,280
the in-sample and out-of-sample
versions.

393
00:20:57,280 --> 00:21:03,740
Now let's revise the learning
diagram with this added component.

394
00:21:03,740 --> 00:21:08,140
Here is the learning diagram.

395
00:21:08,140 --> 00:21:11,550
There's nothing that changed here except
that now, this is the standard

396
00:21:11,550 --> 00:21:13,280
color, because we already
got used to it.

397
00:21:13,280 --> 00:21:15,700
The red stuff is the new stuff.

398
00:21:15,700 --> 00:21:19,610
So you have here, and you want
to add the error measure.

399
00:21:19,610 --> 00:21:22,820
I'd like you to think for a moment
what we are going to do.

400
00:21:22,820 --> 00:21:23,940
We're going to do it in two steps.

401
00:21:23,940 --> 00:21:27,000
The first one is to realize that
we are defining the error

402
00:21:27,000 --> 00:21:28,890
measure on a point.

403
00:21:28,890 --> 00:21:30,660
So here's the addition.

404
00:21:30,660 --> 00:21:36,960
The addition is that in deciding whether
g is close to f, which is the

405
00:21:36,960 --> 00:21:41,520
goal of learning, we test
this with a point x.

406
00:21:41,520 --> 00:21:45,940
And the criterion for deciding whether g
of x is approximately the same as f

407
00:21:45,940 --> 00:21:49,970
of x is our pointwise error measure.

408
00:21:49,970 --> 00:21:53,050
Furthermore, this x is created
from the space using

409
00:21:53,050 --> 00:21:54,920
something very specific.

410
00:21:54,920 --> 00:21:58,360
And that is, it comes from the same
probability distribution.

411
00:21:58,360 --> 00:22:01,330


412
00:22:01,330 --> 00:22:05,970
It comes from the same probability
distribution that generated those

413
00:22:05,970 --> 00:22:07,060
points.

414
00:22:07,060 --> 00:22:09,540
This was implicit when we
talked about the bin.

415
00:22:09,540 --> 00:22:12,750
mu was the probability distribution
in the bin.

416
00:22:12,750 --> 00:22:18,820
And nu was the sample distribution
in the sample that you pick.

417
00:22:18,820 --> 00:22:23,270
When you test the system that you
trained using a certain probability

418
00:22:23,270 --> 00:22:27,530
distribution, I ask you to test it
with points drawn from the same

419
00:22:27,530 --> 00:22:28,650
distribution.

420
00:22:28,650 --> 00:22:32,310
That's the only requirement in order
to invoke Hoeffding, or the

421
00:22:32,310 --> 00:22:36,450
counterparts of Hoeffding for more
elaborate type of functions.

422
00:22:36,450 --> 00:22:41,240
Now, if you do that, then
you have the guarantee.

423
00:22:41,240 --> 00:22:45,300
And it does make sense that
with the benign assumption

424
00:22:45,300 --> 00:22:47,820
that P can be an unknown--

425
00:22:47,820 --> 00:22:50,000
any probability distribution--

426
00:22:50,000 --> 00:22:54,130
all you're asked to do in order to get
the guarantees that we talked about is:

427
00:22:54,130 --> 00:22:58,440
use it to generate the examples, and
use it to test the hypothesis.

428
00:22:58,440 --> 00:23:00,270
So that is what we have.

429
00:23:00,270 --> 00:23:02,980
Now we come to the question--

430
00:23:02,980 --> 00:23:04,420
I understand where the role is.

431
00:23:04,420 --> 00:23:06,950
I'm going to define the error
measure on point by point.

432
00:23:06,950 --> 00:23:11,110
I know how to move from a point to the
in-sample, on to the out-of-sample.

433
00:23:11,110 --> 00:23:13,230
Now, we come to the crux
of the question.

434
00:23:13,230 --> 00:23:15,360
How do I define the error measure?

435
00:23:15,360 --> 00:23:19,540
What is the number that I should return
for h differing from f on

436
00:23:19,540 --> 00:23:20,890
a particular point?

437
00:23:20,890 --> 00:23:24,260


438
00:23:24,260 --> 00:23:26,920
I will give you an example
to make the point.

439
00:23:26,920 --> 00:23:31,180
And my example will be fingerprint
verification.

440
00:23:31,180 --> 00:23:33,310
You declare yourself.

441
00:23:33,310 --> 00:23:34,760
And you want to authenticate yourself.

442
00:23:34,760 --> 00:23:39,710
So you put your finger, and the system
will decide whether it's you and

443
00:23:39,710 --> 00:23:44,820
return +1, or it's an intruder
and return -1.

444
00:23:44,820 --> 00:23:46,450
That's what the system does.

445
00:23:46,450 --> 00:23:51,630
And we would like to see how to define
an error measure in this case.

446
00:23:51,630 --> 00:23:56,110
There are two types of error
that you can make when you have

447
00:23:56,110 --> 00:23:57,270
a system like this.

448
00:23:57,270 --> 00:24:01,810
One of them is called
false accept.

449
00:24:01,810 --> 00:24:03,770
I think it's self-explanatory.

450
00:24:03,770 --> 00:24:07,690
False accept meaning that someone who
shouldn't be there was accepted, was

451
00:24:07,690 --> 00:24:08,660
falsely accepted.

452
00:24:08,660 --> 00:24:10,100
So the intruder got in.

453
00:24:10,100 --> 00:24:11,780
That's an error.

454
00:24:11,780 --> 00:24:14,860
The other type is false reject.

455
00:24:14,860 --> 00:24:18,380
You, the owner of the system, the one
who paid for it, you put your finger,

456
00:24:18,380 --> 00:24:19,580
and you are rejected.

457
00:24:19,580 --> 00:24:20,960
And you're mad at them.

458
00:24:20,960 --> 00:24:23,330
That's a false reject.

459
00:24:23,330 --> 00:24:27,340
Now, in defining an error measure,
I'd like to get this case,

460
00:24:27,340 --> 00:24:30,220
because there is a great intuition
about what is going on.

461
00:24:30,220 --> 00:24:33,960
So if we can come up with a meaningful
error measure here, that captures

462
00:24:33,960 --> 00:24:38,370
both the false accept and false reject,
we will have a handle on what

463
00:24:38,370 --> 00:24:41,255
the error measures are all about.

464
00:24:41,255 --> 00:24:44,480
So how do we penalize each type?

465
00:24:44,480 --> 00:24:45,310
That's what you do.

466
00:24:45,310 --> 00:24:48,940
When you give an error, you penalize
it such that the error is large.

467
00:24:48,940 --> 00:24:51,390
So you move away from that hypothesis,
to get a better hypothesis that

468
00:24:51,390 --> 00:24:54,150
doesn't penalize it as much.

469
00:24:54,150 --> 00:24:58,780
Now, we can put it in
a matrix form.

470
00:24:58,780 --> 00:24:59,900
This is the target.

471
00:24:59,900 --> 00:25:01,730
This is the perfect system.

472
00:25:01,730 --> 00:25:05,770
This returns +1 whenever it's you,
returns -1 whenever it's

473
00:25:05,770 --> 00:25:07,150
an intruder.

474
00:25:07,150 --> 00:25:08,710
That's our dream system.

475
00:25:08,710 --> 00:25:09,520
We don't have that.

476
00:25:09,520 --> 00:25:12,510
We're going to use machine
learning using examples.

477
00:25:12,510 --> 00:25:14,245
And we are going to come
up with a hypothesis.

478
00:25:14,245 --> 00:25:16,220
This may not be the
final hypothesis.

479
00:25:16,220 --> 00:25:18,190
We are talking about a general
hypothesis here.

480
00:25:18,190 --> 00:25:21,210
When it becomes the final hypothesis,
we are going to call it g.

481
00:25:21,210 --> 00:25:23,800
So h could be +1 or -1.

482
00:25:23,800 --> 00:25:28,060
And +1 means you are accepted,
or the person is accepted,

483
00:25:28,060 --> 00:25:28,810
whoever he may be.

484
00:25:28,810 --> 00:25:32,040
And -1 means they are rejected.

485
00:25:32,040 --> 00:25:36,520
Now, let's try to put under the
four possibilities here what the

486
00:25:36,520 --> 00:25:38,270
errors would be.

487
00:25:38,270 --> 00:25:40,600
First, the easy one--

488
00:25:40,600 --> 00:25:42,930
the diagonal corresponds to no error.

489
00:25:42,930 --> 00:25:45,730
And I'm putting it in faint color,
because in that case, it's clear that

490
00:25:45,730 --> 00:25:48,310
you're going to make zero error.

491
00:25:48,310 --> 00:25:49,330
It's you, and you were accepted.

492
00:25:49,330 --> 00:25:50,950
It's not you, and you were rejected.

493
00:25:50,950 --> 00:25:52,350
That's fine.

494
00:25:52,350 --> 00:25:54,020
What's interesting are these two.

495
00:25:54,020 --> 00:26:00,530
So we need to get a number for the
false accept, which means it's

496
00:26:00,530 --> 00:26:08,800
an intruder but they were accepted, or
the false reject, which means it's you

497
00:26:08,800 --> 00:26:11,630
but you were rejected.

498
00:26:11,630 --> 00:26:14,760
If I can come up with four numbers here,
two of which I already know,

499
00:26:14,760 --> 00:26:17,360
then I have the answer.

500
00:26:17,360 --> 00:26:23,030
The key message I'm conveying with this
discussion is that there is no

501
00:26:23,030 --> 00:26:29,520
inherent merit to choosing one
error function over another.

502
00:26:29,520 --> 00:26:31,860
It's not an analytic question.

503
00:26:31,860 --> 00:26:34,360
It's an application-domain question.

504
00:26:34,360 --> 00:26:37,190
And I'm going to argue for that.

505
00:26:37,190 --> 00:26:41,520
Let's look at the error measure for
this problem, for the important

506
00:26:41,520 --> 00:26:46,770
application of supermarkets.

507
00:26:46,770 --> 00:26:49,350
What happens with supermarkets?

508
00:26:49,350 --> 00:26:52,440
Well, supermarkets decide
to become fancy.

509
00:26:52,440 --> 00:26:56,565
And when you go and you want the
discount for your special program, you

510
00:26:56,565 --> 00:26:59,780
not only declare yourself, they
need to verify that it's you.

511
00:26:59,780 --> 00:27:03,390
Because they have recently too many
people just claim any number to get

512
00:27:03,390 --> 00:27:04,050
the discount.

513
00:27:04,050 --> 00:27:05,500
They want to control it a little bit.

514
00:27:05,500 --> 00:27:08,360
So on the checkout, you
identify yourself.

515
00:27:08,360 --> 00:27:09,790
And then, you put your finger.

516
00:27:09,790 --> 00:27:14,730
And then, the system will verify you or
decide that you're an intruder.

517
00:27:14,730 --> 00:27:19,840
Now, given this application, let's try
to see false accepts and false rejects

518
00:27:19,840 --> 00:27:21,130
and how to penalize them.

519
00:27:21,130 --> 00:27:24,200


520
00:27:24,200 --> 00:27:27,070
The false reject in this case
actually is costly.

521
00:27:27,070 --> 00:27:27,830
Think of it this way.

522
00:27:27,830 --> 00:27:33,770
You are a customer, you go out, and you
have this huge bag of stuff, $100

523
00:27:33,770 --> 00:27:35,870
worth of stuff, and you think you're
an important customer to the

524
00:27:35,870 --> 00:27:37,250
supermarket.

525
00:27:37,250 --> 00:27:39,400
You put your finger, you are rejected.

526
00:27:39,400 --> 00:27:42,160
You put your finger again, you're
rejected, put your finger again,

527
00:27:42,160 --> 00:27:43,120
you're rejected.

528
00:27:43,120 --> 00:27:45,620
You're embarrassed in front of the
entire queue, and in your mind, you

529
00:27:45,620 --> 00:27:47,160
say, the heck with this supermarket.

530
00:27:47,160 --> 00:27:49,190
I'm going to go to the competitor.

531
00:27:49,190 --> 00:27:52,880
So when they have a false reject, they
run the risk of losing a customer--

532
00:27:52,880 --> 00:27:57,090


533
00:27:57,090 --> 00:27:58,340
customer gets annoyed.

534
00:27:58,340 --> 00:28:00,860


535
00:28:00,860 --> 00:28:04,160
False accept is not that
big of a deal.

536
00:28:04,160 --> 00:28:07,220
Someone comes in and claims they're
you, and the system passes them.

537
00:28:07,220 --> 00:28:08,330
What is the downside?

538
00:28:08,330 --> 00:28:09,460
They got a discount.

539
00:28:09,460 --> 00:28:11,580
OK, one more discount--

540
00:28:11,580 --> 00:28:14,190
for business, it's not that important.

541
00:28:14,190 --> 00:28:18,300
And furthermore, if you think about it,
that must be a very brave person.

542
00:28:18,300 --> 00:28:28,560
Because they are an intruder, and they
left their fingerprint on the system.

543
00:28:28,560 --> 00:28:30,570
That's part of the deal.

544
00:28:30,570 --> 00:28:32,050
All to get a discount--

545
00:28:32,050 --> 00:28:34,010
I think really they are in trouble.

546
00:28:34,010 --> 00:28:37,880
So we really shouldn't penalize the
false positives that much, if that will

547
00:28:37,880 --> 00:28:39,790
help us with the false negatives.

548
00:28:39,790 --> 00:28:43,820
If you look at a matrix that
fits this situation, this

549
00:28:43,820 --> 00:28:46,130
one qualifies.

550
00:28:46,130 --> 00:28:51,020
I'm going to penalize false rejects.

551
00:28:51,020 --> 00:28:52,640
That's not a question.

552
00:28:52,640 --> 00:28:55,310
But I'm going to penalize
them just by 1.

553
00:28:55,310 --> 00:28:58,405
When it comes to the other one,
which are the false accepts--

554
00:28:58,405 --> 00:29:02,380


555
00:29:02,380 --> 00:29:03,940
let me try again.

556
00:29:03,940 --> 00:29:08,420
This is the false reject.

557
00:29:08,420 --> 00:29:12,290
It's you, and you were rejected, and
you are penalized dearly.

558
00:29:12,290 --> 00:29:14,620
And this one is the false accept.

559
00:29:14,620 --> 00:29:17,500
It's not you, and you were accepted,
and therefore, you

560
00:29:17,500 --> 00:29:18,840
give it less weight.

561
00:29:18,840 --> 00:29:24,180
So this looks like a reasonable
matrix for that case.

562
00:29:24,180 --> 00:29:28,000
Now, let's look at the
exact same system.

563
00:29:28,000 --> 00:29:31,960
You are given training examples, you are
told that the target function is

564
00:29:31,960 --> 00:29:35,030
fingerprint verification, and
you go about your machine

565
00:29:35,030 --> 00:29:37,070
learning algorithm.

566
00:29:37,070 --> 00:29:39,820
Now, one of them is for a supermarket.

567
00:29:39,820 --> 00:29:46,160
And the other one is for the CIA.

568
00:29:46,160 --> 00:29:47,410
Let's see the situation here.

569
00:29:47,410 --> 00:29:50,090


570
00:29:50,090 --> 00:29:53,340
Now, what is the CIA going
to use the system for?

571
00:29:53,340 --> 00:29:54,960
It uses it for security--

572
00:29:54,960 --> 00:29:59,070
identity verification, that you are
an authentic person authorized to do

573
00:29:59,070 --> 00:30:01,040
something, could be entering
the building, could be

574
00:30:01,040 --> 00:30:02,020
looking at a document.

575
00:30:02,020 --> 00:30:04,620
So you put your fingerprint first.

576
00:30:04,620 --> 00:30:06,700
Now, let's look at the false
accept and false reject.

577
00:30:06,700 --> 00:30:10,390


578
00:30:10,390 --> 00:30:13,750
You have to agree with me that false
accept in this case is an unmitigated

579
00:30:13,750 --> 00:30:15,920
disaster.

580
00:30:15,920 --> 00:30:19,200
Someone got authority to something that
they're not authorized in, and

581
00:30:19,200 --> 00:30:20,720
national security is at stake.

582
00:30:20,720 --> 00:30:25,210
That's a no-no.

583
00:30:25,210 --> 00:30:28,010
False reject in this case
can be tolerated.

584
00:30:28,010 --> 00:30:29,690
Why?

585
00:30:29,690 --> 00:30:31,305
You are not a customer.

586
00:30:31,305 --> 00:30:33,190
You are an employee.

587
00:30:33,190 --> 00:30:35,390
It's you, but the system rejected you.

588
00:30:35,390 --> 00:30:37,940
Just try again and
again and again.

589
00:30:37,940 --> 00:30:42,650
Because you're paid to be here.

590
00:30:42,650 --> 00:30:46,070
Just take the inconvenience and do
this, in order to save the false

591
00:30:46,070 --> 00:30:47,740
accepts.

592
00:30:47,740 --> 00:30:50,680
So in this case, it makes sense that
we are going to put the weights in

593
00:30:50,680 --> 00:30:53,700
exactly the opposite way,
even more extreme.

594
00:30:53,700 --> 00:30:57,890
And you will have a matrix
that looks like this.

595
00:30:57,890 --> 00:31:01,460
If you are the wrong person, and you are
accepted, that's a false accept.

596
00:31:01,460 --> 00:31:04,080
That's a huge penalty.

597
00:31:04,080 --> 00:31:06,640
The other one, you put
a meager penalty.

598
00:31:06,640 --> 00:31:11,650
If you're really cruel with your
employees, you put this 0.1 or 0.001,

599
00:31:11,650 --> 00:31:15,710
and then have them really go for this
thing for 20 times until they're

600
00:31:15,710 --> 00:31:16,650
accepted.

601
00:31:16,650 --> 00:31:20,290
But in general, you can see that this
has to be a much bigger number than

602
00:31:20,290 --> 00:31:24,020
this, whereas in the supermarket case,
this was a bigger number than that.

603
00:31:24,020 --> 00:31:29,820
So the take-home lesson is that, when
you're dealing with a practical

604
00:31:29,820 --> 00:31:36,110
learning problem, the error measure
should be specified by the user.

605
00:31:36,110 --> 00:31:38,520
You are going to deliver
a system to them.

606
00:31:38,520 --> 00:31:40,190
The system is not perfect.

607
00:31:40,190 --> 00:31:44,560
They want the target function, and you
give them a hypothesis instead.

608
00:31:44,560 --> 00:31:50,600
You should ask them, how much does it
cost you to use my imperfect system in

609
00:31:50,600 --> 00:31:52,350
place of the perfect system?

610
00:31:52,350 --> 00:31:54,180
That is their decision to make.

611
00:31:54,180 --> 00:31:57,335
And if they articulate that as
a quantitative error function, this is

612
00:31:57,335 --> 00:31:59,920
the error function you
should work with.

613
00:31:59,920 --> 00:32:03,840
However, this does not always happen.

614
00:32:03,840 --> 00:32:09,150
People may not have the formalization
that will capture the error measure

615
00:32:09,150 --> 00:32:10,290
in reality.

616
00:32:10,290 --> 00:32:13,860
And sometimes, they capture it, but
it's very difficult to optimize.

617
00:32:13,860 --> 00:32:16,200
There are other considerations.

618
00:32:16,200 --> 00:32:20,840
So now, what I'm going to talk about are
the alternatives to this approach.

619
00:32:20,840 --> 00:32:23,270
And the alternatives are
a compromise.

620
00:32:23,270 --> 00:32:26,170
They are very common and popular
compromises, and

621
00:32:26,170 --> 00:32:27,640
people indulge on them.

622
00:32:27,640 --> 00:32:30,500
I don't mind indulging on them, because
actually, there are some nice

623
00:32:30,500 --> 00:32:31,450
properties to them.

624
00:32:31,450 --> 00:32:35,040
But always remember, this
is a second choice.

625
00:32:35,040 --> 00:32:39,550
If we knew what the error measure that
needs to be used by the user is, we

626
00:32:39,550 --> 00:32:41,360
would use that.

627
00:32:41,360 --> 00:32:42,720
So here are the two alternatives--

628
00:32:42,720 --> 00:32:45,260
you don't have the user-specified
error measure.

629
00:32:45,260 --> 00:32:51,480
Then, you resort to plausible measures,
measures that you can argue

630
00:32:51,480 --> 00:32:54,200
analytically that they have merit.

631
00:32:54,200 --> 00:32:58,050
Usually, the analytic argument starts
with an assumption that is usually

632
00:32:58,050 --> 00:32:59,240
a loaded assumption.

633
00:32:59,240 --> 00:33:01,370
And from there, the going
is very smooth.

634
00:33:01,370 --> 00:33:04,780
But nonetheless, that is
in the absence of

635
00:33:04,780 --> 00:33:05,870
a meritorious error measure,

636
00:33:05,870 --> 00:33:07,530
we might as well resort to that.

637
00:33:07,530 --> 00:33:11,650
We have seen example of that,
which is squared error.

638
00:33:11,650 --> 00:33:16,040
If you look at squared error, you can
say that if the noise is Gaussian--

639
00:33:16,040 --> 00:33:19,530
I didn't do that in the lecture,
but it's not

640
00:33:19,530 --> 00:33:21,020
a difficult thing to imagine--

641
00:33:21,020 --> 00:33:25,170
that the corresponding error measure in
this case would be squared error.

642
00:33:25,170 --> 00:33:28,190
So that is the plausibility of it.

643
00:33:28,190 --> 00:33:30,950
And you can take other cases, for
example, the binary error.

644
00:33:30,950 --> 00:33:34,200
You can go and get cross-entropy type
of error corresponding to the binary

645
00:33:34,200 --> 00:33:34,660
error and whatnot.

646
00:33:34,660 --> 00:33:38,550
So these guys have an error measure
that goes with them.

647
00:33:38,550 --> 00:33:43,200
The other approach is not to have
a plausible measure, but to have

648
00:33:43,200 --> 00:33:46,500
a friendly measure. You are
not justifying that this is

649
00:33:46,500 --> 00:33:47,780
a meritorious measure.

650
00:33:47,780 --> 00:33:51,250
You're just using it because
it's easy to use.

651
00:33:51,250 --> 00:33:53,210
And we have also seen that.

652
00:33:53,210 --> 00:33:56,655
For example, we can get closed-form
solution if we choose a particular

653
00:33:56,655 --> 00:33:58,010
error measure.

654
00:33:58,010 --> 00:33:59,850
Linear regression comes to mind.

655
00:33:59,850 --> 00:34:02,780
If you didn't use a squared error in
that case, you would not have gotten

656
00:34:02,780 --> 00:34:06,910
the very easy formula that we started
the lecture with.

657
00:34:06,910 --> 00:34:11,889
And also, even if you can't get
a closed-form solution, you might be

658
00:34:11,889 --> 00:34:13,830
able to use optimization
that is favorable.

659
00:34:13,830 --> 00:34:19,480
For example, the cross entropy that I
referred to ends up, in a case of

660
00:34:19,480 --> 00:34:23,929
a linear model, the logistic regression,
being convex which means that

661
00:34:23,929 --> 00:34:25,100
optimization is efficient.

662
00:34:25,100 --> 00:34:27,920
In that case, you get a global
minimum and all of that.

663
00:34:27,920 --> 00:34:34,429
So now, you resort to either
a conceptual appeal, the plausibility,

664
00:34:34,429 --> 00:34:37,750
or practical appeal, which is
the friendly aspect, to

665
00:34:37,750 --> 00:34:38,820
choose the error measure.

666
00:34:38,820 --> 00:34:41,620
This is completely legitimate, because
in many cases, you're not going to

667
00:34:41,620 --> 00:34:44,030
have the user-specified error measure.

668
00:34:44,030 --> 00:34:51,050
Now, let us modify the learning
diagram once more to introduce the

669
00:34:51,050 --> 00:34:53,850
error measure as we defined it.

670
00:34:53,850 --> 00:34:55,100
So here is--

671
00:34:55,100 --> 00:34:58,120


672
00:34:58,120 --> 00:35:02,950
and I'd like to ask you to look at this
for maybe 15 seconds, and tell me

673
00:35:02,950 --> 00:35:08,320
where you think the error measure
will fit in this diagram-- the

674
00:35:08,320 --> 00:35:10,850
error measure itself.

675
00:35:10,850 --> 00:35:12,030
What does it affect?

676
00:35:12,030 --> 00:35:13,230
What does it take from?

677
00:35:13,230 --> 00:35:15,370
What exactly--

678
00:35:15,370 --> 00:35:17,680
I can put the error measure,
for example, here.

679
00:35:17,680 --> 00:35:19,360
That's an option!

680
00:35:19,360 --> 00:35:21,030
I can put it inside the unknown
target function.

681
00:35:21,030 --> 00:35:23,810
What does the error have to do
with the target function?

682
00:35:23,810 --> 00:35:27,910
So you can think, where
would it be?

683
00:35:27,910 --> 00:35:30,825
It's not difficult to realize that
that's where it belongs.

684
00:35:30,825 --> 00:35:33,000
It has two roles.

685
00:35:33,000 --> 00:35:36,330
One of them is to evaluate
this statement.

686
00:35:36,330 --> 00:35:37,630
This statement is qualitative.

687
00:35:37,630 --> 00:35:43,220
The output, the final hypothesis,
approximates the target function.

688
00:35:43,220 --> 00:35:45,440
This is what gives it a number.

689
00:35:45,440 --> 00:35:46,770
This gives it a grade.

690
00:35:46,770 --> 00:35:51,820
And you use the error measure to
quantify this approximate thing.

691
00:35:51,820 --> 00:35:54,230
The other thing is that you have
to feed the error measure to

692
00:35:54,230 --> 00:35:55,310
the learning algorithm.

693
00:35:55,310 --> 00:35:57,490
Because what does the learning
algorithm do when you

694
00:35:57,490 --> 00:35:58,770
have an error measure?

695
00:35:58,770 --> 00:36:01,620
It minimizes the in-sample error,
let's say, in this case.

696
00:36:01,620 --> 00:36:03,970
And the in-sample error depends
on your error measure.

697
00:36:03,970 --> 00:36:06,850
If you're minimizing squared error,
that's different from minimizing

698
00:36:06,850 --> 00:36:08,170
another type of error.

699
00:36:08,170 --> 00:36:12,620
So the error measure feeds
into those two.

700
00:36:12,620 --> 00:36:16,480
Now we go for the next guy, which
is the noisy targets--

701
00:36:16,480 --> 00:36:20,860
new topic, another addition
to the learning diagram.

702
00:36:20,860 --> 00:36:23,000
The noisy targets are actually
very important.

703
00:36:23,000 --> 00:36:26,900
Because in reality, these are the only
types you're going to encounter in the

704
00:36:26,900 --> 00:36:27,960
problems in life.

705
00:36:27,960 --> 00:36:32,060
Very seldom, you get a very
clean target function.

706
00:36:32,060 --> 00:36:38,880
The first statement is, the target
function is not always a function.

707
00:36:38,880 --> 00:36:42,170
Why are we calling it target function
if it's not a function?

708
00:36:42,170 --> 00:36:44,210
Well, function is a mathematical
notion.

709
00:36:44,210 --> 00:36:48,120
You have to return a unique value
for every point in the domain.

710
00:36:48,120 --> 00:36:50,350
That's what qualifies it
as a function.

711
00:36:50,350 --> 00:36:52,360
We used it here a little
bit liberally.

712
00:36:52,360 --> 00:36:55,150
So far, we dealt with it as if
it was really a function.

713
00:36:55,150 --> 00:37:00,100
But let's take the example we started
with, the credit example.

714
00:37:00,100 --> 00:37:04,420
You consider credit card approval, and
here is the historical record.

715
00:37:04,420 --> 00:37:07,340
This is an input.

716
00:37:07,340 --> 00:37:14,110
Isn't it possible that two identical
customers have these fields, and one

717
00:37:14,110 --> 00:37:16,340
of them ended up being good credit,
and one of them ended

718
00:37:16,340 --> 00:37:18,280
up being bad credit?

719
00:37:18,280 --> 00:37:20,840
Sure-- this doesn't capture all
the information in the world.

720
00:37:20,840 --> 00:37:24,780
There's information that is not given
that contributes noise, if you will.

721
00:37:24,780 --> 00:37:28,110
And there are circumstances that the
people will go through that will make

722
00:37:28,110 --> 00:37:31,680
it probabilistic whether they'll
be good credit or bad credit.

723
00:37:31,680 --> 00:37:35,030
So we come to realize that
two identical customers,

724
00:37:35,030 --> 00:37:37,790
in the sense that their input
representation is the same,

725
00:37:37,790 --> 00:37:40,350
can have two different behaviors.

726
00:37:40,350 --> 00:37:46,290
And having this-- this is one point
mapping to two values, so it is

727
00:37:46,290 --> 00:37:47,800
not a function.

728
00:37:47,800 --> 00:37:50,660
What do we do about that?

729
00:37:50,660 --> 00:37:53,980
Well, we use a target distribution,
as in probability distribution.

730
00:37:53,980 --> 00:37:59,500
So instead of having y equals f of x--
you tell me what x is, and I'm going

731
00:37:59,500 --> 00:38:03,410
to tell you what the value
y is for sure.

732
00:38:03,410 --> 00:38:06,250
You use a target distribution.

733
00:38:06,250 --> 00:38:11,470
And the notation for that is
probability of y given x.

734
00:38:11,470 --> 00:38:13,370
So again, it depends on x.

735
00:38:13,370 --> 00:38:16,040
But its dependence is probabilistic.

736
00:38:16,040 --> 00:38:18,840
Some y's are more likely than
others in this case.

737
00:38:18,840 --> 00:38:22,370
Here, one y was possible, and the
rest were impossible.

738
00:38:22,370 --> 00:38:27,540
Now, we make it a little bit
more accommodating.

739
00:38:27,540 --> 00:38:31,080
Now, we have a target distribution
instead of a target function.

740
00:38:31,080 --> 00:38:32,330
Let's follow it through.

741
00:38:32,330 --> 00:38:34,520


742
00:38:34,520 --> 00:38:39,030
x used to be generated by the input
probability distribution.

743
00:38:39,030 --> 00:38:41,570
It will still be generated
by that distribution.

744
00:38:41,570 --> 00:38:45,100
This is an artifact that we introduced
in order to get the benefit of the

745
00:38:45,100 --> 00:38:46,290
Hoeffding-type inequalities.

746
00:38:46,290 --> 00:38:48,050
Nothing has changed.

747
00:38:48,050 --> 00:38:51,660
But what will change now is that, instead
of y being deterministic of x,

748
00:38:51,660 --> 00:38:56,360
once you generate x, y is also
probabilistic-- generated by this

749
00:38:56,360 --> 00:38:58,760
fellow.

750
00:38:58,760 --> 00:39:04,790
So you can think now of x,y as a pair
being generated by the joint

751
00:39:04,790 --> 00:39:08,870
distribution, which is P of x times
P of y given x, assuming

752
00:39:08,870 --> 00:39:11,690
independence.

753
00:39:11,690 --> 00:39:15,250
So in this case-- there's no assumption
of independence once

754
00:39:15,250 --> 00:39:16,470
you put it this way.

755
00:39:16,470 --> 00:39:20,270
But the assumption here is that the
P of y you are given is actually

756
00:39:20,270 --> 00:39:20,990
conditional on x.

757
00:39:20,990 --> 00:39:27,500
Now you get noisy targets.

758
00:39:27,500 --> 00:39:30,550
What is the noisy target
in this case?

759
00:39:30,550 --> 00:39:36,810
Well, a noisy target can be posed as
a deterministic target, like the one we

760
00:39:36,810 --> 00:39:39,350
had before, plus noise.

761
00:39:39,350 --> 00:39:42,480
This applies to any numerical
target function.

762
00:39:42,480 --> 00:39:47,670
So if y is a real number, or binary, or
something numerical, you can always

763
00:39:47,670 --> 00:39:50,540
pose the question of a target
distribution as if it was

764
00:39:50,540 --> 00:39:55,240
a deterministic target function
proper, plus noise.

765
00:39:55,240 --> 00:39:59,500
This is just a convenience, to show
you that this is not far from

766
00:39:59,500 --> 00:40:00,980
what we have already.

767
00:40:00,980 --> 00:40:02,860
And why is that?

768
00:40:02,860 --> 00:40:08,810
Because if you define now a target
function to be the expected value-- the

769
00:40:08,810 --> 00:40:13,120
conditional expected value of y given
x, that's a function.

770
00:40:13,120 --> 00:40:17,500
Although P of y given x gives you
different values, you take the

771
00:40:17,500 --> 00:40:20,240
expected value-- that's a number, and
you call this the value of the

772
00:40:20,240 --> 00:40:24,280
function, f of x.

773
00:40:24,280 --> 00:40:27,355
Then, whatever is left out,
you call the noise.

774
00:40:27,355 --> 00:40:29,190
It's a nice trick.

775
00:40:29,190 --> 00:40:30,440
You've got the bulk of it.

776
00:40:30,440 --> 00:40:32,970


777
00:40:32,970 --> 00:40:36,170
And then, you go here, and you
call the rest the noise.

778
00:40:36,170 --> 00:40:38,250
And that is usually the
form it is given.

779
00:40:38,250 --> 00:40:39,980
So you think that you are really
trying to learn the

780
00:40:39,980 --> 00:40:41,340
target function still.

781
00:40:41,340 --> 00:40:44,230
But there is this annoying noise, and
you're trying to make your algorithm

782
00:40:44,230 --> 00:40:45,340
pick this pattern.

783
00:40:45,340 --> 00:40:47,530
And there's nothing it can do
about the remaining noise,

784
00:40:47,530 --> 00:40:49,320
which averages to 0.

785
00:40:49,320 --> 00:40:56,200
Now, by the same token, there is
no loss of generality when we talk

786
00:40:56,200 --> 00:40:58,150
about probability distributions.

787
00:40:58,150 --> 00:41:01,020
If you actually have a proper function,
which happens once in a blue

788
00:41:01,020 --> 00:41:04,670
moon, you can still pose this as
a probability distribution.

789
00:41:04,670 --> 00:41:08,380
How do you do that?

790
00:41:08,380 --> 00:41:13,350
You get here P of y given x.

791
00:41:13,350 --> 00:41:18,060
And you define it to be identically 0
unless y equals f of x that you have

792
00:41:18,060 --> 00:41:19,200
in mind.

793
00:41:19,200 --> 00:41:22,890
So if we were talking about finite
domains, you put all the probability 1

794
00:41:22,890 --> 00:41:23,970
on this value.

795
00:41:23,970 --> 00:41:27,360
And you put the probability
0 for all other values.

796
00:41:27,360 --> 00:41:30,410
If it happens to be continuous, which is
almost always the case, you put all

797
00:41:30,410 --> 00:41:33,700
the mass on the point, you put a delta
function there, and you let the other

798
00:41:33,700 --> 00:41:35,380
ones be identically 0.

799
00:41:35,380 --> 00:41:38,670
In this case, the target function
is a probability distribution.

800
00:41:38,670 --> 00:41:42,480
Therefore, if we decide that the target
is always a distribution, there

801
00:41:42,480 --> 00:41:44,970
is no loss of generality.

802
00:41:44,970 --> 00:41:52,340
Now, let's do the final installment
of the learning diagram.

803
00:41:52,340 --> 00:41:54,830
Once we are done with this,
we will freeze it forever.

804
00:41:54,830 --> 00:41:59,290
This will be the general learning
diagram for supervised learning.

805
00:41:59,290 --> 00:42:01,580
And here is what we have.

806
00:42:01,580 --> 00:42:05,350
We're going to include the
noisy targets.

807
00:42:05,350 --> 00:42:06,720
This is what we had so far.

808
00:42:06,720 --> 00:42:09,150
It's getting crowded, isn't it?

809
00:42:09,150 --> 00:42:10,870
And we are going to make
it more crowded.

810
00:42:10,870 --> 00:42:13,060
And in this case, we are including
the noisy targets.

811
00:42:13,060 --> 00:42:15,590
So obviously, the modification
will happen here.

812
00:42:15,590 --> 00:42:19,750
And what you do is you replace this
with a target distribution.

813
00:42:19,750 --> 00:42:22,930
Let me magnify it.

814
00:42:22,930 --> 00:42:26,390
So the unknown target function became
unknown target distribution.

815
00:42:26,390 --> 00:42:30,150
You define it as a conditional probability
distribution of y given x.

816
00:42:30,150 --> 00:42:33,780
And you can think of this as if it was
a target function, which is the expected

817
00:42:33,780 --> 00:42:37,530
value that I talked about, plus noise,
which is the remaining part.

818
00:42:37,530 --> 00:42:41,300
But as a target, it is
a distribution.

819
00:42:41,300 --> 00:42:49,790
And I'd like to look at this, and
appreciate the time we spent to build

820
00:42:49,790 --> 00:42:51,260
the blocks here.

821
00:42:51,260 --> 00:42:54,460
In spite of the fact this looks like
a complete jungle, you can go back and

822
00:42:54,460 --> 00:42:57,350
understand every single
component here.

823
00:42:57,350 --> 00:42:59,960
Every component has a reason.

824
00:42:59,960 --> 00:43:04,100
This is to accommodate a practical
consideration, which is the fact that

825
00:43:04,100 --> 00:43:06,160
we are learning something
that is noisy.

826
00:43:06,160 --> 00:43:11,480
This is because a specification of the
penalty, or the cost you pay for not

827
00:43:11,480 --> 00:43:14,270
being perfect, needs to be
specified by the user.

828
00:43:14,270 --> 00:43:18,970
This is our artificial addition to the
problem in order to make learning

829
00:43:18,970 --> 00:43:21,770
feasible, and so on and so forth.

830
00:43:21,770 --> 00:43:26,700
So that is the final diagram
for supervised learning.

831
00:43:26,700 --> 00:43:30,320
Now, I'd like to make one final
point about noisy targets, which is

832
00:43:30,320 --> 00:43:33,602
the distinction between the two
probabilities that we have.

833
00:43:33,602 --> 00:43:37,120
We have probability of x, which
we artificially introduced

834
00:43:37,120 --> 00:43:38,170
to accommodate Hoeffding.

835
00:43:38,170 --> 00:43:42,200
And then, this was introduced in
a completely different context. That is

836
00:43:42,200 --> 00:43:45,930
to accommodate the fact that
genuine functions that you

837
00:43:45,930 --> 00:43:48,700
encounter in practice are not
functions-- are actually noisy

838
00:43:48,700 --> 00:43:50,080
distributions.

839
00:43:50,080 --> 00:43:55,530
So let's look at this.

840
00:43:55,530 --> 00:43:57,290
They look very much related.

841
00:43:57,290 --> 00:44:00,520
They both pour into the
training examples.

842
00:44:00,520 --> 00:44:03,200
That's how the training examples
are generated.

843
00:44:03,200 --> 00:44:06,720
This guy passes on the probability
of y given x.

844
00:44:06,720 --> 00:44:09,430
This guy passes on the
probability of x.

845
00:44:09,430 --> 00:44:12,500
When this guy gets it, it generates
those guys according to the joint

846
00:44:12,500 --> 00:44:16,020
distribution-- multiplies these, if you
will, and then uses it as a way to

847
00:44:16,020 --> 00:44:18,700
generate the pair x,y.

848
00:44:18,700 --> 00:44:21,650
So they look like-- they belong
to the same category.

849
00:44:21,650 --> 00:44:23,460
Both of them are unknown.

850
00:44:23,460 --> 00:44:28,550
This one is unknown so that my machine
learning statement can be as general

851
00:44:28,550 --> 00:44:31,590
as I can afford.

852
00:44:31,590 --> 00:44:32,520
You're learning something.

853
00:44:32,520 --> 00:44:33,590
You don't know what it is.

854
00:44:33,590 --> 00:44:35,300
So that's good to have.

855
00:44:35,300 --> 00:44:38,520
This one is unknown, because it is the
most assumption we could afford in

856
00:44:38,520 --> 00:44:39,610
order to get Hoeffding.

857
00:44:39,610 --> 00:44:43,020
We needed a probability distribution,
but we didn't need to make any

858
00:44:43,020 --> 00:44:44,120
assumptions about it.

859
00:44:44,120 --> 00:44:47,720
So we left it to be an arbitrary
one, and unknown, and we don't

860
00:44:47,720 --> 00:44:49,580
want to know it.

861
00:44:49,580 --> 00:44:51,250
So these are the similarities.

862
00:44:51,250 --> 00:44:52,500
Now, let's look at the differences.

863
00:44:52,500 --> 00:44:55,890


864
00:44:55,890 --> 00:44:59,560
Both have probabilistic aspects.

865
00:44:59,560 --> 00:45:01,840
We have seen that.

866
00:45:01,840 --> 00:45:07,400
Now, the target distribution is
what you are trying to learn.

867
00:45:07,400 --> 00:45:10,980


868
00:45:10,980 --> 00:45:13,870
You are not trying to learn
the input distribution.

869
00:45:13,870 --> 00:45:16,550
As a matter of fact, when you are done,
you will not know what the input

870
00:45:16,550 --> 00:45:17,930
distribution is.

871
00:45:17,930 --> 00:45:23,380
The input distribution is merely playing
the role of quantifying the

872
00:45:23,380 --> 00:45:26,270
relative importance of the point x.

873
00:45:26,270 --> 00:45:28,440
Let me give you an example.

874
00:45:28,440 --> 00:45:31,350
Let's say you are approving
credit again.

875
00:45:31,350 --> 00:45:34,340
The target distribution
is the probability of

876
00:45:34,340 --> 00:45:36,640
creditworthiness given the input.

877
00:45:36,640 --> 00:45:39,210
Let's simplify the input and
say it's the salary.

878
00:45:39,210 --> 00:45:42,940
So I give you the salary, you decide
what is the risk of this person

879
00:45:42,940 --> 00:45:47,480
defaulting, and then you decide--
output is +1, approve credit

880
00:45:47,480 --> 00:45:52,680
with probability 0.9, and disapprove
credit with probability 0.1.

881
00:45:52,680 --> 00:45:54,140
That is the target distribution.

882
00:45:54,140 --> 00:45:56,220
And that is what you're
trying to learn.

883
00:45:56,220 --> 00:45:58,550
You're going to approximate it
to a hard decision probably.

884
00:45:58,550 --> 00:46:00,810
Or you can actually learn the
probability distribution, as

885
00:46:00,810 --> 00:46:03,240
we'll see later on.

886
00:46:03,240 --> 00:46:07,180
The input distribution just tells you
the distribution of salaries in the

887
00:46:07,180 --> 00:46:10,090
general population.

888
00:46:10,090 --> 00:46:12,600
How many people make $100,000,
how many people make

889
00:46:12,600 --> 00:46:14,960
$10,000, et cetera.

890
00:46:14,960 --> 00:46:20,880
So in spite of the fact that the
probability distribution over the

891
00:46:20,880 --> 00:46:25,460
input matters in the sense that: let's
say that you encounter a population

892
00:46:25,460 --> 00:46:29,000
where the salaries are very high, so P
of x is tilted very much towards the

893
00:46:29,000 --> 00:46:34,290
high salaries, and let's conjecture that
high salaries correspond to high

894
00:46:34,290 --> 00:46:38,390
creditworthiness. In this case, the same
system that you trained that will

895
00:46:38,390 --> 00:46:43,100
take any salary, low or high, and then
decide whether to approve credit or

896
00:46:43,100 --> 00:46:48,340
not, will be tested mostly in the very
comfortable region of high salaries.

897
00:46:48,340 --> 00:46:51,410
So it will be returning: yes approve,
yes approve, yes approve, with very

898
00:46:51,410 --> 00:46:53,600
small probability of error.

899
00:46:53,600 --> 00:46:57,710
And if you go and put the mass of
probability around the borderline

900
00:46:57,710 --> 00:47:02,040
cases, the cases where the decision is
difficult, the same system that you

901
00:47:02,040 --> 00:47:05,920
learned will probably perform worse,
just because there are so many points

902
00:47:05,920 --> 00:47:07,720
that are borderline.

903
00:47:07,720 --> 00:47:11,140
So it does give the weight that will
finally grade your hypothesis.

904
00:47:11,140 --> 00:47:15,800
But you're not trying to learn
that distribution.

905
00:47:15,800 --> 00:47:18,480
And when you put them together
analytically, which you're allowed to

906
00:47:18,480 --> 00:47:22,370
do, you can merge them
as P of x and y.

907
00:47:22,370 --> 00:47:24,100
And that's what you will
find in the literature.

908
00:47:24,100 --> 00:47:27,040
It's very nice and pleasant, and you
generate the example using that joint

909
00:47:27,040 --> 00:47:28,200
distribution.

910
00:47:28,200 --> 00:47:33,040
However, you just need to remember that
this merging mixes two concepts

911
00:47:33,040 --> 00:47:35,560
that are inherently different.

912
00:47:35,560 --> 00:47:41,710
Definitely, P of x and y is
not a target distribution

913
00:47:41,710 --> 00:47:43,860
for supervised learning.

914
00:47:43,860 --> 00:47:47,450
The target distribution, the one you're
actually trying to learn, is

915
00:47:47,450 --> 00:47:48,700
this fellow.

916
00:47:48,700 --> 00:47:55,435
And the other component is just
a catalyst in the process.

917
00:47:55,435 --> 00:48:01,770
That covers the error and noise,
and we have arrived at the final

918
00:48:01,770 --> 00:48:03,450
statement of the learning problem.

919
00:48:03,450 --> 00:48:07,020
So now, let me spend the rest of the
lecture trying to prepare you for the

920
00:48:07,020 --> 00:48:11,140
coming two weeks, which will consider
the theory of learning.

921
00:48:11,140 --> 00:48:16,070
It's a very important theory, and I
encourage everyone to bite the bullet

922
00:48:16,070 --> 00:48:17,350
and go through it.

923
00:48:17,350 --> 00:48:20,710
I will do my best to make
it user-friendly.

924
00:48:20,710 --> 00:48:24,860
However, it's important not just because
of the mathematical derivation.

925
00:48:24,860 --> 00:48:28,180
The insight, and the secondary
tools you are going to get,

926
00:48:28,180 --> 00:48:29,840
are extremely important.

927
00:48:29,840 --> 00:48:33,890
It's worth two weeks-- not a full two
weeks, but four hours' worth

928
00:48:33,890 --> 00:48:38,640
of listening to a lecture and actually
trying to study the material well.

929
00:48:38,640 --> 00:48:39,590
So that's my pitch.

930
00:48:39,590 --> 00:48:42,670
Let me give you the preamble
to the theory.

931
00:48:42,670 --> 00:48:47,030
Let's see what we know so far
in order to put the theory in

932
00:48:47,030 --> 00:48:49,740
perspective.

933
00:48:49,740 --> 00:48:54,830
We know that learning is feasible
in a probabilistic sense.

934
00:48:54,830 --> 00:49:00,850
And the way we did this is by stating
that it is likely that the

935
00:49:00,850 --> 00:49:04,920
out-of-sample performance is close
to the in-sample performance.

936
00:49:04,920 --> 00:49:08,300
That, in our mind, corresponded to
the feasibility of learning.

937
00:49:08,300 --> 00:49:16,390
And I'm going to test this premise now
and ask: is this really learning?

938
00:49:16,390 --> 00:49:21,560
Is this condition the condition that
captures what we mean by learning?

939
00:49:21,560 --> 00:49:22,820
Let's raise some doubt.

940
00:49:22,820 --> 00:49:25,970


941
00:49:25,970 --> 00:49:29,600
Well, learning means that you
got the hypothesis right.

942
00:49:29,600 --> 00:49:32,650
You give it to your customer,
and it behaves well--

943
00:49:32,650 --> 00:49:35,440
as close as possible to the
target function, right?

944
00:49:35,440 --> 00:49:37,220
That's success.

945
00:49:37,220 --> 00:49:41,970
That means that the condition for
learning is really that g

946
00:49:41,970 --> 00:49:43,550
approximates f.

947
00:49:43,550 --> 00:49:44,870
And now, we are sophisticated people.

948
00:49:44,870 --> 00:49:48,190
We know what "approximates" means.

949
00:49:48,190 --> 00:49:53,470
This condition is not really
this condition, right?

950
00:49:53,470 --> 00:49:56,890
What is this condition in terms of
the E_in and E_out and stuff?

951
00:49:56,890 --> 00:49:59,130
Very simple--

952
00:49:59,130 --> 00:50:00,860
that's what it means.

953
00:50:00,860 --> 00:50:05,290
It means that the out-of-sample
error for g is close to 0.

954
00:50:05,290 --> 00:50:07,215
Because the out-of-sample
error measures what?

955
00:50:07,215 --> 00:50:12,890
It measures how far you are, that is g,
from the target function over the

956
00:50:12,890 --> 00:50:14,520
entire space.

957
00:50:14,520 --> 00:50:17,820
And therefore, the statement that you
are close means that the out-of-sample

958
00:50:17,820 --> 00:50:20,000
error is small.

959
00:50:20,000 --> 00:50:22,000
So this is what we want.

960
00:50:22,000 --> 00:50:25,020
And this is what we have.

961
00:50:25,020 --> 00:50:26,650
Now, what was that?

962
00:50:26,650 --> 00:50:28,440
If it's not learning, what was it?

963
00:50:28,440 --> 00:50:33,730
Well, this was actually
good generalization.

964
00:50:33,730 --> 00:50:35,890
And it's an important building block.

965
00:50:35,890 --> 00:50:38,410
Because you never will
have access to this.

966
00:50:38,410 --> 00:50:41,340
If I gave you this as the condition,
then you say:

967
00:50:41,340 --> 00:50:43,690
A quantity that I will never
know is close to 0.

968
00:50:43,690 --> 00:50:45,960
Thank you very much!

969
00:50:45,960 --> 00:50:50,390
But now, with the theory, I was able to
tell you: you have a window on E_out

970
00:50:50,390 --> 00:50:56,450
by dealing with E_in, if you have the
right checks in place that we

971
00:50:56,450 --> 00:50:59,930
developed vaguely as the number
of hypotheses is not too big.

972
00:50:59,930 --> 00:51:03,380
And we will define it very, very
accurately when we get

973
00:51:03,380 --> 00:51:04,730
to the theory part.

974
00:51:04,730 --> 00:51:09,290
So if you have that, all of a sudden,
E_in is an important quantity.

975
00:51:09,290 --> 00:51:13,510
Because now, it acts as a proxy
for E_out that you don't know.

976
00:51:13,510 --> 00:51:17,510
So this is not a total waste, but
it's only half the story.

977
00:51:17,510 --> 00:51:21,500
The full story of learning
has two questions.

978
00:51:21,500 --> 00:51:25,930
And if you look at this slide, and
remember that this is always the

979
00:51:25,930 --> 00:51:28,460
case the learning problem is posed,

980
00:51:28,460 --> 00:51:32,230
you will dismiss a lot of misconceptions
of-- learning is

981
00:51:32,230 --> 00:51:33,620
impossible, learning is possible.

982
00:51:33,620 --> 00:51:36,190
You'll find all kinds of results
over the literature.

983
00:51:36,190 --> 00:51:37,440
So here's the deal.

984
00:51:37,440 --> 00:51:39,890


985
00:51:39,890 --> 00:51:44,490
This quantity patently
is: we learned well.

986
00:51:44,490 --> 00:51:46,330
That's what it means, right?

987
00:51:46,330 --> 00:51:51,100
So now, we are going to achieve
this through two conditions.

988
00:51:51,100 --> 00:51:55,290
The first condition is the one
we developed using Hoeffding.

989
00:51:55,290 --> 00:51:58,410
E_in is close to E_out.

990
00:51:58,410 --> 00:52:05,330
The second condition is: E_in is small.

991
00:52:05,330 --> 00:52:09,070
You put them together, and
you have the learning.

992
00:52:09,070 --> 00:52:12,070
And you can see the difference
between the two.

993
00:52:12,070 --> 00:52:14,580
This is a theoretical result.

994
00:52:14,580 --> 00:52:16,040
This is a practical result.

995
00:52:16,040 --> 00:52:16,710
E_in,

996
00:52:16,710 --> 00:52:17,580
I know E_in.

997
00:52:17,580 --> 00:52:21,150
I can try to use linear regression, or
something else, to knock this down and

998
00:52:21,150 --> 00:52:23,170
get it as close to 0 as possible.

999
00:52:23,170 --> 00:52:26,650
And indeed, if you look at where we
handled these questions, we didn't

1000
00:52:26,650 --> 00:52:28,710
explicitly say the questions
in this form.

1001
00:52:28,710 --> 00:52:32,570
But we already covered
them in two lectures.

1002
00:52:32,570 --> 00:52:36,920
This was the subject of
Lecture 2, right?

1003
00:52:36,920 --> 00:52:42,320
Hoeffding was all about the fact
that E_in is close to E_out.

1004
00:52:42,320 --> 00:52:45,270
This was the subject of Lecture 3.

1005
00:52:45,270 --> 00:52:49,340
We had data, and we wanted to get
the in-sample error to be small.

1006
00:52:49,340 --> 00:52:52,430
And we looked for techniques
to do that.

1007
00:52:52,430 --> 00:52:59,130
So now, because this is important,
let's put it in a box.

1008
00:52:59,130 --> 00:53:02,910
Learning reduces to two questions.

1009
00:53:02,910 --> 00:53:05,310
First question:

1010
00:53:05,310 --> 00:53:09,860
can we make sure that the out-of-sample
performance is close

1011
00:53:09,860 --> 00:53:12,830
enough to the in-sample performance?

1012
00:53:12,830 --> 00:53:18,130
This is a theoretical question, and we
are going to spend two weeks answering

1013
00:53:18,130 --> 00:53:23,010
this question.

1014
00:53:23,010 --> 00:53:24,510
Second one:

1015
00:53:24,510 --> 00:53:28,430
can we make the in-sample
error small enough?

1016
00:53:28,430 --> 00:53:34,120
This is a practical question, and we're
going to spend four weeks doing

1017
00:53:34,120 --> 00:53:37,480
this one.

1018
00:53:37,480 --> 00:53:41,340
And then, by the way, at the end, we'll
have one week to reflect.

1019
00:53:41,340 --> 00:53:44,450
And it's always sweet to reflect
when you have a concrete

1020
00:53:44,450 --> 00:53:46,540
ground to stand on.

1021
00:53:46,540 --> 00:53:50,290
We can do all the philosophy in the
world, and we will have very concrete

1022
00:53:50,290 --> 00:53:54,360
mathematics, very concrete algorithms,
and very concrete results on real

1023
00:53:54,360 --> 00:53:58,400
data, to know that what we're talking
about means something.

1024
00:53:58,400 --> 00:54:00,420
That's the plan.

1025
00:54:00,420 --> 00:54:04,140
Now, let me just make a small
comment about this one.

1026
00:54:04,140 --> 00:54:08,960
Small enough has been
close to 0 so far.

1027
00:54:08,960 --> 00:54:13,040
There is a very important class of
applications where there is no way

1028
00:54:13,040 --> 00:54:17,690
under the sun that you'll get
an out-of-sample performance close to 0,

1029
00:54:17,690 --> 00:54:19,040
anywhere near 0.

1030
00:54:19,040 --> 00:54:23,670
And by proxy, simply, E_in
will not also be 0.

1031
00:54:23,670 --> 00:54:26,030
And I'll give you a very
simple example.

1032
00:54:26,030 --> 00:54:30,120
Let's say that you're doing financial
forecasting, trying to detect whether

1033
00:54:30,120 --> 00:54:32,980
the market's going up or down.

1034
00:54:32,980 --> 00:54:36,190
Under idealized conditions,
this is impossible.

1035
00:54:36,190 --> 00:54:40,110
That data is purely noisy, and
there's nothing to learn.

1036
00:54:40,110 --> 00:54:44,350
The fact that the conditions are not
ideal makes hedge funds make money

1037
00:54:44,350 --> 00:54:45,110
because of that.

1038
00:54:45,110 --> 00:54:47,580
They exploit a little
bit of inefficiency.

1039
00:54:47,580 --> 00:54:50,800
But they don't get it right
100% of the time.

1040
00:54:50,800 --> 00:54:53,540
They don't get it right
70% of the time.

1041
00:54:53,540 --> 00:54:58,360
They will be very, very happy if they
get it right 53% of the time,

1042
00:54:58,360 --> 00:55:00,960
consistently.

1043
00:55:00,960 --> 00:55:04,180
Under those conditions, you
will make a lot of money.

1044
00:55:04,180 --> 00:55:06,990
So the out-of-sample error here,
that we're trying to do, is

1045
00:55:06,990 --> 00:55:08,630
very close to a half.

1046
00:55:08,630 --> 00:55:13,730
It's 47% If you get
an out-of-sample error,

1047
00:55:13,730 --> 00:55:17,010
so the correct is 53%,
the error is 47%.

1048
00:55:17,010 --> 00:55:20,840
So you can get as small as possible, in
some applications, to be not really

1049
00:55:20,840 --> 00:55:23,850
near 0 at all, but actually
closer to the half.

1050
00:55:23,850 --> 00:55:28,350
As long as you know for a fact, or at
least have the theoretical guarantee,

1051
00:55:28,350 --> 00:55:33,860
that what you're seeing in-sample, when
you add the Hoeffding allowance,

1052
00:55:33,860 --> 00:55:38,260
if you will, that the out-of-sample will
be comfortably-- error smaller than

1053
00:55:38,260 --> 00:55:40,790
a half consistently, you
are in business.

1054
00:55:40,790 --> 00:55:44,700
If you don't have the Hoeffding
guarantee, then you

1055
00:55:44,700 --> 00:55:46,970
are so happy in-sample.

1056
00:55:46,970 --> 00:55:50,210
You get the stock market
right 75% of the time.

1057
00:55:50,210 --> 00:55:52,130
You think you're going to make money.

1058
00:55:52,130 --> 00:55:55,230
And then, when you look at the jump from
E_in to E_out, you find that the

1059
00:55:55,230 --> 00:55:59,002
error bar is that big, and
you are in trouble.

1060
00:55:59,002 --> 00:56:02,840


1061
00:56:02,840 --> 00:56:06,220
Let me talk about what the theory that
we're going to cover in the next two

1062
00:56:06,220 --> 00:56:10,090
weeks will achieve, and
then I will stop.

1063
00:56:10,090 --> 00:56:14,790
This is a typical figure that
you are going to get.

1064
00:56:14,790 --> 00:56:19,590
Theory deals with in-sample error
and out-of-sample error.

1065
00:56:19,590 --> 00:56:22,400
Let me actually magnify it.

1066
00:56:22,400 --> 00:56:24,450
OK.

1067
00:56:24,450 --> 00:56:30,090
We will see the behavior of in-sample
error as you get the model

1068
00:56:30,090 --> 00:56:33,600
to be more and more elaborate, which
will be measured by a quantity which

1069
00:56:33,600 --> 00:56:35,440
we are going to call the VC dimension.

1070
00:56:35,440 --> 00:56:38,650
You will find that there are certain
behaviors of the in-sample, and the

1071
00:56:38,650 --> 00:56:41,070
out-of-sample, and 
the model complexity.

1072
00:56:41,070 --> 00:56:44,670
And all of the things that appear
in this figure will get a formal

1073
00:56:44,670 --> 00:56:48,730
definition, and an ability to evaluate
them when we get the theory.

1074
00:56:48,730 --> 00:56:50,200
So it is worthwhile.

1075
00:56:50,200 --> 00:56:55,790
But if you summarize what the theory
does, there are two steps that are the

1076
00:56:55,790 --> 00:56:57,050
most important.

1077
00:56:57,050 --> 00:57:01,310
The first one, which is the most
remarkable result in the theory of

1078
00:57:01,310 --> 00:57:05,160
learning, is that we are going to
characterize the feasibility of

1079
00:57:05,160 --> 00:57:10,710
learning for the case where--
infinite M, remember what M was?

1080
00:57:10,710 --> 00:57:13,250
M was the number of hypotheses.

1081
00:57:13,250 --> 00:57:16,550
We worked with a finite hypothesis set,
in order to be able to work with

1082
00:57:16,550 --> 00:57:17,710
simple Hoeffding.

1083
00:57:17,710 --> 00:57:21,280
And we realized that the bigger
M is, the looser the bound.

1084
00:57:21,280 --> 00:57:24,240
And if M goes too big, the
bound is meaningless.

1085
00:57:24,240 --> 00:57:27,400
So if M is infinity, we are toast.

1086
00:57:27,400 --> 00:57:31,140
So now, we would like to be able to find
a counterpart to able to take

1087
00:57:31,140 --> 00:57:35,740
an infinite hypothesis set, like every
hypothesis set we have seen so far--

1088
00:57:35,740 --> 00:57:38,050
perceptron, the linear
regression model.

1089
00:57:38,050 --> 00:57:40,450
All of these are infinite
hypotheses.

1090
00:57:40,450 --> 00:57:45,880
And we are going to try to find a way
to deal with infinite hypotheses.

1091
00:57:45,880 --> 00:57:47,900
This is the bulk of the development.

1092
00:57:47,900 --> 00:57:52,590
And that is, we'll end up-- we are
going to measure the model not by the

1093
00:57:52,590 --> 00:57:56,800
number of hypotheses, but by a single
parameter which tells us the

1094
00:57:56,800 --> 00:57:58,460
sophistication of the model.

1095
00:57:58,460 --> 00:58:02,080
And that sophistication will reflect
the out-of-sample performance as it

1096
00:58:02,080 --> 00:58:04,740
relates to the in-sample performance.

1097
00:58:04,740 --> 00:58:08,150
Once we do this, lots of doors open.

1098
00:58:08,150 --> 00:58:11,380
So we're going to characterize
a tradeoff that we observed on and off

1099
00:58:11,380 --> 00:58:13,630
as we went through the lectures.

1100
00:58:13,630 --> 00:58:18,350
We realized that we would like our
model, the hypothesis set, to be

1101
00:58:18,350 --> 00:58:21,840
elaborate, in order to be
able to fit the data.

1102
00:58:21,840 --> 00:58:24,730
The more parameters you have, the more
likely you are going to fit the data

1103
00:58:24,730 --> 00:58:25,550
and get here.

1104
00:58:25,550 --> 00:58:29,800
So the E_in goes down if you
use more complex models.

1105
00:58:29,800 --> 00:58:33,300
We also suspected that, if you make the
model more complex-- the same

1106
00:58:33,300 --> 00:58:38,400
direction, the discrepancy between E_out
and E_in gets worse and worse.

1107
00:58:38,400 --> 00:58:44,750
E_in tracks E_out much more loosely
than it used to.

1108
00:58:44,750 --> 00:58:48,960
Now, the good news from the theory is
that this will be pinned down so

1109
00:58:48,960 --> 00:58:55,580
concretely that we are going to derive
techniques from this that will make

1110
00:58:55,580 --> 00:58:57,910
a lot of difference in the
practical learning.

1111
00:58:57,910 --> 00:59:01,260
Regularization is a direct
result of this.

1112
00:59:01,260 --> 00:59:05,540
And without regularization, you
basically cannot do machine learning,

1113
00:59:05,540 --> 00:59:08,080
other than extremely naively.

1114
00:59:08,080 --> 00:59:12,420
So this will set the foundation for
a practical method that is used in

1115
00:59:12,420 --> 00:59:15,050
almost every machine learning
problem you will have.

1116
00:59:15,050 --> 00:59:17,550
So it's worth really knowing.

1117
00:59:17,550 --> 00:59:20,800
Now, I will stop here.

1118
00:59:20,800 --> 00:59:22,000
And we'll take questions.

1119
00:59:22,000 --> 00:59:24,080
And we'll start the theory next time.

1120
00:59:24,080 --> 00:59:26,090
Please, get ready.

1121
00:59:26,090 --> 00:59:30,690
Do your exercise, and get ready for two
weeks' worth of very interesting

1122
00:59:30,690 --> 00:59:31,940
derivation.

1123
00:59:31,940 --> 00:59:36,840


1124
00:59:36,840 --> 00:59:40,710
Now, let's go to questions.

1125
00:59:40,710 --> 00:59:47,520
MODERATOR: How does P of x impact
the learning algorithm?

1126
00:59:47,520 --> 00:59:52,460
So does it matter if P of x is different in
the training and the real data set?

1127
00:59:52,460 --> 00:59:56,340
PROFESSOR: There is the
absolute impact of P of x.

1128
00:59:56,340 --> 00:59:57,950
And then, there's the relative impact.

1129
00:59:57,950 --> 00:59:59,360
You're asking about
the relative impact.

1130
00:59:59,360 --> 01:00:03,860
Let's say that I pick the training
points according to one distribution,

1131
01:00:03,860 --> 01:00:05,460
and then test the system
using another.

1132
01:00:05,460 --> 01:00:07,970
Let's answer that question first.

1133
01:00:07,970 --> 01:00:12,730
There is a correction to the theory
that takes into consideration the

1134
01:00:12,730 --> 01:00:18,620
difference between the two probability
distributions, assuming that they are

1135
01:00:18,620 --> 01:00:19,290
not extreme.

1136
01:00:19,290 --> 01:00:22,650
For example, if one probability
distribution completely vanishes, then

1137
01:00:22,650 --> 01:00:23,530
obviously there's a problem.

1138
01:00:23,530 --> 01:00:26,240
Because the points in that part of the
space will never happen, and you

1139
01:00:26,240 --> 01:00:28,810
shouldn't be hoping to learn
at all from that.

1140
01:00:28,810 --> 01:00:32,960
But there are modifications to the
theory, where you get a correction term

1141
01:00:32,960 --> 01:00:36,950
based on the difference between
the two probabilities.

1142
01:00:36,950 --> 01:00:38,280
The absolute version--

1143
01:00:38,280 --> 01:00:41,280
I don't know whether this was asked,
but let me address it anyway--

1144
01:00:41,280 --> 01:00:45,720
how does P of x affect the
learning algorithm?

1145
01:00:45,720 --> 01:00:49,870
Well, the emphasis that P of x gives
on certain parts of the space over

1146
01:00:49,870 --> 01:00:53,040
others will affect the choice
of the learning examples.

1147
01:00:53,040 --> 01:00:57,170
And if you have a limited resource
in your hypothesis set--

1148
01:00:57,170 --> 01:00:59,900
which you always have to have,
otherwise the model is too

1149
01:00:59,900 --> 01:01:01,060
complicated--

1150
01:01:01,060 --> 01:01:05,590
then there's always a compromise about
which part of the space should I try

1151
01:01:05,590 --> 01:01:07,240
to get better than the other?

1152
01:01:07,240 --> 01:01:10,020
You don't think of this explicitly,
but that's what the algorithm does

1153
01:01:10,020 --> 01:01:12,600
when it tries to satisfy
a number of examples.

1154
01:01:12,600 --> 01:01:16,420
Therefore, if you change the
probability distribution--

1155
01:01:16,420 --> 01:01:19,260
even if it's the same for both of them--
then you will end up with

1156
01:01:19,260 --> 01:01:24,310
a slightly different hypothesis that takes
into consideration the emphasis

1157
01:01:24,310 --> 01:01:25,900
of the new one.

1158
01:01:25,900 --> 01:01:28,650
Nonetheless, you are not learning
that input distribution.

1159
01:01:28,650 --> 01:01:32,850
It's just affecting your choices.

1160
01:01:32,850 --> 01:01:36,910
MODERATOR: In this discussion,
you introduced a probability of y

1161
01:01:36,910 --> 01:01:39,090
given x and probability of x.

1162
01:01:39,090 --> 01:01:44,315
Will probability of x given
y ever play a role?

1163
01:01:44,315 --> 01:01:48,520
PROFESSOR: I can imagine cases
where it plays a role,

1164
01:01:48,520 --> 01:01:52,480
where you have P of x and y,
and you ask yourself: if I get this

1165
01:01:52,480 --> 01:01:55,510
output, what is the likely input?

1166
01:01:55,510 --> 01:01:56,440
This is a role.

1167
01:01:56,440 --> 01:01:58,750
I don't know whether it's a machine
learning role or not.

1168
01:01:58,750 --> 01:02:06,070
But in general, the merging of P of x
and P of y given x in the same quantity,

1169
01:02:06,070 --> 01:02:08,340
although it's mathematically convenient,
as I mentioned, it's

1170
01:02:08,340 --> 01:02:09,430
a little bit--

1171
01:02:09,430 --> 01:02:10,320
not misleading.

1172
01:02:10,320 --> 01:02:11,920
Misleading is a strong word.

1173
01:02:11,920 --> 01:02:17,260
What you're really looking at, you
always think, I have P of y given x.

1174
01:02:17,260 --> 01:02:19,730
That's the genuine thing that
I'm trying to learn.

1175
01:02:19,730 --> 01:02:23,300
And that is an integral part
of the learning problem.

1176
01:02:23,300 --> 01:02:28,300
On the other hand, P of x plays a technical
role-- a technical role

1177
01:02:28,300 --> 01:02:29,440
that is fairly negligible.

1178
01:02:29,440 --> 01:02:34,210
It's essential for it to exist, but
it's not nearly as important as

1179
01:02:34,210 --> 01:02:35,460
P of y given x.

1180
01:02:35,460 --> 01:02:42,080


1181
01:02:42,080 --> 01:02:45,830
MODERATOR: In the case of considering the
target function as a probability

1182
01:02:45,830 --> 01:02:50,830
distribution, then what
is better to have--

1183
01:02:50,830 --> 01:02:59,840
N pairs of x and y or N y's per x?

1184
01:02:59,840 --> 01:03:02,240
PROFESSOR: I don't have
a theoretical proof for it.

1185
01:03:02,240 --> 01:03:06,800
It seems to me obvious that if you get
all the outputs corresponding to one

1186
01:03:06,800 --> 01:03:10,940
input, you are dealing with a very
specific part of the input space, and

1187
01:03:10,940 --> 01:03:15,210
you're unlikely to infer anything
about the rest of the space.

1188
01:03:15,210 --> 01:03:17,860
So the answer to the question
is that intuitively--

1189
01:03:17,860 --> 01:03:21,280
and I think it would probably be
not that difficult to prove--

1190
01:03:21,280 --> 01:03:25,790
that you get them independently rather
than get them for the same input.

1191
01:03:25,790 --> 01:03:29,390
Also, by the argument we mentioned
before, you should be choosing the

1192
01:03:29,390 --> 01:03:33,330
inputs according to the probability
distribution, the input probability

1193
01:03:33,330 --> 01:03:36,080
distribution P of x, independently.

1194
01:03:36,080 --> 01:03:40,170
So if you get all the examples according
to the same x, this really

1195
01:03:40,170 --> 01:03:44,730
means that P of x that you're using
is a delta function on that x.

1196
01:03:44,730 --> 01:03:47,470
So if you live up to the expectations,
and use the same probability

1197
01:03:47,470 --> 01:03:50,790
distribution to generate the output,
then you are in good shape.

1198
01:03:50,790 --> 01:03:54,140
But if you change the game on me, and
generate all the examples according to

1199
01:03:54,140 --> 01:03:57,280
this delta function, and then when you
want to test it, you go out and give

1200
01:03:57,280 --> 01:03:59,080
me points that I haven't seen
before, then I'm in trouble.

1201
01:03:59,080 --> 01:04:02,670


1202
01:04:02,670 --> 01:04:08,540
MODERATOR: Can you clarify what
you mean by poor generalization?

1203
01:04:08,540 --> 01:04:10,650
It's a common question.

1204
01:04:10,650 --> 01:04:12,240
PROFESSOR: This will be
part of the theory.

1205
01:04:12,240 --> 01:04:14,980
There will be a very specific quantity
we measure, which is the discrepancy

1206
01:04:14,980 --> 01:04:16,620
between E_out and E_in.

1207
01:04:16,620 --> 01:04:20,210
And we are going to call this the
generalization error.

1208
01:04:20,210 --> 01:04:23,815
And that will quantify poor
generalization or good generalization.

1209
01:04:23,815 --> 01:04:27,040


1210
01:04:27,040 --> 01:04:30,255
MODERATOR: Going back to
slide 11 and 12--

1211
01:04:30,255 --> 01:04:38,754


1212
01:04:38,754 --> 01:04:40,740
PROFESSOR: Ah, the
supermarket and the CIA.

1213
01:04:40,740 --> 01:04:47,730
MODERATOR: Yes, so you chose the numbers
1 and 10, or 1000 and 1.

1214
01:04:47,730 --> 01:04:51,720
Is there a principled way
of choosing these numbers?

1215
01:04:51,720 --> 01:04:56,570
PROFESSOR: The principled way
is to estimate the cost of this

1216
01:04:56,570 --> 01:05:00,200
occurrence, and then translate
it into those.

1217
01:05:00,200 --> 01:05:01,680
This was only an illustration.

1218
01:05:01,680 --> 01:05:04,020
And I wasn't really interested
in the 1 or 10.

1219
01:05:04,020 --> 01:05:08,490
I was only interested in making the
point crisp, that the error measure is

1220
01:05:08,490 --> 01:05:13,500
different between two application
domains for exactly the same system--

1221
01:05:13,500 --> 01:05:17,130
the same system as in machine learning
system, same training data, same

1222
01:05:17,130 --> 01:05:18,140
target function.

1223
01:05:18,140 --> 01:05:20,340
But the error measure can be
different depending on the

1224
01:05:20,340 --> 01:05:21,990
application domain.

1225
01:05:21,990 --> 01:05:27,080
So in this case, indeed, we can actually
go and see, for example,

1226
01:05:27,080 --> 01:05:31,260
the loss of revenue by giving
an unwarranted discount for the

1227
01:05:31,260 --> 01:05:35,880
supermarket, and the probability that
the customer will be annoyed, and

1228
01:05:35,880 --> 01:05:39,490
lost revenue because of the customer,
and actually come up with the right

1229
01:05:39,490 --> 01:05:42,690
balance between false accept and false
reject for the supermarket.

1230
01:05:42,690 --> 01:05:45,530
It may not be 10, but it will be--

1231
01:05:45,530 --> 01:05:47,950
definitely, the number that is 10
here would be bigger than the

1232
01:05:47,950 --> 01:05:49,300
number that is 1 here.

1233
01:05:49,300 --> 01:05:54,680
Similarly, for the CIA, you can go and
ask yourself, what is the risk and how

1234
01:05:54,680 --> 01:06:01,340
much does it cost, versus the lost time
for the employees by trying the system

1235
01:06:01,340 --> 01:06:04,350
again, and then come up with a more
principled way of doing it.

1236
01:06:04,350 --> 01:06:07,840
But that was not really the crux
of what I'm doing here.

1237
01:06:07,840 --> 01:06:12,570
I was only making the point that
they are different, that's all.

1238
01:06:12,570 --> 01:06:25,290
MODERATOR: Once the theory is
explained, will it quantify the errors

1239
01:06:25,290 --> 01:06:30,360
that result from not knowing parts of P
of x, especially if P of x has maybe

1240
01:06:30,360 --> 01:06:31,970
long tails and things like that?

1241
01:06:31,970 --> 01:06:36,640
PROFESSOR: P of x has
been assumed to be

1242
01:06:36,640 --> 01:06:38,930
an unknown function.

1243
01:06:38,930 --> 01:06:44,830
And I only used it as a utility to
invoke a probabilistic setup.

1244
01:06:44,830 --> 01:06:47,430
There are no assumptions about P of x.

1245
01:06:47,430 --> 01:06:52,450
As long as you pick the points from the
same distribution to train as to

1246
01:06:52,450 --> 01:06:56,320
test, everything that I said, and
I will say during the theory

1247
01:06:56,320 --> 01:06:58,420
part, will be valid.

1248
01:06:58,420 --> 01:07:04,130
If it's a long tail, it's a long tail
for training and for testing.

1249
01:07:04,130 --> 01:07:06,780
The probability of getting
something from--

1250
01:07:06,780 --> 01:07:12,070
let's say if it's a heavy tail and I get
something that is outlier, I will

1251
01:07:12,070 --> 01:07:12,830
get a certain error.

1252
01:07:12,830 --> 01:07:15,900
I will get an in-sample error and
I'll get an out-of-sample error.

1253
01:07:15,900 --> 01:07:20,200
I basically don't worry about the
structure of P of x, because I'm

1254
01:07:20,200 --> 01:07:20,900
assuming it's unknown.

1255
01:07:20,900 --> 01:07:24,250
And I'm assuming that, in the course
of supervised learning, I'm not

1256
01:07:24,250 --> 01:07:25,500
going to learn it.

1257
01:07:25,500 --> 01:07:30,510


1258
01:07:30,510 --> 01:07:36,910
MODERATOR: What happens in the case
that both the false positives and

1259
01:07:36,910 --> 01:07:40,400
negatives have higher values?

1260
01:07:40,400 --> 01:07:42,540
PROFESSOR: If you scale both
of them up, it makes no

1261
01:07:42,540 --> 01:07:43,490
difference whatsoever.

1262
01:07:43,490 --> 01:07:46,390
Then, the error measure is scaled
up, and you're minimizing it.

1263
01:07:46,390 --> 01:07:48,830
So it's just a constant
multiplied by it.

1264
01:07:48,830 --> 01:07:52,850
If they are scaled relative to each
other, then obviously the emphasis on

1265
01:07:52,850 --> 01:07:54,140
the system changes,

1266
01:07:54,140 --> 01:07:58,460
trying to get more false positives and
less false negatives, or vice versa.

1267
01:07:58,460 --> 01:08:01,880
And that's what happens between
these two examples.

1268
01:08:01,880 --> 01:08:05,770
For the supermarket, here we are
trying not to reject customers.

1269
01:08:05,770 --> 01:08:10,720
And in the CIA case, we are trying not
to accept people who are intruders.

1270
01:08:10,720 --> 01:08:14,870
MODERATOR: There's also a question of
reiterating the relation of P of x

1271
01:08:14,870 --> 01:08:16,770
to Hoeffding Inequality.

1272
01:08:16,770 --> 01:08:21,800
PROFESSOR: The Hoeffding
Inequality was based on the bin.

1273
01:08:21,800 --> 01:08:24,819
The bin had marbles, and we picked them
according to some probability

1274
01:08:24,819 --> 01:08:26,330
which we labeled as--

1275
01:08:26,330 --> 01:08:28,990
it's a Bernoulli trail, so
it's a binary outcome.

1276
01:08:28,990 --> 01:08:31,609
And the probability was mu.

1277
01:08:31,609 --> 01:08:34,080
The bin became the input space.

1278
01:08:34,080 --> 01:08:37,210
The input space, when we started talking
about machine learning, did not

1279
01:08:37,210 --> 01:08:38,359
have a probability distribution.

1280
01:08:38,359 --> 01:08:40,520
It was just a set.

1281
01:08:40,520 --> 01:08:43,960
So in order to be able to invoke the
probabilistic aspect, we needed to put

1282
01:08:43,960 --> 01:08:48,649
a probability distribution over the
input space, such that when you

1283
01:08:48,649 --> 01:08:51,370
you create green and red
marbles according to

1284
01:08:51,370 --> 01:08:54,270
agreement/disagreement, and the input
space becomes a bin, there is

1285
01:08:54,270 --> 01:08:59,250
a probability that goes with it for
picking red versus green marbles.

1286
01:08:59,250 --> 01:09:01,830
It doesn't matter, because any
probability you put will

1287
01:09:01,830 --> 01:09:03,359
correspond to some mu.

1288
01:09:03,359 --> 01:09:04,600
And then, you have the rest of it.

1289
01:09:04,600 --> 01:09:07,810
And we know that the Hoeffding
Inequality is independent of the--

1290
01:09:07,810 --> 01:09:11,479
the bound on the right-hand side is
independent of the value of mu.

1291
01:09:11,479 --> 01:09:14,600
So any old probability will
do-- will do what?

1292
01:09:14,600 --> 01:09:21,319
Will do the legitimization of the
learning problem as far as the

1293
01:09:21,319 --> 01:09:23,210
probabilistic approach is concerned.

1294
01:09:23,210 --> 01:09:27,970
Obviously, we can enter a discussion
about the probability being

1295
01:09:27,970 --> 01:09:31,410
concentrated or spread out, or
parts of the space being 0.

1296
01:09:31,410 --> 01:09:34,960
All of that is good and valid, except
that it doesn't affect the basic

1297
01:09:34,960 --> 01:09:38,890
question, which is to make sure
that learning is feasible in

1298
01:09:38,890 --> 01:09:40,460
a probabilistic sense.

1299
01:09:40,460 --> 01:09:44,140
Any P of x will achieve that.

1300
01:09:44,140 --> 01:09:45,300
MODERATOR: A clarification--

1301
01:09:45,300 --> 01:09:50,140
some people are asking to simplify
the case of a squared error measure

1302
01:09:50,140 --> 01:09:52,620
and the closed-form solution.

1303
01:09:52,620 --> 01:09:57,410
PROFESSOR: This actually
goes to the review.

1304
01:09:57,410 --> 01:10:03,950
Let me go to the review one, because
this is from last lecture.

1305
01:10:03,950 --> 01:10:11,260
There is an algorithm that we
derived for linear regression.

1306
01:10:11,260 --> 01:10:15,580
And the algorithm was based on
minimizing squared error.

1307
01:10:15,580 --> 01:10:19,080
Remember that we took a gradient, and
we took advantage of the form being

1308
01:10:19,080 --> 01:10:22,020
squared error in order for the thing
to be differentiable, and for the

1309
01:10:22,020 --> 01:10:23,850
derivative to have a simple form.

1310
01:10:23,850 --> 01:10:29,610
And that simple form is what ended up
in getting the formula for w at the

1311
01:10:29,610 --> 01:10:33,890
bottom, which is X transposed X, inverse
of that, times X transposed y,

1312
01:10:33,890 --> 01:10:39,540
as a simple closed-form solution for
the final hypothesis of linear

1313
01:10:39,540 --> 01:10:40,550
regression.

1314
01:10:40,550 --> 01:10:44,630
So in that case, it is the squared
error measure, that defines linear

1315
01:10:44,630 --> 01:10:47,880
regression, that enabled us to
find such a simple solution.

1316
01:10:47,880 --> 01:10:52,330
If you take another measure, you may
or may not get a simple solution.

1317
01:10:52,330 --> 01:10:54,100
But for sure, in this case, we got it.

1318
01:10:54,100 --> 01:10:57,030
And there are definitely error measures
that you can put, where you

1319
01:10:57,030 --> 01:10:59,010
cannot find a simple solution
like this one.

1320
01:10:59,010 --> 01:11:03,840


1321
01:11:03,840 --> 01:11:13,630
MODERATOR: Going back to the problem
of the CIA and the supermarket, if the

1322
01:11:13,630 --> 01:11:20,590
probability of y equals +1, and y equals
-1, is not balanced, should

1323
01:11:20,590 --> 01:11:27,990
you do something regarding P of x to
have a correct estimate of your error?

1324
01:11:27,990 --> 01:11:31,230
PROFESSOR: Probability of
y, in the absolute, depends on two

1325
01:11:31,230 --> 01:11:35,080
things-- probability of y given
x and probability of x.

1326
01:11:35,080 --> 01:11:38,270
So if you put them together, and you get
an imbalance in the probability of

1327
01:11:38,270 --> 01:11:43,540
y, this means that the building
quantities, which is P of x and P of y

1328
01:11:43,540 --> 01:11:45,310
given x, are what affected that.

1329
01:11:45,310 --> 01:11:49,020
And those quantities will definitely
affect the learning process.

1330
01:11:49,020 --> 01:11:52,330
So the answer-- if you want to answer
what happens when y is not

1331
01:11:52,330 --> 01:11:54,460
balanced, go back and see
what gave rise to it.

1332
01:11:54,460 --> 01:11:58,620
And then, you will be able to find the
answer more directly linked through

1333
01:11:58,620 --> 01:12:03,050
the quantities that directly affect
the learning process.

1334
01:12:03,050 --> 01:12:09,660
MODERATOR: And again, on these costs, is
there ever a case where you can use

1335
01:12:09,660 --> 01:12:16,830
rewards instead of costs, as in
assigning negative values to--

1336
01:12:16,830 --> 01:12:19,520
PROFESSOR: Yeah, they
are equivalent, indeed.

1337
01:12:19,520 --> 01:12:23,360
You are just maximizing the reward
or minimizing the punishment.

1338
01:12:23,360 --> 01:12:25,100
I think it's just two ways of
looking at the same thing.

1339
01:12:25,100 --> 01:12:30,700


1340
01:12:30,700 --> 01:12:31,910
MODERATOR: A question--

1341
01:12:31,910 --> 01:12:37,030
In the example of the bins, when you
say there's a bin that becomes the

1342
01:12:37,030 --> 01:12:40,390
input space, does the input space
include just the training data points,

1343
01:12:40,390 --> 01:12:44,250
or does input space include
all possible points?

1344
01:12:44,250 --> 01:12:47,370
PROFESSOR: The input space
includes all possible points, but

1345
01:12:47,370 --> 01:12:49,920
includes only the input parts
of those possible points.

1346
01:12:49,920 --> 01:12:53,780
If you look at the examples, the
training data, there is x and y.

1347
01:12:53,780 --> 01:12:57,430
And the input space deals
only with the x part.

1348
01:12:57,430 --> 01:13:00,860
When you talk about the input space in
general, it covers all possible x's.

1349
01:13:00,860 --> 01:13:04,120
When you talk about the training data,
you are talking about the x's that

1350
01:13:04,120 --> 01:13:08,263
were picked as a training
set, N of them.

1351
01:13:08,263 --> 01:13:12,120


1352
01:13:12,120 --> 01:13:20,460
MODERATOR: Regarding the
transformation, what relation does phi

1353
01:13:20,460 --> 01:13:24,420
have to something like principal
component analysis?

1354
01:13:24,420 --> 01:13:27,580
PROFESSOR: This is
a different subject.

1355
01:13:27,580 --> 01:13:32,680
So there is a subject of processing
the input, in order to make it more

1356
01:13:32,680 --> 01:13:35,470
compact, in order to get rid of
irrelevant parts and whatnot.

1357
01:13:35,470 --> 01:13:39,350
And that is a legitimate processing
step, but it's not what I

1358
01:13:39,350 --> 01:13:40,950
was alluding to here.

1359
01:13:40,950 --> 01:13:46,060
What I was alluding to here, in the
nonlinear transformation, is an ability

1360
01:13:46,060 --> 01:13:51,730
to implement more sophisticated
hypotheses using the same simple

1361
01:13:51,730 --> 01:13:54,350
method, which is the
linear method.

1362
01:13:54,350 --> 01:13:57,660
And therefore, the transformation
is with a view to that.

1363
01:13:57,660 --> 01:14:01,160
Not with a view to getting rid of
some of the artifacts

1364
01:14:01,160 --> 01:14:02,200
of the input.

1365
01:14:02,200 --> 01:14:04,470
However, feature extraction
is feature extraction.

1366
01:14:04,470 --> 01:14:08,350
You can think of the nonlinear
transformation as feature extraction.

1367
01:14:08,350 --> 01:14:11,750
You can also think of other methods for
processing the input, and getting

1368
01:14:11,750 --> 01:14:16,860
rid of some of the irrelevances,
also as feature extraction.

1369
01:14:16,860 --> 01:14:20,240
And if you think of the example of the
handwritten digits that we talked

1370
01:14:20,240 --> 01:14:25,740
about, we started with the full image,
which I think was 257 bits' worth,

1371
01:14:25,740 --> 01:14:27,140
counting the constant 1.

1372
01:14:27,140 --> 01:14:31,540
And then, we ended up with only
two features plus the 1.

1373
01:14:31,540 --> 01:14:34,550
The two features where symmetry
and intensity.

1374
01:14:34,550 --> 01:14:37,980
And in some sense, these are
informative features.

1375
01:14:37,980 --> 01:14:41,470
And in that case, you lost some
information about the input.

1376
01:14:41,470 --> 01:14:44,440
But hopefully what you lost
is not relevant.

1377
01:14:44,440 --> 01:14:48,560
The principal component analysis, and
other methods, are fairly systematic to

1378
01:14:48,560 --> 01:14:50,020
detect that without attaching meaning.

1379
01:14:50,020 --> 01:14:51,830
So you don't really study the subject.

1380
01:14:51,830 --> 01:14:57,110
You just apply a standard method that
will pick the most informative

1381
01:14:57,110 --> 01:15:01,690
directions in the input space, in
the input representation space.

1382
01:15:01,690 --> 01:15:03,590
And that will be your goal.

1383
01:15:03,590 --> 01:15:04,800
So it's a different subject.

1384
01:15:04,800 --> 01:15:07,020
It's not related to nonlinear
transformation, per se.

1385
01:15:07,020 --> 01:15:09,520


1386
01:15:09,520 --> 01:15:14,210
MODERATOR: Regarding the error measures,
so the squared error measure is used

1387
01:15:14,210 --> 01:15:16,300
mainly for mathematical convenience.

1388
01:15:16,300 --> 01:15:24,520
Do we lose too much by replacing it for
something like just an absolute value?

1389
01:15:24,520 --> 01:15:26,845
PROFESSOR: You
lose the optimization.

1390
01:15:26,845 --> 01:15:30,190
Squared error is this way.

1391
01:15:30,190 --> 01:15:34,060
And that is nice and smooth, and
has all kinds of properties.

1392
01:15:34,060 --> 01:15:36,910
You take the absolute value,
and you have this guy.

1393
01:15:36,910 --> 01:15:39,190
And the edge is really bad news.

1394
01:15:39,190 --> 01:15:44,220
All of a sudden, it becomes combinatorial
optimization instead of

1395
01:15:44,220 --> 01:15:45,130
a smooth function.

1396
01:15:45,130 --> 01:15:47,650
So yes, you lose in terms
of optimization.

1397
01:15:47,650 --> 01:15:54,580
If you have a specific merit for using
the absolute value-- that is, the guy

1398
01:15:54,580 --> 01:15:57,650
tells you that this is my function, and
I want to make sure that this is

1399
01:15:57,650 --> 01:15:58,620
what you minimize--

1400
01:15:58,620 --> 01:16:01,240
then we have to bite the bullet
and work through it.

1401
01:16:01,240 --> 01:16:05,180
But if you're making an analytic choice
just for the heck of it, you

1402
01:16:05,180 --> 01:16:08,590
might as well pick something that is
friendly either to the concept or to

1403
01:16:08,590 --> 01:16:09,840
the optimizer.

1404
01:16:09,840 --> 01:16:12,200


1405
01:16:12,200 --> 01:16:19,370
MODERATOR: So this question regarding
the use of a linear model,

1406
01:16:19,370 --> 01:16:23,290
when you have P of y given x,
that represents f of x.

1407
01:16:23,290 --> 01:16:26,360
And then, f of x would be the
result of w transposed--

1408
01:16:26,360 --> 01:16:29,710


1409
01:16:29,710 --> 01:16:31,720
hello?

1410
01:16:31,720 --> 01:16:38,920
OK, so if this is the case, then when
you subtract y by f of x, does it mean

1411
01:16:38,920 --> 01:16:41,620
you have a P of y of x shape?

1412
01:16:41,620 --> 01:16:42,670
PROFESSOR: The target is f of x.

1413
01:16:42,670 --> 01:16:47,480
The target is not w transposed x.
w transposed x is the final hypothesis

1414
01:16:47,480 --> 01:16:50,330
that is my attempt to approximate
the target function.

1415
01:16:50,330 --> 01:16:53,570
So I was talking about target function
versus target distribution, even

1416
01:16:53,570 --> 01:16:55,400
without any learning taking place.

1417
01:16:55,400 --> 01:16:56,530
Someone has a target function.

1418
01:16:56,530 --> 01:16:57,470
It's noisy.

1419
01:16:57,470 --> 01:16:59,600
I'm telling them that they
can model it this way--

1420
01:16:59,600 --> 01:17:03,430
take the expected value, assuming it's
a numerical function-- the expected

1421
01:17:03,430 --> 01:17:05,690
value under the probability
distribution.

1422
01:17:05,690 --> 01:17:09,160
You will get the average
y given a particular x.

1423
01:17:09,160 --> 01:17:10,400
That's a function.

1424
01:17:10,400 --> 01:17:12,030
So your call this f of x.

1425
01:17:12,030 --> 01:17:18,130
The remaining part, which is the value
of y minus that, will be pure noise in

1426
01:17:18,130 --> 01:17:20,140
the sense that it averages around 0.

1427
01:17:20,140 --> 01:17:22,350
So this was just a way
of looking at it.

1428
01:17:22,350 --> 01:17:25,990
But definitely, it does not touch
at all on linear models

1429
01:17:25,990 --> 01:17:27,230
or any other models.

1430
01:17:27,230 --> 01:17:32,030
It's a characterization of the target
function versus target distribution.

1431
01:17:32,030 --> 01:17:38,640
MODERATOR: There's a tradeoff
between complexity and the

1432
01:17:38,640 --> 01:17:39,190
performance.

1433
01:17:39,190 --> 01:17:43,980
Is there a way to simultaneously
improve the generalization as well as

1434
01:17:43,980 --> 01:17:45,310
minimize error?

1435
01:17:45,310 --> 01:17:49,060
PROFESSOR: If you sit through
the next four lectures very,

1436
01:17:49,060 --> 01:17:51,740
very attentively, you'll get the answer
to that at the end of the four

1437
01:17:51,740 --> 01:17:54,500
lectures.

1438
01:17:54,500 --> 01:17:57,200
I'm half joking, but that's
the reality of it.

1439
01:17:57,200 --> 01:17:59,630
You'll have enough tools to be able
to answer questions like that.

1440
01:17:59,630 --> 01:18:03,887


1441
01:18:03,887 --> 01:18:05,390
MODERATOR: I think that's it.

1442
01:18:05,390 --> 01:18:06,120
PROFESSOR: OK, that's it.

1443
01:18:06,120 --> 01:18:08,030
Thank you, and we'll see you next week.

1444
01:18:08,030 --> 01:18:21,635

