1
00:00:00,000 --> 00:00:02,860


2
00:00:02,860 --> 00:00:05,525
ANNOUNCER: The following program
is brought to you by Caltech.

3
00:00:05,525 --> 00:00:18,210


4
00:00:18,210 --> 00:00:21,090
YASER ABU-MOSTAFA: Welcome back.

5
00:00:21,090 --> 00:00:25,630
Last time, we introduced some important
concepts in our theoretical

6
00:00:25,630 --> 00:00:27,550
development.

7
00:00:27,550 --> 00:00:31,710
And the first concept was dichotomies.

8
00:00:31,710 --> 00:00:36,250
And the idea is that there is an input
space behind this opaque sheet, and

9
00:00:36,250 --> 00:00:38,480
there is a hypothesis that's
separating red

10
00:00:38,480 --> 00:00:40,400
regions from blue regions.

11
00:00:40,400 --> 00:00:42,550
But we don't get to see that.

12
00:00:42,550 --> 00:00:46,760
What we get to see are just the
data points, holes in that

13
00:00:46,760 --> 00:00:48,270
sheet if you will.

14
00:00:48,270 --> 00:00:52,140
And there could be very exciting stuff
happening behind that sheet, and all

15
00:00:52,140 --> 00:00:56,030
you get to see is when the boundary
crosses one of these points, and a blue

16
00:00:56,030 --> 00:00:58,790
point turns red or vice-versa.

17
00:00:58,790 --> 00:01:03,600
So if you think of the purpose for the
dichotomies, we had a problem with

18
00:01:03,600 --> 00:01:06,250
counting the number of hypotheses,
because we end up with

19
00:01:06,250 --> 00:01:07,770
a very large number.

20
00:01:07,770 --> 00:01:11,850
But if you restrict your attention to
dichotomies, which are the hypotheses

21
00:01:11,850 --> 00:01:17,020
restricted to a finite set of points,
the blue and red points here, then you

22
00:01:17,020 --> 00:01:19,640
don't have to count everything
that is happening outside.

23
00:01:19,640 --> 00:01:22,980
You only count it as different when
something different happens only on

24
00:01:22,980 --> 00:01:24,090
those points.

25
00:01:24,090 --> 00:01:27,610
So a dichotomy is a mini-hypothesis,
if you will.

26
00:01:27,610 --> 00:01:34,170
And it counts the hypotheses only
on the finite set of points.

27
00:01:34,170 --> 00:01:38,740
This resulted in a definition that
parallels the number of hypotheses,

28
00:01:38,740 --> 00:01:41,730
which is the number of dichotomies
in this case.

29
00:01:41,730 --> 00:01:43,980
So we define the growth function.

30
00:01:43,980 --> 00:01:48,230
The growth function is-- you pick
the points x_1 up to x_N.

31
00:01:48,230 --> 00:01:52,180
You pick them wisely, with a view to
maximizing the dichotomies, such that

32
00:01:52,180 --> 00:01:56,545
the number you get will be more than any
number another person gets with N

33
00:01:56,545 --> 00:01:58,540
points. That's the purpose.

34
00:01:58,540 --> 00:02:02,650
So you take your hypothesis set, which
applies to the entire input

35
00:02:02,650 --> 00:02:07,660
space, and then apply it
only to x_1 up to x_N.

36
00:02:07,660 --> 00:02:11,690
This will result in a pattern of
+1 or -1's, N of them.

37
00:02:11,690 --> 00:02:14,855
And as you vary the hypothesis within
this set, you will get another

38
00:02:14,855 --> 00:02:17,060
pattern, another pattern,
another pattern.

39
00:02:17,060 --> 00:02:20,390
So you will get a set of different
patterns that are all the dichotomies

40
00:02:20,390 --> 00:02:24,910
that can be generated by this hypothesis
set, on this set of points.

41
00:02:24,910 --> 00:02:27,520
And the number of those guys is
what we are interested in.

42
00:02:27,520 --> 00:02:30,600
It will play the role of the
number of hypotheses.

43
00:02:30,600 --> 00:02:33,220
And that is the growth function.

44
00:02:33,220 --> 00:02:37,290
Now in principle, the growth function
can be 2 to the N. You may be in

45
00:02:37,290 --> 00:02:40,690
an input space and a hypothesis set,
such that you can generate

46
00:02:40,690 --> 00:02:42,410
any pattern you want.

47
00:02:42,410 --> 00:02:46,300
However, in most of the cases, the
restriction of using hypotheses coming

48
00:02:46,300 --> 00:02:50,150
from H will result in missing
out on some of the patterns.

49
00:02:50,150 --> 00:02:52,580
Some patterns will simply
be impossible.

50
00:02:52,580 --> 00:02:55,390
And that led us to the idea
of a break point.

51
00:02:55,390 --> 00:02:58,770
For the case of a perceptron in
two dimensions, which is the case we

52
00:02:58,770 --> 00:03:03,030
studied, we realize that for four
points, there will always be a pattern

53
00:03:03,030 --> 00:03:05,430
that cannot be realized
by a perceptron.

54
00:03:05,430 --> 00:03:09,620
There is no way to have a line come
here, and separate those red points

55
00:03:09,620 --> 00:03:10,810
from the blue points.

56
00:03:10,810 --> 00:03:14,930
And any choice of four points will
also result in

57
00:03:14,930 --> 00:03:16,290
missing patterns.

58
00:03:16,290 --> 00:03:21,110
Therefore, the number k equals 4, in this
case, is defined as a break point

59
00:03:21,110 --> 00:03:22,890
for the perceptrons.

60
00:03:22,890 --> 00:03:26,720
And our theoretical goal is to take that
single number, which is the break

61
00:03:26,720 --> 00:03:31,950
point, and be able to characterize the
entire growth function for every N.

62
00:03:31,950 --> 00:03:38,080
And therefore, be able to characterize
the generalization, as we will see.

63
00:03:38,080 --> 00:03:41,690
We then talked about the maximum
number of dichotomies, under the

64
00:03:41,690 --> 00:03:43,210
constraint that there
is a break point.

65
00:03:43,210 --> 00:03:46,950
And we had an illustrative example to
tell you that, when you tell me that

66
00:03:46,950 --> 00:03:49,480
you cannot get all patterns on any--

67
00:03:49,480 --> 00:03:51,680
in this case, two points--

68
00:03:51,680 --> 00:03:55,160
that is a very strong restriction on
the number of dichotomies you can

69
00:03:55,160 --> 00:03:56,960
get on a larger number of points.

70
00:03:56,960 --> 00:03:59,350
So this is the simplest case.

71
00:03:59,350 --> 00:04:02,710
If you take any two columns, you
cannot get all four patterns.

72
00:04:02,710 --> 00:04:03,840
That's by decree.

73
00:04:03,840 --> 00:04:07,000
I'm telling you that the hypothesis
has a break point of 2.

74
00:04:07,000 --> 00:04:10,180
And then I'm asking you, under those
constraints, how many lines you can

75
00:04:10,180 --> 00:04:12,710
get, how many different
patterns you can get.

76
00:04:12,710 --> 00:04:15,370
And you go and you add them
up, and you end up in this

77
00:04:15,370 --> 00:04:16,420
case with only four.

78
00:04:16,420 --> 00:04:17,779
So you lost half of them.

79
00:04:17,779 --> 00:04:20,769
And you can see that if we have 10
points, and you apply the same

80
00:04:20,769 --> 00:04:23,820
restriction, there will be so many
lost, because now the restriction

81
00:04:23,820 --> 00:04:26,500
applies to any pair of points.

82
00:04:26,500 --> 00:04:30,140
Now, if you look at this schedule,
this does not appeal to any

83
00:04:30,140 --> 00:04:34,800
particulars of the hypothesis set or the
input space, other than the fact

84
00:04:34,800 --> 00:04:36,950
that the break point is 2.

85
00:04:36,950 --> 00:04:40,990
I could be in a situation, where the
hypothesis set cannot generate some of

86
00:04:40,990 --> 00:04:42,990
these guys for other reasons.

87
00:04:42,990 --> 00:04:46,800
But here, I'm abstracting only
a hypothesis set and an input space.

88
00:04:46,800 --> 00:04:48,990
I don't want to bother to
know more about them.

89
00:04:48,990 --> 00:04:52,240
Just tell me that they have a break
point, and I'm trying to find under

90
00:04:52,240 --> 00:04:56,110
that single constraint, how many
can I possibly have?

91
00:04:56,110 --> 00:04:58,900
And I already have, by that
combinatorial constraint,

92
00:04:58,900 --> 00:05:02,330
a restriction which is strong enough
to get me a good-enough result.

93
00:05:02,330 --> 00:05:05,640
That's good, because now I don't have
to worry about every hypothesis

94
00:05:05,640 --> 00:05:07,450
set, and every input space, you give me.

95
00:05:07,450 --> 00:05:09,030
I just ask you:
what is the break point?

96
00:05:09,030 --> 00:05:12,400
And I'm able to make a statement about
the growth function not being bigger

97
00:05:12,400 --> 00:05:13,120
than something.

98
00:05:13,120 --> 00:05:15,250
That is the key.

99
00:05:15,250 --> 00:05:19,900
We move on to today's lecture, and
the title is, properly, the Theory of

100
00:05:19,900 --> 00:05:20,760
Generalization.

101
00:05:20,760 --> 00:05:22,320
It's very theoretical.

102
00:05:22,320 --> 00:05:26,760
And today's lecture is the most
theoretical of the entire course.

103
00:05:26,760 --> 00:05:31,770
So fasten your seat belts,
and let's start!

104
00:05:31,770 --> 00:05:34,450
We have two items of business.

105
00:05:34,450 --> 00:05:38,240
The first one is to show that the growth
function, with a break point, is

106
00:05:38,240 --> 00:05:40,320
indeed polynomial.

107
00:05:40,320 --> 00:05:45,410
The second one is to show that we can
actually take that notion, the growth

108
00:05:45,410 --> 00:05:49,650
function, and put it in place of
M, the number of hypotheses,

109
00:05:49,650 --> 00:05:52,580
in Hoeffding's inequality.

110
00:05:52,580 --> 00:05:57,590
So basically, we are saying in the
first part: it's worthwhile to study

111
00:05:57,590 --> 00:05:58,830
the growth function.

112
00:05:58,830 --> 00:06:01,770
Because being polynomial will
be very advantageous.

113
00:06:01,770 --> 00:06:05,780
And then, the second one is: we can
actually do something good with it.

114
00:06:05,780 --> 00:06:07,020
We can do the replacement.

115
00:06:07,020 --> 00:06:10,170
These are the only two items.

116
00:06:10,170 --> 00:06:12,660
Let's start.

117
00:06:12,660 --> 00:06:16,240
We are going to bound the growth
function by a polynomial.

118
00:06:16,240 --> 00:06:20,880
And I just wanted to point some
of the aspects of that.

119
00:06:20,880 --> 00:06:25,360
If I say m_H of N is polynomial, it's not
that I am going to actually solve

120
00:06:25,360 --> 00:06:28,910
for the growth function, and show that
it is this particular polynomial, and

121
00:06:28,910 --> 00:06:29,780
the coefficients.

122
00:06:29,780 --> 00:06:36,130
All I am saying is that it is really
just bounded above by a polynomial.

123
00:06:36,130 --> 00:06:40,330
I don't have to get the particulars
of m_H of N, the growth function.

124
00:06:40,330 --> 00:06:42,530
I am going to just tell you that this
is less than something, less than

125
00:06:42,530 --> 00:06:43,830
something, less than a polynomial.

126
00:06:43,830 --> 00:06:47,730
That's all I need, because eventually
I am going to put this in the

127
00:06:47,730 --> 00:06:48,980
Hoeffding inequality.

128
00:06:48,980 --> 00:06:51,890
And as long as it's bounded by
a polynomial, I am in business.

129
00:06:51,890 --> 00:06:53,920
Because the negative exponential
will kill it, as we

130
00:06:53,920 --> 00:06:55,560
discussed, and we are OK.

131
00:06:55,560 --> 00:06:58,010
So we can be a bit loose, which
is very good in theory.

132
00:06:58,010 --> 00:07:01,690
Because now you leave a lot
of artifacts that you

133
00:07:01,690 --> 00:07:02,680
don't need to study.

134
00:07:02,680 --> 00:07:06,440
And just talk about the upper bound in
the general case, and still get what

135
00:07:06,440 --> 00:07:07,690
you want to get.

136
00:07:07,690 --> 00:07:09,610


137
00:07:09,610 --> 00:07:12,820
The key quantity we are going to use,
which is a purely combinatorial

138
00:07:12,820 --> 00:07:17,910
quantity, we are going to
call it B of N and k.

139
00:07:17,910 --> 00:07:22,050
This is exactly the quantity we
were seeking in the puzzle.

140
00:07:22,050 --> 00:07:23,970
I give you N points.

141
00:07:23,970 --> 00:07:28,830
I tell you that k is a break point, and
ask you: how many different patterns

142
00:07:28,830 --> 00:07:31,530
can you get under those conditions?

143
00:07:31,530 --> 00:07:35,800
In that case, we had three points
and the break point was 2.

144
00:07:35,800 --> 00:07:38,020
And we answered this question
by construction.

145
00:07:38,020 --> 00:07:42,090
We played around with the patterns until
we got it, and then we said it's 4.

146
00:07:42,090 --> 00:07:45,700
Now, as I develop the theory,
the puzzle will come up

147
00:07:45,700 --> 00:07:47,030
in one of the results.

148
00:07:47,030 --> 00:07:51,960
I would like you to keep an eye and
say which slide, and which particular

149
00:07:51,960 --> 00:07:57,390
part of the slide, addresses the very
specific puzzle we talked about.

150
00:07:57,390 --> 00:08:03,010
The definition here is the maximum
number of dichotomies on N points,

151
00:08:03,010 --> 00:08:05,400
such that they have a break point k.

152
00:08:05,400 --> 00:08:09,080
So this is N and this is k.

153
00:08:09,080 --> 00:08:13,350
And the good thing here is that I didn't
appeal to any hypothesis set, or

154
00:08:13,350 --> 00:08:14,530
any input space.

155
00:08:14,530 --> 00:08:16,820
This is a purely combinatorial
quantity.

156
00:08:16,820 --> 00:08:19,470
And because it's a combinatorial quantity,
I am going to be able to pin

157
00:08:19,470 --> 00:08:22,670
it down exactly, as it turns out.

158
00:08:22,670 --> 00:08:26,910
And now, when I pin it down exactly, you
go and you find the fanciest input

159
00:08:26,910 --> 00:08:28,930
space, and the fanciest hypothesis set.

160
00:08:28,930 --> 00:08:35,630
You pick the break point for that, and
you use that here, ridding the

161
00:08:35,630 --> 00:08:39,090
problem of all the other aspects, and
you still are able to make an upper

162
00:08:39,090 --> 00:08:39,780
bound statement.

163
00:08:39,780 --> 00:08:43,058
You can say that the growth function,
for the particular case you talked

164
00:08:43,058 --> 00:08:45,610
about, is less than or equal
to-- and just go to this

165
00:08:45,610 --> 00:08:47,790
combinatorial quantity.

166
00:08:47,790 --> 00:08:49,550
The plan is clear.

167
00:08:49,550 --> 00:08:52,890
So let's look at the bound
for B of N, k.

168
00:08:52,890 --> 00:08:54,150
And we are going to do it recursively.

169
00:08:54,150 --> 00:08:57,530
It's a very cute argument, and I am
going to build it very carefully.

170
00:08:57,530 --> 00:09:00,900
So I want your attention.

171
00:09:00,900 --> 00:09:02,160
Consider the following table.

172
00:09:02,160 --> 00:09:07,040
Very much like the puzzle, we are
going to list x_1, x_2, up to x_N.

173
00:09:07,040 --> 00:09:09,390
N points, which used
to be three points.

174
00:09:09,390 --> 00:09:13,910
And I am going to try to put as many
patterns as I can, under a constraint

175
00:09:13,910 --> 00:09:15,780
that there is a break point.

176
00:09:15,780 --> 00:09:21,430
So I will be putting the first pattern
this way, and the second pattern, and so

177
00:09:21,430 --> 00:09:24,290
on, trying to fill this table.

178
00:09:24,290 --> 00:09:31,040
Now, I am going to do a structural
analysis of this, and this will happen

179
00:09:31,040 --> 00:09:32,840
through this division.

180
00:09:32,840 --> 00:09:34,120
Let's look at it.

181
00:09:34,120 --> 00:09:37,640
Still the same problem, x_1
and x_N is my vector.

182
00:09:37,640 --> 00:09:40,540
And I am trying to fill this with
as many rows as possible, under

183
00:09:40,540 --> 00:09:42,390
a constraint of a break point.

184
00:09:42,390 --> 00:09:45,370
But now I am going to isolate
the last point.

185
00:09:45,370 --> 00:09:46,660
Why am I isolating the last point?

186
00:09:46,660 --> 00:09:48,340
Because I want a recursion.

187
00:09:48,340 --> 00:09:52,890
I want to be able to relate this fellow,
to the same fellow applied to

188
00:09:52,890 --> 00:09:54,540
smaller quantities.

189
00:09:54,540 --> 00:09:57,490
And you have seen enough of that to
realize that, if I manage to do that, I

190
00:09:57,490 --> 00:10:00,520
might be able to actually
solve for B of N and k.

191
00:10:00,520 --> 00:10:03,470
That's why I'm isolating
the last point.

192
00:10:03,470 --> 00:10:10,890
After I do the isolation, I am going
to group the rows of the big

193
00:10:10,890 --> 00:10:13,540
matrix, into some groups.

194
00:10:13,540 --> 00:10:15,990
This is just my way
of looking at things.

195
00:10:15,990 --> 00:10:17,650
I haven't changed anything.

196
00:10:17,650 --> 00:10:22,310
What I am going to do, I am going to
shuffle the rows around, after you have

197
00:10:22,310 --> 00:10:23,020
constructed them.

198
00:10:23,020 --> 00:10:27,210
So we have a full matrix now, and I am
shuffling them, and putting some guys

199
00:10:27,210 --> 00:10:29,150
in the first group.

200
00:10:29,150 --> 00:10:33,110
And the first group I
am going to call S_1.

201
00:10:33,110 --> 00:10:36,020
Here is the definition
of the group S_1.

202
00:10:36,020 --> 00:10:42,480
These are the rows that appear
only once, as far as x_1 up to

203
00:10:42,480 --> 00:10:45,500
x_N-1 are concerned.

204
00:10:45,500 --> 00:10:50,610
Well, every row in its entirety appears
only once, because these are

205
00:10:50,610 --> 00:10:51,400
different rows.

206
00:10:51,400 --> 00:10:53,410
That's how I'm constructing
the matrix.

207
00:10:53,410 --> 00:10:57,790
But if you take out the last guy, it is
conceivable that the first N minus

208
00:10:57,790 --> 00:11:02,280
1 coordinates happen twice, once with
extension -1, once with

209
00:11:02,280 --> 00:11:03,950
extension +1.

210
00:11:03,950 --> 00:11:07,050
So I am taking the guys that
go with only one extension,

211
00:11:07,050 --> 00:11:07,810
whatever it might be.

212
00:11:07,810 --> 00:11:10,860
Could be -1 or could be +1,
but not both, and putting

213
00:11:10,860 --> 00:11:12,980
them in this group.

214
00:11:12,980 --> 00:11:16,700
Fairly well defined.

215
00:11:16,700 --> 00:11:22,480
So you fill it up, and these are all the
rows that have a single extension.

216
00:11:22,480 --> 00:11:28,400
Now, you go under this, and you
define the number of rows in

217
00:11:28,400 --> 00:11:29,470
this group to be alpha.

218
00:11:29,470 --> 00:11:30,250
It is a number.

219
00:11:30,250 --> 00:11:32,510
I am just going to call it alpha.

220
00:11:32,510 --> 00:11:36,380
And you can see where this is going,
because now I'm going to claim that

221
00:11:36,380 --> 00:11:40,460
the B of N and k, which is the total
number of rows in the entire matrix,

222
00:11:40,460 --> 00:11:42,800
is alpha plus something.

223
00:11:42,800 --> 00:11:43,270
That is obvious.

224
00:11:43,270 --> 00:11:45,830
I have already taken care of alpha,
and I am going to add up the

225
00:11:45,830 --> 00:11:49,260
other stuff later on.

226
00:11:49,260 --> 00:11:51,730
So what is the other stuff?

227
00:11:51,730 --> 00:11:54,100
That is the stuff I am
going to call S_2.

228
00:11:54,100 --> 00:11:56,410
And you probably have a good
guess what these are.

229
00:11:56,410 --> 00:12:01,830
These are the guys that happen
with both patterns.

230
00:12:01,830 --> 00:12:05,980
That is, they happen with extension
+1 and with -1.

231
00:12:05,980 --> 00:12:08,060
That is disjoint from the first group.

232
00:12:08,060 --> 00:12:11,530
A typical member will
look like this.

233
00:12:11,530 --> 00:12:16,850
This is the same guy from x_1 up to
x_N-1, as it appears here.

234
00:12:16,850 --> 00:12:22,080
It just appears here with +1,
and appears here with -1.

235
00:12:22,080 --> 00:12:23,040
And I keep doing it.

236
00:12:23,040 --> 00:12:26,180
So what I'm doing, I just reorganize
the rows of the matrix to

237
00:12:26,180 --> 00:12:27,430
fall into these nice categories.

238
00:12:27,430 --> 00:12:27,980
The other guy?

239
00:12:27,980 --> 00:12:29,170
Exactly the same thing.

240
00:12:29,170 --> 00:12:34,330
So the second one corresponds to
the second one, and so on.

241
00:12:34,330 --> 00:12:37,590
Now, that covers all the rows.

242
00:12:37,590 --> 00:12:39,270
I look at x_1 up to x_N-1.

243
00:12:39,270 --> 00:12:42,580
I either have both extensions,
or one extension. That's it.

244
00:12:42,580 --> 00:12:45,650
One extension belongs to the first
group. Two extensions belong to the

245
00:12:45,650 --> 00:12:49,540
second group in both ways,
with +1 and -1.

246
00:12:49,540 --> 00:12:54,020
In terms of the counting, this has
beta rows, whatever beta might be.

247
00:12:54,020 --> 00:12:56,620
This also has beta rows, because
they're identical.

248
00:12:56,620 --> 00:13:02,520
And therefore, the number B of N and
K, which I'm interested in, is

249
00:13:02,520 --> 00:13:06,810
alpha plus 2 beta.

250
00:13:06,810 --> 00:13:07,390
That is complete.

251
00:13:07,390 --> 00:13:10,520
Just calling things names.

252
00:13:10,520 --> 00:13:15,350
So now, I am going to try to find
a handle on alphas and betas, so that I

253
00:13:15,350 --> 00:13:19,160
can find a recursion for the big
function B of N and k.

254
00:13:19,160 --> 00:13:22,880
B of N and k are the maximum
number of rows--

255
00:13:22,880 --> 00:13:30,140
patterns I can get on N points,
such that no k columns have

256
00:13:30,140 --> 00:13:32,780
all possible patterns.

257
00:13:32,780 --> 00:13:34,040
That's the definition.

258
00:13:34,040 --> 00:13:37,910
I am going to relate that to the same
quantity on smaller numbers, smaller N

259
00:13:37,910 --> 00:13:39,160
and smaller k.

260
00:13:39,160 --> 00:13:41,560


261
00:13:41,560 --> 00:13:43,980
So the first is to estimate
alpha and beta.

262
00:13:43,980 --> 00:13:46,990


263
00:13:46,990 --> 00:13:51,750
I'd like to ask you to focus on
the x_1 up to x_N-1 columns.

264
00:13:51,750 --> 00:13:57,990
And I am going to help you visually
do that, by graying out the rest.

265
00:13:57,990 --> 00:13:59,340


266
00:13:59,340 --> 00:14:02,220
Now for a moment, look at these.

267
00:14:02,220 --> 00:14:04,940
Are these rows different?

268
00:14:04,940 --> 00:14:07,750
They used to be different when
you have the extension.

269
00:14:07,750 --> 00:14:09,200
Well, let me see.

270
00:14:09,200 --> 00:14:11,480
The first group, I know they
are different, because

271
00:14:11,480 --> 00:14:13,460
they have one extension.

272
00:14:13,460 --> 00:14:17,570
If there is one which is repeated, then
it must be repeated with both

273
00:14:17,570 --> 00:14:22,520
extensions, in order to get different
rows all over, and that violates the

274
00:14:22,520 --> 00:14:23,730
condition for being here.

275
00:14:23,730 --> 00:14:27,000
They are here because they
have only one extension.

276
00:14:27,000 --> 00:14:28,920
These guys are the same.

277
00:14:28,920 --> 00:14:32,700
This one appears with -1, and
here appears with +1.

278
00:14:32,700 --> 00:14:39,470
But if you cut the last guy, this
guy is identical to this guy, right?

279
00:14:39,470 --> 00:14:42,820
This second guy is identical
to the second guy.

280
00:14:42,820 --> 00:14:45,990
So I cannot count these
as different rows.

281
00:14:45,990 --> 00:14:51,150
I can do that when I gray
out one of the groups.

282
00:14:51,150 --> 00:14:54,480
Now, these are patently different.

283
00:14:54,480 --> 00:14:58,220
Nothing here is repeated, because we said
they have only one extension, and

284
00:14:58,220 --> 00:15:00,040
they are all tucked in here.

285
00:15:00,040 --> 00:15:03,550
These two guys, there are no two guys
here that are equal, because they all

286
00:15:03,550 --> 00:15:05,290
have the same extension.

287
00:15:05,290 --> 00:15:09,770
And supposedly, the whole row
makes it different rows.

288
00:15:09,770 --> 00:15:12,850
Therefore, these guys are
different from each other.

289
00:15:12,850 --> 00:15:16,770
And these guys are different from here
because again, if they are equal, then

290
00:15:16,770 --> 00:15:18,010
I will have an extension.

291
00:15:18,010 --> 00:15:22,190
And then the guys here will belong to
a row that had both extensions.

292
00:15:22,190 --> 00:15:22,780
Very easy.

293
00:15:22,780 --> 00:15:26,410
Just a verbose argument,
but we end up with these guys

294
00:15:26,410 --> 00:15:27,930
being different.

295
00:15:27,930 --> 00:15:30,900
Now, I like the fact that these guys are
being different, because when they

296
00:15:30,900 --> 00:15:33,700
are different, I can relate
them to B of N and k.

297
00:15:33,700 --> 00:15:38,280
B of N and k was the maximum number of
patterns-- different rows,

298
00:15:38,280 --> 00:15:39,610
that's how I am counting them--

299
00:15:39,610 --> 00:15:41,560
such that a condition occurs.

300
00:15:41,560 --> 00:15:44,310
So what is the condition
that is occurring here?

301
00:15:44,310 --> 00:15:49,460
I can say that alpha plus beta, which
is the total number of rows or

302
00:15:49,460 --> 00:15:55,290
patterns in this mini-matrix, can I say
something about a break point for

303
00:15:55,290 --> 00:15:58,160
this small matrix?

304
00:15:58,160 --> 00:15:59,550
Yeah.

305
00:15:59,550 --> 00:16:02,270
The original matrix, I could
not find all possible

306
00:16:02,270 --> 00:16:05,830
patterns on any k columns, right?

307
00:16:05,830 --> 00:16:10,410
So I cannot possibly find all possible
patterns on any k columns on this

308
00:16:10,410 --> 00:16:11,700
smaller set.

309
00:16:11,700 --> 00:16:15,710
Because if I find all possible patterns
on k columns here, they will

310
00:16:15,710 --> 00:16:19,050
serve as all possible patterns
in the big matrix.

311
00:16:19,050 --> 00:16:21,570
And I know, that doesn't exist.

312
00:16:21,570 --> 00:16:25,850
So I can now confidently say that alpha
plus beta, which is the number

313
00:16:25,850 --> 00:16:31,920
of different guys here, is less than or
equal to B of N minus 1, because I

314
00:16:31,920 --> 00:16:34,730
have only x_1 up to x_N-1,

315
00:16:34,730 --> 00:16:39,690
and k, because that is the break
point for these guys as well.

316
00:16:39,690 --> 00:16:44,000
Why am I saying less than
or equal to, not equal?

317
00:16:44,000 --> 00:16:48,000
When I constructed the original matrix,
it was equal by construction.

318
00:16:48,000 --> 00:16:50,530
I looked at the maximum number
of rows I get.

319
00:16:50,530 --> 00:16:52,230
And I told you this is
what I constructed.

320
00:16:52,230 --> 00:16:55,210
And therefore, by definition,
this is B of N and k.

321
00:16:55,210 --> 00:16:58,250
Here, I obtained this
in a special way.

322
00:16:58,250 --> 00:17:01,670
I took out a guy from the other
matrix, and did that.

323
00:17:01,670 --> 00:17:04,930
I am not sure that this is the best way
to maximize the number of rows.

324
00:17:04,930 --> 00:17:06,770
At least it's conceivably not.

325
00:17:06,770 --> 00:17:10,530
But for sure it's at most B of
N minus 1 and k, because that

326
00:17:10,530 --> 00:17:11,720
is the maximum number.

327
00:17:11,720 --> 00:17:13,980
I am safe saying that it's
less than or equal to.

328
00:17:13,980 --> 00:17:16,640


329
00:17:16,640 --> 00:17:19,730
So I have the first one.

330
00:17:19,730 --> 00:17:21,810
Now, let's try to estimate
beta by itself.

331
00:17:21,810 --> 00:17:24,430
This is the more subtle argument.

332
00:17:24,430 --> 00:17:28,540
In this case, we are going to
focus now on the second part

333
00:17:28,540 --> 00:17:30,410
only, the S_2 part.

334
00:17:30,410 --> 00:17:34,010
The guys that appear twice
in the big matrix.

335
00:17:34,010 --> 00:17:37,480
So let's focus on them.

336
00:17:37,480 --> 00:17:41,020
Now, when I focus on them, these
guys are very easy to analyze.

337
00:17:41,020 --> 00:17:44,040
They are here and here
exactly the same.

338
00:17:44,040 --> 00:17:48,550
This block is identical
to this block.

339
00:17:48,550 --> 00:17:51,530
The interesting thing, when I look at
these guys, is that I am going to be

340
00:17:51,530 --> 00:18:00,272
able to argue that these guys have
a break point of k minus 1, not k.

341
00:18:00,272 --> 00:18:03,260
The argument is very cute.

342
00:18:03,260 --> 00:18:07,860
Let's say that you have all possible
patterns on k minus 1 guys, in this

343
00:18:07,860 --> 00:18:08,890
small matrix.

344
00:18:08,890 --> 00:18:11,106
First, I have to kill these.

345
00:18:11,106 --> 00:18:14,540
These are not different guys, because
these are identical to these.

346
00:18:14,540 --> 00:18:17,930
So let me reduce it to the guys
that are patently different.

347
00:18:17,930 --> 00:18:19,400
I'm now looking at this matrix.

348
00:18:19,400 --> 00:18:22,240
I am claiming that k minus
1 is a break point here.

349
00:18:22,240 --> 00:18:23,200
Why is that?

350
00:18:23,200 --> 00:18:26,920
Because if you had k minus 1 guys
here, where you get all possible

351
00:18:26,920 --> 00:18:34,040
patterns, then by adding both copies,
+1 and -1, and adding x_N, you

352
00:18:34,040 --> 00:18:40,312
will be getting k columns overall that
have all possible patterns, which you

353
00:18:40,312 --> 00:18:44,310
know you cannot have because k is
a break point for the whole thing.

354
00:18:44,310 --> 00:18:47,510
So now I'm taking advantage of the
fact that these guys repeat.

355
00:18:47,510 --> 00:18:51,830
It's very dangerous to have k minus 1
guys, because now I have the k that I

356
00:18:51,830 --> 00:18:53,620
know doesn't exist.

357
00:18:53,620 --> 00:18:57,090
Let's do it illustratively.

358
00:18:57,090 --> 00:18:58,200
Here is a pattern here.

359
00:18:58,200 --> 00:19:00,640
You add the +1 extension
and the -1 extension,

360
00:19:00,640 --> 00:19:02,870
by taking this column.

361
00:19:02,870 --> 00:19:07,150
If you get all possible patterns on k
minus 1, and you add this guy, then you

362
00:19:07,150 --> 00:19:11,040
have both patterns here, and you will
end up with all possible patterns on k

363
00:19:11,040 --> 00:19:12,330
points on the overall matrix.

364
00:19:12,330 --> 00:19:14,950


365
00:19:14,950 --> 00:19:19,500
That enables me to actually count
this in terms of B of N and k, again,

366
00:19:19,500 --> 00:19:21,030
with the proper values of N and k.

367
00:19:21,030 --> 00:19:24,630
We can say that beta is less than
or equal to-- again, less than or

368
00:19:24,630 --> 00:19:27,620
equal to because I obtained this
matrix by lots of eliminations.

369
00:19:27,620 --> 00:19:30,220
I didn't do it deliberately to maximize
the number, so I don't know

370
00:19:30,220 --> 00:19:31,290
whether it's the maximum.

371
00:19:31,290 --> 00:19:34,480
But I sure know that it's less than or
equal to the maximum, by the definition

372
00:19:34,480 --> 00:19:36,410
of what a maximum is.

373
00:19:36,410 --> 00:19:38,420
And that would be of what?

374
00:19:38,420 --> 00:19:44,260
I have N minus 1 point and I argued
for a break point of k minus 1.

375
00:19:44,260 --> 00:19:47,630
So I end up with this fellow.

376
00:19:47,630 --> 00:19:49,650
Both arguments are very simple.

377
00:19:49,650 --> 00:19:53,230
Now, we pull the rabbit out of the hat!

378
00:19:53,230 --> 00:19:54,580
You put it together.

379
00:19:54,580 --> 00:19:55,610
What do we have?

380
00:19:55,610 --> 00:19:57,640
This is the full matrix.

381
00:19:57,640 --> 00:20:02,530
The first item was just calling things
names, the number of rows in the big

382
00:20:02,530 --> 00:20:06,460
matrix is B of N and k,
by definition-- by construction.

383
00:20:06,460 --> 00:20:10,190
I organized it such that there is alpha,
and there is beta, and there is

384
00:20:10,190 --> 00:20:14,350
another beta, so this one is the first
result I got, which is B of N and k

385
00:20:14,350 --> 00:20:16,910
equals alpha plus 2 beta.

386
00:20:16,910 --> 00:20:19,150
What else did I get?

387
00:20:19,150 --> 00:20:24,240
I got that alpha plus beta is at
most B of N minus 1 and k.

388
00:20:24,240 --> 00:20:27,480
That was the first slide
of the analysis.

389
00:20:27,480 --> 00:20:28,990
We have seen that.

390
00:20:28,990 --> 00:20:35,110
So this basically takes this matrix,
and does an analysis on it.

391
00:20:35,110 --> 00:20:38,500
And it has a break point k, because k
will be inherited when you go to the

392
00:20:38,500 --> 00:20:39,090
bigger one.

393
00:20:39,090 --> 00:20:40,640
That's what we did.

394
00:20:40,640 --> 00:20:45,420
The other one is, beta is less than
B of N minus 1 and k minus 1.

395
00:20:45,420 --> 00:20:48,970
And this is the case where I only looked
at this guy, and now I have to

396
00:20:48,970 --> 00:20:51,770
be more restrictive in terms of all
possible patterns, because I have

397
00:20:51,770 --> 00:20:54,650
an extension to add, and I would be
violating the big constraint.

398
00:20:54,650 --> 00:20:57,100
So I ended up with this being less
than or equal to B of N minus

399
00:20:57,100 --> 00:20:59,760
1 and k minus 1.

400
00:20:59,760 --> 00:21:03,530
Anybody notice anything in this slide?

401
00:21:03,530 --> 00:21:07,700
How convenient! I have alpha plus 2 beta
there, and I have alpha plus beta

402
00:21:07,700 --> 00:21:10,380
on one, and beta on one.

403
00:21:10,380 --> 00:21:12,220
If I add them, I am in business.

404
00:21:12,220 --> 00:21:17,190
I can actually now relate B of N and k
to other B of N and k, and alpha and

405
00:21:17,190 --> 00:21:19,900
beta are gone.

406
00:21:19,900 --> 00:21:25,400
B of N and k, now I know, has
to be at most this fellow.

407
00:21:25,400 --> 00:21:28,440
So you can see where the
recursion is going.

408
00:21:28,440 --> 00:21:32,210
Now I know that this property
holds for the B of N and k.

409
00:21:32,210 --> 00:21:36,080
And now all I need to do is solve it, in
order to find an actual numerical

410
00:21:36,080 --> 00:21:37,690
value for B of N and k.

411
00:21:37,690 --> 00:21:42,480
And that numerical value will serve as
an upper bound for any growth function

412
00:21:42,480 --> 00:21:45,690
of a hypothesis set that
has a break point k.

413
00:21:45,690 --> 00:21:48,450


414
00:21:48,450 --> 00:21:53,020
Let's do the numerical
computation first.

415
00:21:53,020 --> 00:21:58,170
I have this recursion, and I can see
that, from smaller values of N and

416
00:21:58,170 --> 00:22:02,400
K, I can get bigger values, or I can get
an upper bound on bigger values.

417
00:22:02,400 --> 00:22:06,520
Let's do it in a table.

418
00:22:06,520 --> 00:22:07,900
Here is a table.

419
00:22:07,900 --> 00:22:09,710
Here is the value of N-- 1, 2.

420
00:22:09,710 --> 00:22:13,470
This is the number of points, the
number of columns in the matrix.

421
00:22:13,470 --> 00:22:14,420
And this is k.

422
00:22:14,420 --> 00:22:16,240
This is the break point
I am talking about.

423
00:22:16,240 --> 00:22:19,030
So this will be-- there's a break point
of 1, break point 2, break point

424
00:22:19,030 --> 00:22:20,540
3, et cetera.

425
00:22:20,540 --> 00:22:24,960
And what I'd like to do here, I'd like
to fill this table with an upper bound

426
00:22:24,960 --> 00:22:25,930
on B of N and k.

427
00:22:25,930 --> 00:22:29,660
I'd like to put numbers here, that I know
that B of N and k can be at most

428
00:22:29,660 --> 00:22:31,290
that number.

429
00:22:31,290 --> 00:22:35,060
And we can construct this matrix very,
very easily having this recursion.

430
00:22:35,060 --> 00:22:38,000
Here's what we do.

431
00:22:38,000 --> 00:22:41,280
First, I fill the boundary conditions.

432
00:22:41,280 --> 00:22:42,990
Let's look at this.

433
00:22:42,990 --> 00:22:47,360
Here it says that there
is a break point of 1.

434
00:22:47,360 --> 00:22:51,435
I cannot get all possible
patterns on one point.

435
00:22:51,435 --> 00:22:55,080
Well, what are all possible
patterns on one point?

436
00:22:55,080 --> 00:22:55,930
-1 and +1.

437
00:22:55,930 --> 00:22:57,200
It's one point.

438
00:22:57,200 --> 00:22:59,760
So I cannot get both
-1 and +1.

439
00:22:59,760 --> 00:23:01,930
That's a pretty heavy restriction.

440
00:23:01,930 --> 00:23:05,930
So I'm asking myself, let's say you
have now N columns in the matrix.

441
00:23:05,930 --> 00:23:11,070
How many different rows can you get in
that matrix, under that constraint?

442
00:23:11,070 --> 00:23:12,240
Well, I'm in trouble.

443
00:23:12,240 --> 00:23:18,430
Because if I have the first pattern, and
then I put a second pattern, the

444
00:23:18,430 --> 00:23:23,080
second pattern must be different from
the first one in at least one column.

445
00:23:23,080 --> 00:23:24,080
That's what makes it different.

446
00:23:24,080 --> 00:23:28,490
If it's identical in every column, then
it's not a different pattern, right?

447
00:23:28,490 --> 00:23:30,760
So you go to that point,
where it's different.

448
00:23:30,760 --> 00:23:36,910
And unfortunately, for that point
you get both possible patterns.

449
00:23:36,910 --> 00:23:37,790
So we are stuck.

450
00:23:37,790 --> 00:23:41,715
We can only have one pattern
under this constraint.

451
00:23:41,715 --> 00:23:42,940
Hence, the 1's--

452
00:23:42,940 --> 00:23:45,040
1, 1, 1, 1, 1.

453
00:23:45,040 --> 00:23:46,670
That's good.

454
00:23:46,670 --> 00:23:51,160
Now, in the other direction,
it's also easy.

455
00:23:51,160 --> 00:23:52,650
In this case, it's 2.

456
00:23:52,650 --> 00:23:53,890
It's very easy to argue.

457
00:23:53,890 --> 00:23:58,250
Now, I am taking the case where
I have only one column.

458
00:23:58,250 --> 00:24:02,145
So I'm asking myself, how many patterns
I can get for one column.

459
00:24:02,145 --> 00:24:04,630
Well, the most is 2.

460
00:24:04,630 --> 00:24:06,500
Why am I getting 2's here?

461
00:24:06,500 --> 00:24:12,160
Because in the upper diagonal of
this table, the constraint I

462
00:24:12,160 --> 00:24:15,760
am putting is vacuous.

463
00:24:15,760 --> 00:24:19,460
Here, for example, I am telling you how
many different patterns can you

464
00:24:19,460 --> 00:24:26,750
get on one point, such that no four
points have all possible patterns.

465
00:24:26,750 --> 00:24:27,990
Four points, what are
you talking about?

466
00:24:27,990 --> 00:24:29,470
You have only one point.

467
00:24:29,470 --> 00:24:32,090
So that's no constraint at all.

468
00:24:32,090 --> 00:24:35,530
Therefore, it doesn't restrict the
choices, and the maximum number is the

469
00:24:35,530 --> 00:24:39,080
maximum number I would get unrestricted,
which happens to be 2.

470
00:24:39,080 --> 00:24:40,970
If I have one point,
I get two patterns.

471
00:24:40,970 --> 00:24:44,030
That's why you have the
2's sitting here.

472
00:24:44,030 --> 00:24:48,030
Now, I covered the boundary conditions,
and that's really all I need to

473
00:24:48,030 --> 00:24:53,020
complete the entire table, given the
nature of the constraint I have.

474
00:24:53,020 --> 00:24:55,110
Why is that?

475
00:24:55,110 --> 00:24:58,800
Because that constraint looks like this.

476
00:24:58,800 --> 00:25:03,770
If you know the solid blue guys, I
will tell you the empty blue guy.

477
00:25:03,770 --> 00:25:06,680
Because this would be--
look at N and k.

478
00:25:06,680 --> 00:25:08,680
This is N and k.

479
00:25:08,680 --> 00:25:12,450
This would be N minus 1 and k.

480
00:25:12,450 --> 00:25:16,170
This would be N minus 1 and k minus 1.

481
00:25:16,170 --> 00:25:19,460
That's exactly what this says.

482
00:25:19,460 --> 00:25:22,550
So if I have these two points, I can
get a value here, which will be

483
00:25:22,550 --> 00:25:25,320
an upper bound on this fellow.

484
00:25:25,320 --> 00:25:29,370
Let us actually go through
this table, and fill it up.

485
00:25:29,370 --> 00:25:32,940
The first guy I'm going
to take is this 1 and 2.

486
00:25:32,940 --> 00:25:36,350
According to this shape, I might
be able to get this fellow.

487
00:25:36,350 --> 00:25:37,740
What would that fellow be?

488
00:25:37,740 --> 00:25:40,400


489
00:25:40,400 --> 00:25:41,930
3, right?

490
00:25:41,930 --> 00:25:43,680
You just add the two numbers.

491
00:25:43,680 --> 00:25:46,340
How about the next guy?

492
00:25:46,340 --> 00:25:49,090
Anybody has a guess here?

493
00:25:49,090 --> 00:25:53,150
OK, 4.

494
00:25:53,150 --> 00:25:53,920
And then?

495
00:25:53,920 --> 00:25:56,020
A bunch of 4's.

496
00:25:56,020 --> 00:25:57,590
Always get 2's.

497
00:25:57,590 --> 00:26:02,440
I am actually happy about this because
you see that when k grows big, much

498
00:26:02,440 --> 00:26:05,060
bigger than N, as we said, the
constraint is vacuous.

499
00:26:05,060 --> 00:26:07,150
So I should be getting all
possible patterns on the

500
00:26:07,150 --> 00:26:08,390
number of points I have.

501
00:26:08,390 --> 00:26:10,450
And as you can see, for
1, I get the 2's.

502
00:26:10,450 --> 00:26:12,760
For 2, I will get eventually the 4's.

503
00:26:12,760 --> 00:26:14,520
And for 3, it will be the 8's.

504
00:26:14,520 --> 00:26:16,600
So that is very nice.

505
00:26:16,600 --> 00:26:17,870
Let's go over the next row.

506
00:26:17,870 --> 00:26:18,820
Can I solve this one?

507
00:26:18,820 --> 00:26:23,840
Now that I got this one, I can become
more sophisticated and get this one.

508
00:26:23,840 --> 00:26:25,810
See where this came from?

509
00:26:25,810 --> 00:26:27,710
How about the next one,
what would that be?

510
00:26:27,710 --> 00:26:28,960
That should be 7, right?

511
00:26:28,960 --> 00:26:31,710


512
00:26:31,710 --> 00:26:33,710
8.

513
00:26:33,710 --> 00:26:35,480
A bunch of 8's.

514
00:26:35,480 --> 00:26:37,810
This is kind of fun.

515
00:26:37,810 --> 00:26:42,160
And you can fill up the entire table.

516
00:26:42,160 --> 00:26:44,620
So we have it completely
solved, numerically.

517
00:26:44,620 --> 00:26:47,510
It would be nice to have a formula,
which we will have in a minute.

518
00:26:47,510 --> 00:26:50,650
But numerically, we will have that.

519
00:26:50,650 --> 00:26:53,480
Now, let me highlight one guy.

520
00:26:53,480 --> 00:26:55,340
Do you see anything that
changed colors?

521
00:26:55,340 --> 00:26:58,060


522
00:26:58,060 --> 00:26:59,355
I claim that you have
seen this before.

523
00:26:59,355 --> 00:27:02,930


524
00:27:02,930 --> 00:27:04,180
That's the puzzle.

525
00:27:04,180 --> 00:27:06,760


526
00:27:06,760 --> 00:27:09,800
You had three points.

527
00:27:09,800 --> 00:27:12,060
Your break point was 2.

528
00:27:12,060 --> 00:27:16,510
And now we know for a fact that the
maximum number you can get is 4,

529
00:27:16,510 --> 00:27:19,170
without having to go through
the entire torture we went

530
00:27:19,170 --> 00:27:20,120
through last time.

531
00:27:20,120 --> 00:27:20,810
Can we try this?

532
00:27:20,810 --> 00:27:22,440
Can we try that?
Oh, I am violating--

533
00:27:22,440 --> 00:27:23,960
You don't have to do that.

534
00:27:23,960 --> 00:27:28,600
Here are the numbers, just by computing
a very simple recursion.

535
00:27:28,600 --> 00:27:30,830
Now, let's go for the analytic
version of that.

536
00:27:30,830 --> 00:27:35,510
What I'd like to do, I'd like to
find a formula that computes this

537
00:27:35,510 --> 00:27:36,540
number outright.

538
00:27:36,540 --> 00:27:40,680
I don't have to go through this
computation numerically.

539
00:27:40,680 --> 00:27:41,920
So let's do that.

540
00:27:41,920 --> 00:27:44,060
This is the analytic solution
for B of N and k.

541
00:27:44,060 --> 00:27:46,830


542
00:27:46,830 --> 00:27:49,280
Again, this is the recursion.

543
00:27:49,280 --> 00:27:52,180
And now we have a theorem.

544
00:27:52,180 --> 00:27:55,560
Yeah, when you're doing mathematical
theory, you have to have theorems.

545
00:27:55,560 --> 00:27:58,450
Otherwise, you lose your
qualifications!

546
00:27:58,450 --> 00:27:59,810
What does the theorem say?

547
00:27:59,810 --> 00:28:02,410


548
00:28:02,410 --> 00:28:06,870
It tells you that this is a formula
that is an upper bound

549
00:28:06,870 --> 00:28:08,640
for B of N and k.

550
00:28:08,640 --> 00:28:09,620
What is this formula?

551
00:28:09,620 --> 00:28:13,420
This is N choose i, the combinatorial
quantity.

552
00:28:13,420 --> 00:28:16,120
And you sum this up from
i equals 0 to k minus 1.

553
00:28:16,120 --> 00:28:17,660
So both N and k appear.

554
00:28:17,660 --> 00:28:22,900
N appears as the number here, and k
appears as the limit for the index of

555
00:28:22,900 --> 00:28:25,420
summation-- appears as k minus 1.

556
00:28:25,420 --> 00:28:29,460
This quantity will be an upper
bound for B of N and k.

557
00:28:29,460 --> 00:28:33,320
You can now, if you believe that,
which we will argue in a moment,

558
00:28:33,320 --> 00:28:34,750
you compute this number.

559
00:28:34,750 --> 00:28:39,570
And that will be an upper bound for the
growth function of any hypothesis

560
00:28:39,570 --> 00:28:43,970
set that has a break point k, without
asking any questions whatsoever about

561
00:28:43,970 --> 00:28:46,940
the hypothesis set or the input space.

562
00:28:46,940 --> 00:28:51,400
It shouldn't come as a surprise
that this quantity is right, because if

563
00:28:51,400 --> 00:28:56,560
you look at this, this is really
screaming for something binomial or

564
00:28:56,560 --> 00:28:57,630
combinatorial.

565
00:28:57,630 --> 00:28:59,910
Clearly, it will come
out one way or the other.

566
00:28:59,910 --> 00:29:01,520
But why is it this way?

567
00:29:01,520 --> 00:29:04,330
Well, what we are going to show, we are
going to show that this is exactly

568
00:29:04,330 --> 00:29:07,780
the quantity we computed numerically
for the other table.

569
00:29:07,780 --> 00:29:10,470
And we are going to do
it by induction.

570
00:29:10,470 --> 00:29:13,960
So the recursion we did, we are just
going to do it analytically.

571
00:29:13,960 --> 00:29:16,370
How do you do that?

572
00:29:16,370 --> 00:29:18,820
You start with boundary conditions.

573
00:29:18,820 --> 00:29:20,060
What were the boundary conditions?

574
00:29:20,060 --> 00:29:22,950
We argued that this is, indeed,
the value of B of N and k.

575
00:29:22,950 --> 00:29:26,120
And hence, an upper bound on
it, from the last slide.

576
00:29:26,120 --> 00:29:30,110
Now we want to verify that this
quantity actually returns those

577
00:29:30,110 --> 00:29:36,270
numbers, when you plug in the value
N equals 1 or k equals 1.

578
00:29:36,270 --> 00:29:38,190
How do I do that?

579
00:29:38,190 --> 00:29:39,560
You just do it.

580
00:29:39,560 --> 00:29:41,040
Just plug in, and it will come out.

581
00:29:41,040 --> 00:29:42,750
I'm not going even to bother doing it.

582
00:29:42,750 --> 00:29:43,700
It's a very simple formula.

583
00:29:43,700 --> 00:29:46,140
You just evaluate it, and you get that.

584
00:29:46,140 --> 00:29:49,120
The interesting part is the recursion.

585
00:29:49,120 --> 00:29:57,330
I would like to argue that if
this formula holds for the solid blue

586
00:29:57,330 --> 00:30:01,210
points, then it will also
hold for this guy.

587
00:30:01,210 --> 00:30:04,760
And then by induction, since it holds
for all of these guys, I can just do

588
00:30:04,760 --> 00:30:09,870
this step by step and fill the schedule,
with the truth of this being

589
00:30:09,870 --> 00:30:15,160
the correct value for the numbers
that appear here.

590
00:30:15,160 --> 00:30:18,900
Everybody is clear
about the logic of it?

591
00:30:18,900 --> 00:30:21,200
So let's do the induction.

592
00:30:21,200 --> 00:30:22,660
We have the induction step.

593
00:30:22,660 --> 00:30:26,460
We just want to make clear
what the induction step is.

594
00:30:26,460 --> 00:30:33,640
You are going to assume that
the formula holds for this

595
00:30:33,640 --> 00:30:36,290
point and this point.

596
00:30:36,290 --> 00:30:39,430
So indeed, if you plug in the values for
N and k, which here, N minus 1 and k

597
00:30:39,430 --> 00:30:43,070
minus 1, and here it would be N minus
1 and k, you plug it into that

598
00:30:43,070 --> 00:30:45,250
particular formula.

599
00:30:45,250 --> 00:30:47,090
Then the numbers will be correct.

600
00:30:47,090 --> 00:30:49,100
That's the assumption.

601
00:30:49,100 --> 00:30:53,610
And then you prove that, if this is true,
then the formula will hold here.

602
00:30:53,610 --> 00:30:55,890
That's the induction step.

603
00:30:55,890 --> 00:30:56,900
Fair enough.

604
00:30:56,900 --> 00:30:59,910
So let's do that.

605
00:30:59,910 --> 00:31:02,020
This is the formula for N and k.

606
00:31:02,020 --> 00:31:04,290
You just need to remember it.

607
00:31:04,290 --> 00:31:06,610
N appears here and k appears here.

608
00:31:06,610 --> 00:31:08,850
Minus 1 is an integral
part of the formula.

609
00:31:08,850 --> 00:31:11,740
This is the value for
k, not for k minus 1.

610
00:31:11,740 --> 00:31:16,520
The value, for k, happens to be the sum
from i equals 0 to that k, minus 1.

611
00:31:16,520 --> 00:31:21,190
So this is the formula that
is supposed to be here.

612
00:31:21,190 --> 00:31:25,880
And we would like to argue
that this is equal to--

613
00:31:25,880 --> 00:31:26,840
what is this one?

614
00:31:26,840 --> 00:31:32,020
This one is for N minus 1, and still k.

615
00:31:32,020 --> 00:31:32,910
So this would be--

616
00:31:32,910 --> 00:31:36,000
I am moved from here to here.

617
00:31:36,000 --> 00:31:38,830
So this will be the value here.

618
00:31:38,830 --> 00:31:41,720
And what is the other guy?

619
00:31:41,720 --> 00:31:43,870
That will be the value for N minus 1.

620
00:31:43,870 --> 00:31:46,940
And now it's for k minus 1, because
you still take the other minus 1.

621
00:31:46,940 --> 00:31:48,230
It becomes k minus 2.

622
00:31:48,230 --> 00:31:51,860
This part belongs here.

623
00:31:51,860 --> 00:31:53,120
So this is the induction step.

624
00:31:53,120 --> 00:31:54,000
We don't have it yet.

625
00:31:54,000 --> 00:31:55,140
That's what we want to establish.

626
00:31:55,140 --> 00:31:57,580
So let me put a question mark
to make sure that we haven't

627
00:31:57,580 --> 00:31:59,920
established it yet.

628
00:31:59,920 --> 00:32:04,230
What I am going to do, I am going to
take the right-hand side, and keep

629
00:32:04,230 --> 00:32:07,290
reducing it, until the left-hand
side appears.

630
00:32:07,290 --> 00:32:08,200
That's all.

631
00:32:08,200 --> 00:32:10,070
And then we'll be done with
the induction step.

632
00:32:10,070 --> 00:32:13,480
And since we have the boundary
conditions, we will have proved the

633
00:32:13,480 --> 00:32:16,570
theorem we asserted.

634
00:32:16,570 --> 00:32:20,380
The first thing I am going to do,
I am going to look at this fellow.

635
00:32:20,380 --> 00:32:24,290
And I notice that the index goes
here from i equals 0 to k minus 1.

636
00:32:24,290 --> 00:32:26,820
Here, it goes from i equals 0
to k minus 2.

637
00:32:26,820 --> 00:32:29,110
I'd like to merge the two summations.

638
00:32:29,110 --> 00:32:31,680
So in order to merge the two summations,
I will make them the same

639
00:32:31,680 --> 00:32:33,970
number of terms, first.

640
00:32:33,970 --> 00:32:38,280
Very easy. I will just take the zeroth
term, which would be N minus 1 choose

641
00:32:38,280 --> 00:32:40,500
0, which is 1, out.

642
00:32:40,500 --> 00:32:45,410
And now the summation goes from
i equals 1 to k minus 1.

643
00:32:45,410 --> 00:32:49,400
Now, I go to the other
guy and do this.

644
00:32:49,400 --> 00:32:51,010
What did I do?

645
00:32:51,010 --> 00:32:54,480
I just changed the name of
the dummy variable i.

646
00:32:54,480 --> 00:32:57,530
I wanted the index to go from 1
to k minus 1, in order to be

647
00:32:57,530 --> 00:32:58,810
able to merge it easily.

648
00:32:58,810 --> 00:33:00,960
Here, it goes from 0 to k minus 2.

649
00:33:00,960 --> 00:33:02,030
So what do I do?

650
00:33:02,030 --> 00:33:04,630
I just make this i, and
make this i minus 1.

651
00:33:04,630 --> 00:33:08,910
So i minus 1 goes from 0 to k
minus 2, as this i used to.

652
00:33:08,910 --> 00:33:10,860
Just changing the names.

653
00:33:10,860 --> 00:33:15,580
And now, having done that, I am ready
to merge the two summations.

654
00:33:15,580 --> 00:33:19,160
And they are merged.

655
00:33:19,160 --> 00:33:25,390
Now, I would like to be able to take
this, and produce one quantity.

656
00:33:25,390 --> 00:33:27,240
And you can do it by brute force.

657
00:33:27,240 --> 00:33:28,290
This is no mysterious quantity.

658
00:33:28,290 --> 00:33:28,760
This is what?

659
00:33:28,760 --> 00:33:33,930
This is N minus 1 times N minus
2 times N minus 3, i terms,

660
00:33:33,930 --> 00:33:35,890
divided by i factorial.

661
00:33:35,890 --> 00:33:37,700
And this one applies the same thing.

662
00:33:37,700 --> 00:33:43,220
So you end up with something, and then
you do all kinds of algebra, and it

663
00:33:43,220 --> 00:33:43,880
looks familiar.

664
00:33:43,880 --> 00:33:45,310
And then you reduce it
to another quantity.

665
00:33:45,310 --> 00:33:47,950
So there's always an algebraic
way of reducing it.

666
00:33:47,950 --> 00:33:51,830
But I am going to reduce it with a very
simple combinatorial argument.

667
00:33:51,830 --> 00:33:53,680
I am going to claim that this is--

668
00:33:53,680 --> 00:33:55,790
the 1 remains the same.

669
00:33:55,790 --> 00:33:58,720
And this actually, the whole thing
here reduces to N choose i.

670
00:33:58,720 --> 00:34:01,850
So these two guys become this one.

671
00:34:01,850 --> 00:34:05,060
Instead of doing the algebra,
I am going to give you

672
00:34:05,060 --> 00:34:06,710
a combinatorial argument.

673
00:34:06,710 --> 00:34:11,650
That is, this quantity is identical
to N choose i.

674
00:34:11,650 --> 00:34:17,719
Let's say that I am trying to choose
10 people from this room.

675
00:34:17,719 --> 00:34:20,699
And let's say that the room
has N people.

676
00:34:20,699 --> 00:34:22,500
There are N people.

677
00:34:22,500 --> 00:34:28,000
How many ways can you chose 10
people out of this room?

678
00:34:28,000 --> 00:34:31,949
That is N choose 10.

679
00:34:31,949 --> 00:34:34,320
Let's put this on the side.

680
00:34:34,320 --> 00:34:37,870
Here is another way of counting it.

681
00:34:37,870 --> 00:34:44,290
We can count the number of ways you can
pick 10 people, excluding me, plus

682
00:34:44,290 --> 00:34:50,150
the number of ways you can pick
10 people, including me.

683
00:34:50,150 --> 00:34:50,550
Right?

684
00:34:50,550 --> 00:34:53,540
These are disjoint, and they
cover all the cases.

685
00:34:53,540 --> 00:34:55,480
Let's look at excluding me.

686
00:34:55,480 --> 00:35:00,720
How many ways can you pick 10 people
from the room, excluding me?

687
00:35:00,720 --> 00:35:04,220
Well, then you are picking the
10 people from N minus 1.

688
00:35:04,220 --> 00:35:06,110
I am the minus 1.

689
00:35:06,110 --> 00:35:10,080
So that would be N minus 1 choose 10.

690
00:35:10,080 --> 00:35:13,310
Put this in the bank.

691
00:35:13,310 --> 00:35:17,890
How many ways can you pick
10 people, including me?

692
00:35:17,890 --> 00:35:20,410
Well, you already decided you are
including me, so you are only deciding

693
00:35:20,410 --> 00:35:22,820
on the 9 remaining guys.

694
00:35:22,820 --> 00:35:27,510
So that would be N minus 1 choose 9.

695
00:35:27,510 --> 00:35:32,750
So we have N minus 1 choose 10, plus
N minus 1 choose 9, that equals the

696
00:35:32,750 --> 00:35:37,020
original number, which
was N choose 10.

697
00:35:37,020 --> 00:35:37,730
Look at this.

698
00:35:37,730 --> 00:35:38,980
What do we have?

699
00:35:38,980 --> 00:35:41,800


700
00:35:41,800 --> 00:35:43,900
This is excluding me.

701
00:35:43,900 --> 00:35:45,820
This is including me.

702
00:35:45,820 --> 00:35:47,930
And this is the original count.

703
00:35:47,930 --> 00:35:50,730
So it's a combinatorial identity, and
we don't have to go through the

704
00:35:50,730 --> 00:35:55,260
torture of the algebra in order to
prove that it's exactly the same.

705
00:35:55,260 --> 00:35:56,520
Now, I go back.

706
00:35:56,520 --> 00:35:59,140
I look, this goes from
i equals 1 to k minus 1.

707
00:35:59,140 --> 00:36:04,240
I have this 1, so I conveniently put
it back, and get this formula.

708
00:36:04,240 --> 00:36:06,585
Have you seen it before?

709
00:36:06,585 --> 00:36:07,690
Yeah, it looks familiar.

710
00:36:07,690 --> 00:36:09,930
Oh, this is the one we want to prove.

711
00:36:09,930 --> 00:36:13,380
So it means that we are done.

712
00:36:13,380 --> 00:36:14,380
That's it.

713
00:36:14,380 --> 00:36:20,150
We have an exact solution for the
upper bound on B of N and k.

714
00:36:20,150 --> 00:36:25,980
Since we spent some time developing
it, let's look at it and

715
00:36:25,980 --> 00:36:28,450
celebrate it, and be happy about it.

716
00:36:28,450 --> 00:36:32,880
First thing: yes, it's a polynomial,
because all of this torture was to get

717
00:36:32,880 --> 00:36:34,415
a polynomial, right?

718
00:36:34,415 --> 00:36:37,870
If we did all of this, and it's perfect
math, and the end result was not

719
00:36:37,870 --> 00:36:39,460
a polynomial, then we are in trouble.

720
00:36:39,460 --> 00:36:42,850
Because although the quantity is
correct, it's not going to be useful

721
00:36:42,850 --> 00:36:45,560
in the utility that we are aiming at.

722
00:36:45,560 --> 00:36:47,650
So why is it polynomial?

723
00:36:47,650 --> 00:36:51,950
Remember that for a particular
hypothesis set, the break point is

724
00:36:51,950 --> 00:36:52,510
a fixed point.

725
00:36:52,510 --> 00:36:55,500
It doesn't grow with N. You
ask in a hypothesis set,

726
00:36:55,500 --> 00:36:59,490
can I get all possible dichotomies
on four points?

727
00:36:59,490 --> 00:37:00,820
That's a question for the perceptron.

728
00:37:00,820 --> 00:37:01,540
No.

729
00:37:01,540 --> 00:37:04,670
Then 4, in the perceptron,
is a break point.

730
00:37:04,670 --> 00:37:08,040
Now, I can ask myself what the
perceptron does on 100 points.

731
00:37:08,040 --> 00:37:11,370
And the break point is still
4, just a constant.

732
00:37:11,370 --> 00:37:14,060
You give me a hypothesis set,
I give you a break point.

733
00:37:14,060 --> 00:37:15,310
That's a fixed number.

734
00:37:15,310 --> 00:37:17,930


735
00:37:17,930 --> 00:37:23,680
So according to our argument now, the
growth function for a hypothesis set

736
00:37:23,680 --> 00:37:29,860
that has a break point k is less than or
equal to the purely combinatorial

737
00:37:29,860 --> 00:37:34,470
quantity, B of N and k, which is defined
as the maximum such number of

738
00:37:34,470 --> 00:37:38,230
dichotomies you can get, under the
constraint that k is a break point.

739
00:37:38,230 --> 00:37:41,550
And that was less than or equal
to the nice formula we had.

740
00:37:41,550 --> 00:37:44,450
So we can now make this statement.

741
00:37:44,450 --> 00:37:47,430
You go in a real learning
situation.

742
00:37:47,430 --> 00:37:50,740
Let's say you have a neural network
making a decision, and you tell me the

743
00:37:50,740 --> 00:37:54,730
break point for that neural
network is 17.

744
00:37:54,730 --> 00:37:57,480
I don't ask you what is a neural
network, because we don't know yet, so

745
00:37:57,480 --> 00:37:58,520
you don't have to know.

746
00:37:58,520 --> 00:38:01,020
I don't ask you what is the
dimensionality of the Euclidean space

747
00:38:01,020 --> 00:38:01,980
you are working on.

748
00:38:01,980 --> 00:38:02,910
You told me 17.

749
00:38:02,910 --> 00:38:07,430
Your growth function of your neural
network that I don't know, in

750
00:38:07,430 --> 00:38:10,700
the space that I don't know, happens to
be less than or equal to that, and I

751
00:38:10,700 --> 00:38:13,570
know that I'm correct.

752
00:38:13,570 --> 00:38:16,470
So is this quantity polynomial in N?

753
00:38:16,470 --> 00:38:17,570
That's what we need.

754
00:38:17,570 --> 00:38:21,370
Because remember, in the Hoeffding, there
was a negative exponential in N.

755
00:38:21,370 --> 00:38:24,450
If we get this to be polynomial
in N, we are in business.

756
00:38:24,450 --> 00:38:28,130
Well, any one of those guys is what?

757
00:38:28,130 --> 00:38:33,110
N times N minus 1 times N minus 2,
i times, divided by i factorial.

758
00:38:33,110 --> 00:38:34,760
i factorial doesn't matter,
it's a constant.

759
00:38:34,760 --> 00:38:38,790
So you basically get N multiplied by
itself a number of times, i times, for

760
00:38:38,790 --> 00:38:40,320
the i-th term.

761
00:38:40,320 --> 00:38:44,330
The most that N will be multiplied by
itself is when you get to i equals

762
00:38:44,330 --> 00:38:46,160
k minus 1, the maximum.

763
00:38:46,160 --> 00:38:49,980
And then N will be multiplied
by itself k minus 1 times.

764
00:38:49,980 --> 00:38:59,070
Therefore, the maximum power in this
quantity is N to the k minus 1.

765
00:38:59,070 --> 00:39:03,860
This comes from N times N minus
1 times N minus 2 times--

766
00:39:03,860 --> 00:39:07,860
k times, that corresponds to the
case where i equals k minus 1.

767
00:39:07,860 --> 00:39:10,680
When you get N choose k minus
1, that's what you get.

768
00:39:10,680 --> 00:39:14,670
Anything else, will give you a power
of N, but it's a smaller power.

769
00:39:14,670 --> 00:39:16,770
This is the most you will have.

770
00:39:16,770 --> 00:39:19,080
What do we know about this fellow k?

771
00:39:19,080 --> 00:39:20,910
We know it's just a number.

772
00:39:20,910 --> 00:39:21,620
It's a constant.

773
00:39:21,620 --> 00:39:25,690
It doesn't change with N. And
therefore, this is indeed

774
00:39:25,690 --> 00:39:32,110
a polynomial in N. And we have achieved
what we set out to do.

775
00:39:32,110 --> 00:39:35,910
That is pretty good.

776
00:39:35,910 --> 00:39:40,060
Let's take three examples, in order to
make this relate to experiences we

777
00:39:40,060 --> 00:39:41,310
had before.

778
00:39:41,310 --> 00:39:44,540


779
00:39:44,540 --> 00:39:46,080
This is the famous quantity by now.

780
00:39:46,080 --> 00:39:47,300
You know it by heart.

781
00:39:47,300 --> 00:39:48,060
I have the N.

782
00:39:48,060 --> 00:39:48,730
I remember k.

783
00:39:48,730 --> 00:39:49,760
I have to put minus 1.

784
00:39:49,760 --> 00:39:53,210
And that is the upper bound for anything
that has a break point k.

785
00:39:53,210 --> 00:39:58,380
Now, let's take hypothesis sets we
looked at before, for which we computed

786
00:39:58,380 --> 00:40:03,280
the growth function explicitly, and see
if they actually satisfy the bound.

787
00:40:03,280 --> 00:40:04,760
They had better, because this is math.

788
00:40:04,760 --> 00:40:05,760
We proved it.

789
00:40:05,760 --> 00:40:08,260
But just to see that this
is, indeed, the case.

790
00:40:08,260 --> 00:40:10,265
Positive rays.

791
00:40:10,265 --> 00:40:13,460
Oh, remember positive rays
from some time ago?

792
00:40:13,460 --> 00:40:15,870
We have one dimension,
so just the real line.

793
00:40:15,870 --> 00:40:19,170
Then we take from a point on,
it goes to +1.

794
00:40:19,170 --> 00:40:22,590
And we said that the whole analysis
here is exactly to

795
00:40:22,590 --> 00:40:23,790
avoid what I just did.

796
00:40:23,790 --> 00:40:25,640
You don't have to tell
me what is the input.

797
00:40:25,640 --> 00:40:26,650
You don't have to tell me--

798
00:40:26,650 --> 00:40:29,360
you just have to tell me what?

799
00:40:29,360 --> 00:40:32,810
What is the break point?

800
00:40:32,810 --> 00:40:34,530
That's all we want.

801
00:40:34,530 --> 00:40:36,500
you can call it positive rays.

802
00:40:36,500 --> 00:40:38,020
You can call it George, I don't care!

803
00:40:38,020 --> 00:40:39,930
It has a break point of 2.

804
00:40:39,930 --> 00:40:42,630
That's what I pull.

805
00:40:42,630 --> 00:40:46,440
We did compute the growth
function for the positive rays.

806
00:40:46,440 --> 00:40:47,600
We did it by brute force.

807
00:40:47,600 --> 00:40:49,690
We looked at it, and we see what
the patterns are, and did

808
00:40:49,690 --> 00:40:50,670
a combinatorial argument.

809
00:40:50,670 --> 00:40:54,360
And we ended up, that the growth function
for this guy is N plus 1.

810
00:40:54,360 --> 00:40:57,840
Let us see if this satisfies
the bound.

811
00:40:57,840 --> 00:41:00,160
This is supposedly
less than or equal to.

812
00:41:00,160 --> 00:41:04,100
And you substitute here for
N, which is the number here.

813
00:41:04,100 --> 00:41:05,710
And the break point is k.

814
00:41:05,710 --> 00:41:10,650
So you're summing, from i equals
0 to 1, this quantity.

815
00:41:10,650 --> 00:41:14,310
You have N choose
0, also known as 1.

816
00:41:14,310 --> 00:41:19,040
Plus N choose 1, also known
as N. That's it.

817
00:41:19,040 --> 00:41:21,560
So you get this to be less
than or equal to--

818
00:41:21,560 --> 00:41:22,810
wow!

819
00:41:22,810 --> 00:41:25,230


820
00:41:25,230 --> 00:41:27,430
Look at the analysis we did
to get the N plus 1.

821
00:41:27,430 --> 00:41:28,640
And we get exactly the same.

822
00:41:28,640 --> 00:41:30,130
With all the bounds and--

823
00:41:30,130 --> 00:41:32,540
we think that there is
a big slack here.

824
00:41:32,540 --> 00:41:34,130
But here, actually it's exactly tight.

825
00:41:34,130 --> 00:41:39,460
We get the same answer exactly, without
looking at anything of the geometry of

826
00:41:39,460 --> 00:41:42,490
what the hypothesis set was.

827
00:41:42,490 --> 00:41:43,230
Let's try another one.

828
00:41:43,230 --> 00:41:44,780
Maybe we'll continue to be lucky.

829
00:41:44,780 --> 00:41:45,860
Positive intervals.

830
00:41:45,860 --> 00:41:48,240
Yeah, I remember those were
the more sophisticated--

831
00:41:48,240 --> 00:41:49,110
oh, I'm sorry.

832
00:41:49,110 --> 00:41:51,000
I am not supposed to ask any questions
about the hypothesis.

833
00:41:51,000 --> 00:41:52,680
I'm asking about the break point only.

834
00:41:52,680 --> 00:41:53,800
I remember now.

835
00:41:53,800 --> 00:41:56,100
So tell me what the break point is.

836
00:41:56,100 --> 00:41:58,730
That was k equals 3.

837
00:41:58,730 --> 00:42:01,670
And we did compute the
growth function.

838
00:42:01,670 --> 00:42:03,120
Remember, this one was a funny one.

839
00:42:03,120 --> 00:42:07,950
We're picking two segments out of
N plus 1, and then adding the 1.

840
00:42:07,950 --> 00:42:10,940
So we ended up-- this
would be the formula.

841
00:42:10,940 --> 00:42:14,990
What would be the bound according
to the result we just had?

842
00:42:14,990 --> 00:42:16,380
This would be again, this formula.

843
00:42:16,380 --> 00:42:18,480
And now k equals 3.

844
00:42:18,480 --> 00:42:23,900
So I have N choose 0 plus N
choose 1 plus N choose 2.

845
00:42:23,900 --> 00:42:27,030
I get 1 plus N plus something
that has squared terms.

846
00:42:27,030 --> 00:42:31,900
And I do the reduction
and what do I get?

847
00:42:31,900 --> 00:42:33,550
Boring, boring.

848
00:42:33,550 --> 00:42:36,290
I seem to be getting it all the time.

849
00:42:36,290 --> 00:42:37,520
It doesn't happen this way.

850
00:42:37,520 --> 00:42:40,420
It will always happen
that it's true.

851
00:42:40,420 --> 00:42:44,200
But there will be a slack
in many cases.

852
00:42:44,200 --> 00:42:46,140
So, we verified it.

853
00:42:46,140 --> 00:42:48,050
We are very comfortable
now with the result.

854
00:42:48,050 --> 00:42:53,120
Let's apply it to something where we
could not get the growth function.

855
00:42:53,120 --> 00:42:54,940
Remember this old fellow?

856
00:42:54,940 --> 00:42:57,710
Well, in the two-dimensional perceptron,
we went through a full

857
00:42:57,710 --> 00:43:02,130
argument just to prove that
the break point is 4.

858
00:43:02,130 --> 00:43:05,450
But we didn't bother go through
a general number of points N, and ask

859
00:43:05,450 --> 00:43:09,820
ourselves, how many hypotheses can the
perceptron generate on N points?

860
00:43:09,820 --> 00:43:11,370
Can you imagine the torture?

861
00:43:11,370 --> 00:43:12,500
We do this--

862
00:43:12,500 --> 00:43:14,600
can I get this pattern--

863
00:43:14,600 --> 00:43:17,230
And you have to do this for every
N. So we didn't do it.

864
00:43:17,230 --> 00:43:19,810
The growth function is unknown to us.

865
00:43:19,810 --> 00:43:21,570
We just know the break point.

866
00:43:21,570 --> 00:43:25,240
But using just that factor, we are
able to bound the growth function

867
00:43:25,240 --> 00:43:26,080
completely.

868
00:43:26,080 --> 00:43:28,410
And you substitute again
with k equals 4.

869
00:43:28,410 --> 00:43:30,240
You get another term, which is cubic.

870
00:43:30,240 --> 00:43:31,750
And you do the reduction.

871
00:43:31,750 --> 00:43:34,120
And lo and behold, you
have that statement.

872
00:43:34,120 --> 00:43:37,700
That statement holds for the perceptrons
in two dimensions.

873
00:43:37,700 --> 00:43:40,340
And you can see that this
will apply to anything.

874
00:43:40,340 --> 00:43:44,010
So now it was all worth the trouble,
because now we have a very simple

875
00:43:44,010 --> 00:43:46,870
characterization of hypothesis sets.

876
00:43:46,870 --> 00:43:51,870
And we can take this, and
move to the other part.

877
00:43:51,870 --> 00:43:55,900
Remember, this part, which has now
disappeared is proving that it's

878
00:43:55,900 --> 00:43:56,420
polynomial.

879
00:43:56,420 --> 00:43:59,170
Proving that we are interested
in the growth function.

880
00:43:59,170 --> 00:44:01,340
If it wasn't polynomial, we wouldn't
be interested in it.

881
00:44:01,340 --> 00:44:04,440
Now, this is an interesting
quantity.

882
00:44:04,440 --> 00:44:07,820
This one tells us that-- oh, and by the
way, it's not only interesting.

883
00:44:07,820 --> 00:44:09,670
You actually can use it.

884
00:44:09,670 --> 00:44:12,090
We can put it in the Hoeffding
inequality, and claim that the

885
00:44:12,090 --> 00:44:14,390
Hoeffding inequality is true
using the growth function.

886
00:44:14,390 --> 00:44:16,900


887
00:44:16,900 --> 00:44:24,110
Now let's see what we want, to remind
you of the context of substituting for

888
00:44:24,110 --> 00:44:28,330
the total number of hypotheses
by the growth function.

889
00:44:28,330 --> 00:44:31,630
We wanted, instead of
having this fellow--

890
00:44:31,630 --> 00:44:35,380
this is Hoeffding, and this is the number
of hypotheses using the union

891
00:44:35,380 --> 00:44:37,810
bound, which we said is next
to useless whenever M

892
00:44:37,810 --> 00:44:39,930
is big, or M is infinite.

893
00:44:39,930 --> 00:44:43,020
And instead of that, we wanted
really to substitute for this

894
00:44:43,020 --> 00:44:44,640
by the growth function.

895
00:44:44,640 --> 00:44:46,145
So this is what we are trying to do.

896
00:44:46,145 --> 00:44:49,540
We are trying to justify that instead
of this, you can actually say that.

897
00:44:49,540 --> 00:44:53,140
Well, it turns out that this is not
exactly what we are going to say.

898
00:44:53,140 --> 00:44:56,690
We are going to modify the constants
here for technical reasons that will

899
00:44:56,690 --> 00:44:57,670
become clear.

900
00:44:57,670 --> 00:44:58,970
But the essence is the same.

901
00:44:58,970 --> 00:45:00,560
There would be the growth
function here.

902
00:45:00,560 --> 00:45:03,980
It will be polynomial in N, and it
will be killed by the negative

903
00:45:03,980 --> 00:45:09,280
exponential, provided that there is
a break point-- any break point.

904
00:45:09,280 --> 00:45:10,880
Now, how are we going
to prove that?

905
00:45:10,880 --> 00:45:14,100


906
00:45:14,100 --> 00:45:16,000
We are going to have
a pictorial proof.

907
00:45:16,000 --> 00:45:19,140
What a relief, because I think
you are exhausted by now.

908
00:45:19,140 --> 00:45:22,150
So the formal proof is
in the Appendix.

909
00:45:22,150 --> 00:45:23,830
It's six pages.

910
00:45:23,830 --> 00:45:27,820
My purpose of the presentation here
is to give you the key points in

911
00:45:27,820 --> 00:45:31,690
the proof, so that you don't get
lost in epsilon's and delta's.

912
00:45:31,690 --> 00:45:34,520
There are basically certain things
you need to establish.

913
00:45:34,520 --> 00:45:37,210
And once you know that that's what you
are looking for, you can bite the

914
00:45:37,210 --> 00:45:40,280
bullet and go through it line by line.

915
00:45:40,280 --> 00:45:43,230
The two aspects are the following.

916
00:45:43,230 --> 00:45:46,370
Why did we do this growth function?

917
00:45:46,370 --> 00:45:49,750
We used the growth function because it's
smaller, so it will be helpful.

918
00:45:49,750 --> 00:45:53,020
But how could it possibly replace M?

919
00:45:53,020 --> 00:45:57,860
Because M was assuming no overlaps
at all in the bad regions.

920
00:45:57,860 --> 00:45:58,880
Remember?

921
00:45:58,880 --> 00:46:03,160
So now that we know that there are
overlaps, this will take care of it.

922
00:46:03,160 --> 00:46:06,750
The question is, how does the
growth function actually

923
00:46:06,750 --> 00:46:08,640
relate to the overlaps?

924
00:46:08,640 --> 00:46:10,810
You need to establish that.

925
00:46:10,810 --> 00:46:12,360
So this is the first one.

926
00:46:12,360 --> 00:46:15,680
And when we establish that, we find that
it's a completely clean argument at

927
00:46:15,680 --> 00:46:18,860
everything, except for
one annoying aspect.

928
00:46:18,860 --> 00:46:21,290
Growth function relates
to a finite sample.

929
00:46:21,290 --> 00:46:24,710
So we will get a perfect handle
on the E_in, the in-sample

930
00:46:24,710 --> 00:46:26,590
error part of the deal.

931
00:46:26,590 --> 00:46:29,280
But in the Hoeffding inequality,
there is this E_out.

932
00:46:29,280 --> 00:46:32,740
And E_out relates to the performance
over the entire space.

933
00:46:32,740 --> 00:46:35,270
So we are no longer talking about
dichotomies, we are talking about full

934
00:46:35,270 --> 00:46:36,510
hypotheses.

935
00:46:36,510 --> 00:46:39,920
We lose the benefit of
the growth function.

936
00:46:39,920 --> 00:46:41,440
So what do we do about E out?

937
00:46:41,440 --> 00:46:43,650
That was a question that
was asked last time.

938
00:46:43,650 --> 00:46:48,130
What to do about E_out, in order
to get the argument to conform

939
00:46:48,130 --> 00:46:51,740
while we are just using a finite
sample, is the second step.

940
00:46:51,740 --> 00:46:54,620
After that, it's a technical
putting it together, in order to get

941
00:46:54,620 --> 00:46:55,580
the final result.

942
00:46:55,580 --> 00:46:56,990
That's the plan.

943
00:46:56,990 --> 00:46:58,840
But the proofs are pictures.

944
00:46:58,840 --> 00:47:01,180
So let's have a blank page.

945
00:47:01,180 --> 00:47:06,240
And let's say you are an artist
and this is your canvas.

946
00:47:06,240 --> 00:47:08,400
It's a very special canvas.

947
00:47:08,400 --> 00:47:13,520
It's the canvas of data sets.

948
00:47:13,520 --> 00:47:15,190
What is that?

949
00:47:15,190 --> 00:47:21,110
Every point here is an entire
data set, x_1, x_2, up to x_N.

950
00:47:21,110 --> 00:47:22,600
Fix N in your mind.

951
00:47:22,600 --> 00:47:24,190
So this is one vector.

952
00:47:24,190 --> 00:47:25,190
This is another vector.

953
00:47:25,190 --> 00:47:26,900
This is another vector.

954
00:47:26,900 --> 00:47:32,920
And this canvas covers the entire
set of possible data sets.

955
00:47:32,920 --> 00:47:34,760
Now, why am I doing this space?

956
00:47:34,760 --> 00:47:39,000
Well, I am doing this space because the
event of being good or bad, whether

957
00:47:39,000 --> 00:47:41,610
E_in goes to E out, depends
on the sample.

958
00:47:41,610 --> 00:47:43,040
Depends on the data set.

959
00:47:43,040 --> 00:47:46,410
For some data sets, you will
be close to the E_out.

960
00:47:46,410 --> 00:47:49,380
For some data sets, you are
not going to be close.

961
00:47:49,380 --> 00:47:53,170
So I want to draw it here, in order to
look at the bad regions and the

962
00:47:53,170 --> 00:47:55,450
overlaps, and then argue why
the growth function is

963
00:47:55,450 --> 00:47:57,290
useful for the overlaps.

964
00:47:57,290 --> 00:47:59,430
Now, we assume that there's
a probability distribution.

965
00:47:59,430 --> 00:48:03,150
And for simplicity, let's say that the
area corresponds to the probability.

966
00:48:03,150 --> 00:48:07,280
So the total area of the canvas is 1.

967
00:48:07,280 --> 00:48:11,410
Now, you look at the event, the
bad event, that E_in is

968
00:48:11,410 --> 00:48:12,750
far away from E_out.

969
00:48:12,750 --> 00:48:15,980
And let's say that you paint
the points that correspond

970
00:48:15,980 --> 00:48:17,780
to that event red.

971
00:48:17,780 --> 00:48:19,610
So you pick-- is this data
set good or bad?

972
00:48:19,610 --> 00:48:20,620
What does it mean, good or bad?

973
00:48:20,620 --> 00:48:23,760
I look at E_in in that data set, compare
it to E_out on a particular

974
00:48:23,760 --> 00:48:27,730
hypothesis, and then paint
it red if it's bad.

975
00:48:27,730 --> 00:48:31,770
So I have a hypothesis in mind, and I am
painting the points here red or

976
00:48:31,770 --> 00:48:34,740
leaving them alone, according to whether
they violate Hoeffding's

977
00:48:34,740 --> 00:48:37,530
inequality or not.

978
00:48:37,530 --> 00:48:40,860
And I get this, just illustratively.

979
00:48:40,860 --> 00:48:43,650
And you realize that I didn't
paint a lot of area.

980
00:48:43,650 --> 00:48:46,015
And that is because of
Hoeffding inequality.

981
00:48:46,015 --> 00:48:49,990
Hoeffding inequality tells me
that that area is small.

982
00:48:49,990 --> 00:48:53,540
So I'm entitled to put a small patch.

983
00:48:53,540 --> 00:48:59,860
Now we went from one hypothesis, which
is this guy, to the case where we have

984
00:48:59,860 --> 00:49:02,470
multiple hypotheses, using
the union bound.

985
00:49:02,470 --> 00:49:05,830
So again, this is the space of data
sets, exactly the same one.

986
00:49:05,830 --> 00:49:11,860
And now, I am saying for the first
hypothesis, you get this bad region.

987
00:49:11,860 --> 00:49:14,470
What happens when you have
a second hypothesis?

988
00:49:14,470 --> 00:49:18,200
Because I am using the very pessimistic
union bound, I am hedging

989
00:49:18,200 --> 00:49:23,990
my bets and saying you get
a bad region that is disjoint.

990
00:49:23,990 --> 00:49:26,920
Another hypothesis--

991
00:49:26,920 --> 00:49:27,910
two of them.

992
00:49:27,910 --> 00:49:30,460
More.

993
00:49:30,460 --> 00:49:31,415
More.

994
00:49:31,415 --> 00:49:34,210
Oh, no.

995
00:49:34,210 --> 00:49:35,310
We are in trouble.

996
00:49:35,310 --> 00:49:37,170
The colored area is the bad area.

997
00:49:37,170 --> 00:49:39,380
Now the canvas is the bad area.

998
00:49:39,380 --> 00:49:42,790
That's why we get the problem
with the union bound.

999
00:49:42,790 --> 00:49:46,640
Because obviously, having them disjoint
fills up the canvas very quickly.

1000
00:49:46,640 --> 00:49:48,890
Each of them is small, but
I have so many of them.

1001
00:49:48,890 --> 00:49:50,360
Infinity of them as a matter of fact.

1002
00:49:50,360 --> 00:49:51,280
This will overflow.

1003
00:49:51,280 --> 00:49:52,580
Well, no, it won't overflow.

1004
00:49:52,580 --> 00:49:54,660
Just figuratively speaking.

1005
00:49:54,660 --> 00:49:57,010
So that's what I'm going to have.

1006
00:49:57,010 --> 00:50:00,180
What is the argument
we are applying now?

1007
00:50:00,180 --> 00:50:01,850
We are not applying the union bound.

1008
00:50:01,850 --> 00:50:04,440
We are going to a new canvas.

1009
00:50:04,440 --> 00:50:10,700
And that canvas is called the VC bound,
as in Vapnik-Chervonenkis.

1010
00:50:10,700 --> 00:50:12,570
We'll see it in a moment.

1011
00:50:12,570 --> 00:50:13,400
So what do you do?

1012
00:50:13,400 --> 00:50:16,660
Your first hypothesis, same thing.

1013
00:50:16,660 --> 00:50:19,320
When you take the second hypothesis,
you take the overlaps into

1014
00:50:19,320 --> 00:50:21,340
consideration.

1015
00:50:21,340 --> 00:50:22,870
So it falls here.

1016
00:50:22,870 --> 00:50:24,270
You get more.

1017
00:50:24,270 --> 00:50:26,110
You get more.

1018
00:50:26,110 --> 00:50:27,360
You get all of them.

1019
00:50:27,360 --> 00:50:30,000


1020
00:50:30,000 --> 00:50:32,500
It's not as good as the first one.

1021
00:50:32,500 --> 00:50:34,130
I never expected it to be.

1022
00:50:34,130 --> 00:50:37,040
But definitely not as bad as the
second one, because now they are

1023
00:50:37,040 --> 00:50:37,600
overlapping.

1024
00:50:37,600 --> 00:50:41,200
And indeed, the total area, which is
the bad region-- something bad

1025
00:50:41,200 --> 00:50:42,000
happening--

1026
00:50:42,000 --> 00:50:44,070
is a small fraction of
the whole thing.

1027
00:50:44,070 --> 00:50:46,610
And I can learn.

1028
00:50:46,610 --> 00:50:50,180
So we are trying to characterize
this overlap.

1029
00:50:50,180 --> 00:50:52,620
That's the whole deal with
the growth function.

1030
00:50:52,620 --> 00:50:56,910
One way to do it is the one that
I alluded to before. Study the

1031
00:50:56,910 --> 00:50:58,030
hypothesis set.

1032
00:50:58,030 --> 00:50:59,930
Study the probability distribution.

1033
00:50:59,930 --> 00:51:02,940
Get the full joint probability
distribution of any two events

1034
00:51:02,940 --> 00:51:06,480
involving two hypotheses, and
then characterize this.

1035
00:51:06,480 --> 00:51:08,170
Well, good luck!

1036
00:51:08,170 --> 00:51:09,780
We won't do that.

1037
00:51:09,780 --> 00:51:12,950
The reason we introduced the growth
function, because it's an abstract

1038
00:51:12,950 --> 00:51:16,810
quantity that is simple, and is going
to characterize the overlaps.

1039
00:51:16,810 --> 00:51:19,530
The question is, how is the
growth function going to

1040
00:51:19,530 --> 00:51:20,930
characterize the overlaps?

1041
00:51:20,930 --> 00:51:24,480
Here is what is going to happen.

1042
00:51:24,480 --> 00:51:29,510
I will tell you that if you look at
this canvas, if any point gets

1043
00:51:29,510 --> 00:51:36,050
painted at all, it will get
painted over 100 times.

1044
00:51:36,050 --> 00:51:38,050
Let's say that I have that guarantee.

1045
00:51:38,050 --> 00:51:40,330
I don't know which hypotheses
will paint it again.

1046
00:51:40,330 --> 00:51:46,650
But any point that gets a red, it will
get a blue, and a green-- 100 times.

1047
00:51:46,650 --> 00:51:50,020
If I tell you that statement, what
do you know about the total

1048
00:51:50,020 --> 00:51:52,650
area that is colored?

1049
00:51:52,650 --> 00:51:57,480
Now it's, at most, one hundredth
of what it used to be.

1050
00:51:57,480 --> 00:52:00,330
Because when I had them non-overlapping,
they filled it over.

1051
00:52:00,330 --> 00:52:03,300
Now for every point that is colored,
I have to do it 100 times.

1052
00:52:03,300 --> 00:52:06,560
So I am overusing these guys, and
these guys will have to shrink.

1053
00:52:06,560 --> 00:52:09,160
And I will get one hundredth of that.

1054
00:52:09,160 --> 00:52:11,150
That is basically the essence
of the argument.

1055
00:52:11,150 --> 00:52:14,750
What the growth function tells you is
that-- what is the growth function?

1056
00:52:14,750 --> 00:52:15,710
Number of dichotomies.

1057
00:52:15,710 --> 00:52:19,150
If you take a dichotomy, this is not
the full hypothesis, but the

1058
00:52:19,150 --> 00:52:21,770
hypothesis on a finite set of points.

1059
00:52:21,770 --> 00:52:28,860
There are many, many hypotheses that
return the exact same dichotomy.

1060
00:52:28,860 --> 00:52:32,240
Remember the gray sheet
with the holes.

1061
00:52:32,240 --> 00:52:34,410
Lots of stuff can be happening
behind the sheet.

1062
00:52:34,410 --> 00:52:37,610
And as far am I am concerned, they
are all the same dichotomy.

1063
00:52:37,610 --> 00:52:41,410
So all of these guys will be behaving
exactly the same way.

1064
00:52:41,410 --> 00:52:45,520
If one of them colored the
point, the others will.

1065
00:52:45,520 --> 00:52:48,520
This tells me that the
redundancy is captured

1066
00:52:48,520 --> 00:52:50,700
by the growth function.

1067
00:52:50,700 --> 00:52:52,780
That would be a very clean argument.

1068
00:52:52,780 --> 00:52:57,200
And it would have been a very simple
proof, except for one annoyance.

1069
00:52:57,200 --> 00:53:01,780
That the point being colored doesn't
depend only on the sample, but depends

1070
00:53:01,780 --> 00:53:03,680
also on the entire space.

1071
00:53:03,680 --> 00:53:06,850
Because the point gets colored
because it's a bad point.

1072
00:53:06,850 --> 00:53:08,190
What is a bad point?

1073
00:53:08,190 --> 00:53:12,810
The frequency on the sample, that is
patently on the sample, deviates

1074
00:53:12,810 --> 00:53:14,850
from E_out.

1075
00:53:14,850 --> 00:53:17,340
Oh, E_out involves the
entire hypothesis.

1076
00:53:17,340 --> 00:53:21,110
If I have the gray sheet and the
holes, I cannot compute E out.

1077
00:53:21,110 --> 00:53:26,290
I have to peel it off, look, and get
the areas in order to get E out.

1078
00:53:26,290 --> 00:53:31,850
So the argument is great, as long as you
can tell me how do I go around

1079
00:53:31,850 --> 00:53:33,720
the presence of E_out?

1080
00:53:33,720 --> 00:53:35,450
And that's the second
part of the proof.

1081
00:53:35,450 --> 00:53:39,090


1082
00:53:39,090 --> 00:53:41,300
What to do about E_out.

1083
00:53:41,300 --> 00:53:44,300
The simplest argument possible.

1084
00:53:44,300 --> 00:53:46,570
That is really the breakthrough
that Vapnik and

1085
00:53:46,570 --> 00:53:48,840
Chervonenkis did.

1086
00:53:48,840 --> 00:53:51,960
Back to the bin, just because it's
an illustration of the binary case.

1087
00:53:51,960 --> 00:53:54,940
So here, we have one hypothesis.

1088
00:53:54,940 --> 00:53:59,800
And we have E out, which is the
overall, in the entire space--

1089
00:53:59,800 --> 00:54:01,910
the error in the entire space.

1090
00:54:01,910 --> 00:54:06,600
We pick a sample, and then we get E_in,
which is the value for the error

1091
00:54:06,600 --> 00:54:07,170
on this one.

1092
00:54:07,170 --> 00:54:08,730
So we have seen this before.

1093
00:54:08,730 --> 00:54:12,780
And we said this tracks this, according
to the Hoeffding inequality.

1094
00:54:12,780 --> 00:54:16,320
And the problem is that when you have
many, many bins, some of these guys

1095
00:54:16,320 --> 00:54:19,750
will start deviating from E_out, to the
level if you pick according to the

1096
00:54:19,750 --> 00:54:22,660
sample, you are no longer sure that
you picked the right one, because the

1097
00:54:22,660 --> 00:54:23,720
deviation could be big.

1098
00:54:23,720 --> 00:54:25,240
That was the argument.

1099
00:54:25,240 --> 00:54:27,172
Now, I want to get rid of E_out.

1100
00:54:27,172 --> 00:54:29,180
The way I am going to do it is this.

1101
00:54:29,180 --> 00:54:31,810


1102
00:54:31,810 --> 00:54:38,020
Instead of picking one sample, I
am going to pick two samples,

1103
00:54:38,020 --> 00:54:40,010
independently.

1104
00:54:40,010 --> 00:54:41,630
So obviously, they are not
identical samples.

1105
00:54:41,630 --> 00:54:43,140
Some of them are green
or red, et cetera.

1106
00:54:43,140 --> 00:54:45,660
But they are coming from
the same distribution.

1107
00:54:45,660 --> 00:54:48,860
Now, let's see what is going on.

1108
00:54:48,860 --> 00:54:53,150
E_out and E_in track each other, because
E_in is generated from this

1109
00:54:53,150 --> 00:54:55,580
distribution.

1110
00:54:55,580 --> 00:55:00,340
Now, let's say I look at these two
samples and give them names.

1111
00:55:00,340 --> 00:55:04,240
I am going to call them
E_in and E_in dash.

1112
00:55:04,240 --> 00:55:05,340
They're both in-sample.

1113
00:55:05,340 --> 00:55:06,150
It happens to be a different sample.

1114
00:55:06,150 --> 00:55:07,620
So I have two samples.

1115
00:55:07,620 --> 00:55:11,320
I am going to call this E_in,
and this E_in dash.

1116
00:55:11,320 --> 00:55:19,750
My question is, does E_in track
E_in dash, if you have one bin?

1117
00:55:19,750 --> 00:55:23,820
Well, each of them tracks
E_out, right?

1118
00:55:23,820 --> 00:55:25,440
Because it was generated by it.

1119
00:55:25,440 --> 00:55:28,750
So consequently, they
track each other.

1120
00:55:28,750 --> 00:55:32,390
A bit more loosely, because
you have now two ways of

1121
00:55:32,390 --> 00:55:34,310
getting the sample error.

1122
00:55:34,310 --> 00:55:38,550
On the other hand, if I do
two presidential polls--

1123
00:55:38,550 --> 00:55:41,470
one polling asks 3000 people.

1124
00:55:41,470 --> 00:55:43,310
Another asks 3000 people.

1125
00:55:43,310 --> 00:55:45,250
These are different 3000 people.

1126
00:55:45,250 --> 00:55:50,350
You fully expect that the result will
be close to each other, right?

1127
00:55:50,350 --> 00:55:52,990
So these guys track each other.

1128
00:55:52,990 --> 00:55:54,490
OK, fine.

1129
00:55:54,490 --> 00:55:55,280
What is the advantage?

1130
00:55:55,280 --> 00:55:57,220
The advantage is the following.

1131
00:55:57,220 --> 00:56:03,010
If I now have multiple bins, the
problem I had here is reflected

1132
00:56:03,010 --> 00:56:06,170
exactly in the new tracking.

1133
00:56:06,170 --> 00:56:11,040
When I had multiple bins, the tie
between E_out and E_in became looser

1134
00:56:11,040 --> 00:56:11,890
and looser.

1135
00:56:11,890 --> 00:56:16,490
Because I'm looking for worst case, and
I might be unlucky enough, that the

1136
00:56:16,490 --> 00:56:24,340
tracking now lost the tightness that one
bin with Hoeffding would dictate.

1137
00:56:24,340 --> 00:56:27,870
If I am doing multiple bins, and not
looking at the bin at all, just

1138
00:56:27,870 --> 00:56:32,890
looking at the two samples from each
bin, they track each other, but they

1139
00:56:32,890 --> 00:56:37,470
also get loosely apart
as I go for more.

1140
00:56:37,470 --> 00:56:40,540
Let's say, I tell you this experiment.

1141
00:56:40,540 --> 00:56:42,280
You pick two samples.

1142
00:56:42,280 --> 00:56:45,550
They are close in terms of
the fraction of red.

1143
00:56:45,550 --> 00:56:49,650
If you keep repeating it, can you get
one sample to be mostly red, and the

1144
00:56:49,650 --> 00:56:51,700
other sample to be mostly green?

1145
00:56:51,700 --> 00:56:52,110
Yeah.

1146
00:56:52,110 --> 00:56:53,950
If you are patient enough,
it will happen.

1147
00:56:53,950 --> 00:56:56,410
Exactly for the same reason,
because you keep looking

1148
00:56:56,410 --> 00:56:58,360
for it until it happens.

1149
00:56:58,360 --> 00:57:03,660
So the mathematical ramifications of
multiple hypotheses happen here,

1150
00:57:03,660 --> 00:57:06,710
exactly the same way they happen here.

1151
00:57:06,710 --> 00:57:10,250
The finesse now is that, if I
characterize it using the two

1152
00:57:10,250 --> 00:57:15,860
samples, then I am completely
in the realm of dichotomies.

1153
00:57:15,860 --> 00:57:17,840
Because now I'm not appealing
to E_out at all.

1154
00:57:17,840 --> 00:57:20,280
I am only appealing to what
happens in a sample.

1155
00:57:20,280 --> 00:57:21,850
It's a bigger sample.

1156
00:57:21,850 --> 00:57:27,030
I have 2N marbles now instead of N.
But still, I can define a growth

1157
00:57:27,030 --> 00:57:28,200
function on them.

1158
00:57:28,200 --> 00:57:31,600
And now the characterization is
full, and I am ready to go.

1159
00:57:31,600 --> 00:57:34,240
These are the only two components
you need to worry about as

1160
00:57:34,240 --> 00:57:36,550
you read the proof.

1161
00:57:36,550 --> 00:57:39,610
Now, let's put it together.

1162
00:57:39,610 --> 00:57:42,270


1163
00:57:42,270 --> 00:57:43,670
This is what we wanted.

1164
00:57:43,670 --> 00:57:44,650
This is not true.

1165
00:57:44,650 --> 00:57:45,900
Don't hold this against me.

1166
00:57:45,900 --> 00:57:49,340
And to make sure, this is
not quite what we have.

1167
00:57:49,340 --> 00:57:53,530
This would be direct substitution of the
plain-vanilla growth function in

1168
00:57:53,530 --> 00:57:56,500
terms of M.

1169
00:57:56,500 --> 00:58:03,850
We are not going to have that, but we
are going instead to have this.

1170
00:58:03,850 --> 00:58:05,100
Lets look and compare.

1171
00:58:05,100 --> 00:58:08,450


1172
00:58:08,450 --> 00:58:12,210
These look the same, except
that this 2 became 4.

1173
00:58:12,210 --> 00:58:13,790
Is this good or bad?

1174
00:58:13,790 --> 00:58:14,650
Well, it's bad.

1175
00:58:14,650 --> 00:58:16,430
We want this probability to be small.

1176
00:58:16,430 --> 00:58:17,680
Bad, but not fatal.

1177
00:58:17,680 --> 00:58:19,930


1178
00:58:19,930 --> 00:58:21,850
This one goes to here.

1179
00:58:21,850 --> 00:58:22,810
I have twice the sample.

1180
00:58:22,810 --> 00:58:24,710
You know why I have 2 now.

1181
00:58:24,710 --> 00:58:29,275
Because now I use the bigger sample
for the argument, so I need 2N.

1182
00:58:29,275 --> 00:58:32,550
Oh, but all of this was about
a polynomial and now I don't know

1183
00:58:32,550 --> 00:58:33,590
whether this will be a polynomial.

1184
00:58:33,590 --> 00:58:34,970
Yes, you do.

1185
00:58:34,970 --> 00:58:37,850
If it's polynomial in N, it's
polynomial in N here.

1186
00:58:37,850 --> 00:58:40,630
Because you get 2N to the
k, then you get 2 to the k.

1187
00:58:40,630 --> 00:58:42,130
That's a constant.

1188
00:58:42,130 --> 00:58:44,250
And you still get N to the k.

1189
00:58:44,250 --> 00:58:45,910
So that remains a polynomial.

1190
00:58:45,910 --> 00:58:47,130
A bigger polynomial.

1191
00:58:47,130 --> 00:58:49,780
I don't like it, but you
don't have to like it.

1192
00:58:49,780 --> 00:58:53,230
It just has to be true, and
do the job we want.

1193
00:58:53,230 --> 00:58:56,380
And finally, you can see this is minus
2, which was a very helpful factor.

1194
00:58:56,380 --> 00:58:57,960
This is in the exponent.

1195
00:58:57,960 --> 00:59:01,170
2 in the exponent goes
a lot of mileage.

1196
00:59:01,170 --> 00:59:03,830
And now we knock it down
all the way to 1/8.

1197
00:59:03,830 --> 00:59:06,400
That's really, really bad news.

1198
00:59:06,400 --> 00:59:08,840
The reason this is happening
is that, as we go through the

1199
00:59:08,840 --> 00:59:13,340
technicalities of the proof, the epsilon
will become epsilon over 2.

1200
00:59:13,340 --> 00:59:17,310
And then will become epsilon over 4, just
to take care of different steps.

1201
00:59:17,310 --> 00:59:20,480
And when you plug in epsilon over 4
here, you get epsilon squared over 16.

1202
00:59:20,480 --> 00:59:22,200
And so you get a factor of 1/8.

1203
00:59:22,200 --> 00:59:24,320
That's the reason for it.

1204
00:59:24,320 --> 00:59:26,140
So this is what we will end up with.

1205
00:59:26,140 --> 00:59:29,530
And you can be finicky and try to
improve this constant a lot, but the

1206
00:59:29,530 --> 00:59:35,020
basic message is that here is
a statement that holds true for any

1207
00:59:35,020 --> 00:59:37,210
hypothesis set that has a break point.

1208
00:59:37,210 --> 00:59:44,020
And this fellow is polynomial in N,
with the order of the polynomial

1209
00:59:44,020 --> 00:59:45,370
decided by the break point.

1210
00:59:45,370 --> 00:59:49,460
And you will eventually learn, because
if N is big enough-- if I give you

1211
00:59:49,460 --> 00:59:53,435
enough examples-- using that hypothesis,
you will be able to claim that E_in

1212
00:59:53,435 --> 00:59:56,610
tracks E_out correctly.

1213
00:59:56,610 --> 01:00:01,560
This result, which is called the
Vapnik-Chervonenkis inequality, is the

1214
01:00:01,560 --> 01:00:06,120
most important theoretical result
in machine learning.

1215
01:00:06,120 --> 01:00:09,730
On that happy note, we will stop
here and take questions

1216
01:00:09,730 --> 01:00:10,980
after a short break.

1217
01:00:10,980 --> 01:00:19,140


1218
01:00:19,140 --> 01:00:22,730
Let's start the Q&amp;A.

1219
01:00:22,730 --> 01:00:29,260
MODERATOR: First, a few
clarifications from the beginning.

1220
01:00:29,260 --> 01:00:29,270


1221
01:00:29,270 --> 01:00:40,450
In slide 5, when you choose the N points,
does it mean your data set is

1222
01:00:40,450 --> 01:00:44,710
of N points, or you just chose
N points from the data set?

1223
01:00:44,710 --> 01:00:50,170
PROFESSOR: When I apply this to an actual
hypothesis set in an input space, then

1224
01:00:50,170 --> 01:00:50,180


1225
01:00:50,180 --> 01:00:52,730
these actually correspond
to a particular set of

1226
01:00:52,730 --> 01:00:54,970
points in that space.

1227
01:00:54,970 --> 01:01:00,810
However, in the abstraction that just
defines the function B, these are just

1228
01:01:00,810 --> 01:01:02,290
abstract labels.

1229
01:01:02,290 --> 01:01:06,220
These are labels for which
column I'm talking about.

1230
01:01:06,220 --> 01:01:11,740
So although I call them x_1 up to
x_N-1, these are not really--

1231
01:01:11,740 --> 01:01:14,380
in the abstraction here, they don't
correspond to any particular input

1232
01:01:14,380 --> 01:01:15,050
space in mind.

1233
01:01:15,050 --> 01:01:17,910
But when they do, they will
correspond to a sample.

1234
01:01:17,910 --> 01:01:21,490
And I am supposed to pick the sample
in that space that maximizes the

1235
01:01:21,490 --> 01:01:25,200
number of dichotomies, et cetera, as
we defined the growth function.

1236
01:01:25,200 --> 01:01:29,340
But it's a sample that I pick when I
apply this to a particular input space

1237
01:01:29,340 --> 01:01:30,590
and a hypothesis set.

1238
01:01:30,590 --> 01:01:32,900


1239
01:01:32,900 --> 01:01:36,850
MODERATOR: Also, there are
some people asking--

1240
01:01:36,850 --> 01:01:36,860


1241
01:01:36,860 --> 01:01:40,590
they didn't understand exactly why
alpha was different to beta.

1242
01:01:40,590 --> 01:01:41,900
PROFESSOR: alpha
is different from beta?

1243
01:01:41,900 --> 01:01:42,655
MODERATOR: Yeah. Why?

1244
01:01:42,655 --> 01:01:42,660


1245
01:01:42,660 --> 01:01:47,480
PROFESSOR: Well, the short
answer is that I never made the

1246
01:01:47,480 --> 01:01:49,530
statement that alpha is
different from beta.

1247
01:01:49,530 --> 01:01:54,170
I just didn't bother ascertain any
relationship between alpha and beta.

1248
01:01:54,170 --> 01:01:55,380
I just called them names.

1249
01:01:55,380 --> 01:01:56,790
If they happen to be
equal, I am happy.

1250
01:01:56,790 --> 01:01:58,660
If they happen to be
unequal, I am happy.

1251
01:01:58,660 --> 01:02:02,670
So all I'm doing here is just calling
the guys that happen to have a single

1252
01:02:02,670 --> 01:02:05,740
extension, the number of
them, calling it alpha.

1253
01:02:05,740 --> 01:02:10,190
Calling the guys that happen to
have double extension beta.

1254
01:02:10,190 --> 01:02:13,010
I don't know whether alpha is bigger
than beta, or smaller than beta, in any

1255
01:02:13,010 --> 01:02:14,060
particular case.

1256
01:02:14,060 --> 01:02:16,830
And it doesn't matter as far as
the analysis is concerned.

1257
01:02:16,830 --> 01:02:20,110
If I call them this way, then it will
always be true that the total number

1258
01:02:20,110 --> 01:02:24,730
of rows here is alpha plus beta plus
beta, which is alpha plus twice beta.

1259
01:02:24,730 --> 01:02:29,890
So there is really no assertion about
the relative value of alpha and beta.

1260
01:02:29,890 --> 01:02:35,040
MODERATOR: Moving on to the case
where you show the break points, and

1261
01:02:35,040 --> 01:02:36,910
how it satisfies the bound.

1262
01:02:36,910 --> 01:02:39,930
What happens if k equals infinity?

1263
01:02:39,930 --> 01:02:44,010
No break points, basically.

1264
01:02:44,010 --> 01:02:47,000
PROFESSOR: This is for the
positive rays and whatnot?

1265
01:02:47,000 --> 01:02:47,560
MODERATOR: Yeah.

1266
01:02:47,560 --> 01:02:50,966
So for example, if you
had the convex sets.

1267
01:02:50,966 --> 01:02:53,770
PROFESSOR: k equals infinity
means there is no break point.

1268
01:02:53,770 --> 01:02:57,090
In that case, you don't have to bother
with any of the analysis I did.

1269
01:02:57,090 --> 01:02:58,890
No break points means what?

1270
01:02:58,890 --> 01:03:02,790
Means the growth function is
2 to the N for every N, right? We

1271
01:03:02,790 --> 01:03:04,780
just computed it exactly.

1272
01:03:04,780 --> 01:03:07,710
If you want a bound for it, yes,
it's bounded by 2 to the N. Not

1273
01:03:07,710 --> 01:03:09,130
a polynomial.

1274
01:03:09,130 --> 01:03:11,820
So all of these cases, we're addressing
the case where there is

1275
01:03:11,820 --> 01:03:15,860
a break point, because that is the case
where I can guarantee a polynomial.

1276
01:03:15,860 --> 01:03:18,150
And therefore, I can
guarantee learning.

1277
01:03:18,150 --> 01:03:19,300
That is the interesting case.

1278
01:03:19,300 --> 01:03:23,770
If there is no break point, this
theoretical line of analysis will not

1279
01:03:23,770 --> 01:03:25,300
guarantee learning.

1280
01:03:25,300 --> 01:03:28,810
So if I have a hypothesis set that
happens to be able to shatter every

1281
01:03:28,810 --> 01:03:33,610
set of points, I cannot make a statement
using this line of analysis

1282
01:03:33,610 --> 01:03:34,790
that it will learn.

1283
01:03:34,790 --> 01:03:37,270
And one example we had
was convex sets.

1284
01:03:37,270 --> 01:03:41,250
So convex sets have a growth function
of 2 to the N. Well, it really is

1285
01:03:41,250 --> 01:03:44,930
a very pessimistic estimate here, because
the points have to be really, really

1286
01:03:44,930 --> 01:03:45,280
very funny.

1287
01:03:45,280 --> 01:03:48,350
You have to build the pathological case,
in order not to be able to learn.

1288
01:03:48,350 --> 01:03:50,530
And in many cases, you might be.

1289
01:03:50,530 --> 01:03:54,820
But again, if I want a uniform statement
based only on the break

1290
01:03:54,820 --> 01:03:58,420
point, this is the most I can say
using this line of analysis.

1291
01:03:58,420 --> 01:04:04,050


1292
01:04:04,050 --> 01:04:06,450
MODERATOR: OK.

1293
01:04:06,450 --> 01:04:09,020
Just a quick review.

1294
01:04:09,020 --> 01:04:11,710
How is the break point calculated?

1295
01:04:11,710 --> 01:04:12,530
PROFESSOR: Calculated.

1296
01:04:12,530 --> 01:04:15,940
The break point is-- this is the only
time you actually need to visit the

1297
01:04:15,940 --> 01:04:18,400
input space and the hypothesis set.

1298
01:04:18,400 --> 01:04:22,630
You basically-- you are sitting in
a room with your hypothesis set.

1299
01:04:22,630 --> 01:04:24,980
Someone gave you a problem
for credit approval.

1300
01:04:24,980 --> 01:04:29,110
You decided to use perceptrons, and
you decided to use a nonlinear

1301
01:04:29,110 --> 01:04:29,930
transformation.

1302
01:04:29,930 --> 01:04:32,230
And you do all of that, and you
start programming it.

1303
01:04:32,230 --> 01:04:35,630
And you would like to know some
prediction of the generalization

1304
01:04:35,630 --> 01:04:38,160
performance that you are going to get.

1305
01:04:38,160 --> 01:04:41,040
So you go into the room, and ask yourself:
for this hypothesis set, over

1306
01:04:41,040 --> 01:04:41,800
this input space,

1307
01:04:41,800 --> 01:04:43,290
what is the break point?

1308
01:04:43,290 --> 01:04:47,310
So now you have to actually go and
study your hypothesis set.

1309
01:04:47,310 --> 01:04:50,720
And then find out that using this
hypothesis set, I cannot separate,

1310
01:04:50,720 --> 01:04:52,860
let's say, 10 points in
every possible way.

1311
01:04:52,860 --> 01:04:56,030
Very much along the argument we used for
the perceptron in two dimensions.

1312
01:04:56,030 --> 01:05:00,800
We found out that we cannot separate
four points in every possible way.

1313
01:05:00,800 --> 01:05:04,650
But the good news is that, you don't have
to do it anew, because for most of

1314
01:05:04,650 --> 01:05:08,370
the famous learning models, this
has already been done.

1315
01:05:08,370 --> 01:05:11,960
For the perceptrons, we will
get an exact break point.

1316
01:05:11,960 --> 01:05:14,050
For any-dimensional perceptron.

1317
01:05:14,050 --> 01:05:16,590
So 20-dimensional perceptron,
here's the break point, and

1318
01:05:16,590 --> 01:05:17,680
here's the growth function.

1319
01:05:17,680 --> 01:05:19,270
Or, here's the bound.

1320
01:05:19,270 --> 01:05:22,150
Similarity from neural networks,
there is a break point.

1321
01:05:22,150 --> 01:05:25,460
Not exact estimate of the break point,
but a bound on the break point.

1322
01:05:25,460 --> 01:05:28,850
And again, in most of these cases,
bounds work, because we are always

1323
01:05:28,850 --> 01:05:30,440
trying to bound above.

1324
01:05:30,440 --> 01:05:34,730
And we have room to play with, because
a polynomial is a polynomial

1325
01:05:34,730 --> 01:05:35,810
is a polynomial.

1326
01:05:35,810 --> 01:05:40,530
So if you become a little bit sloppy
and forget something, and the break

1327
01:05:40,530 --> 01:05:42,370
point-- you say 10 instead of 7--

1328
01:05:42,370 --> 01:05:45,380
it's not going to break the back of
learning versus non-learning.

1329
01:05:45,380 --> 01:05:49,830
It's just going to tell you more
pessimistically, how much resources do

1330
01:05:49,830 --> 01:05:51,180
you need in order to learn?

1331
01:05:51,180 --> 01:05:54,825
Which is more benign damage
than deciding, oh, I

1332
01:05:54,825 --> 01:05:57,460
cannot learn at all.

1333
01:05:57,460 --> 01:05:58,710
MODERATOR: OK.

1334
01:05:58,710 --> 01:06:00,790


1335
01:06:00,790 --> 01:06:06,910
Can you come up with an example, where
these bounds are not tight as here?

1336
01:06:06,910 --> 01:06:09,430
PROFESSOR: There's one case,
which I could have covered but I

1337
01:06:09,430 --> 01:06:13,860
didn't, where you take positive
and negative rays.

1338
01:06:13,860 --> 01:06:16,160
So positive rays, you
take the real line.

1339
01:06:16,160 --> 01:06:19,510
And from a point on it's +1.
Before, it's -1.

1340
01:06:19,510 --> 01:06:23,640
Positive and negative rays, it means you
are also allowed to take rays that

1341
01:06:23,640 --> 01:06:26,900
return +1 first, and
then -1 later.

1342
01:06:26,900 --> 01:06:30,550
And the union of them is the model
called positive and negative rays.

1343
01:06:30,550 --> 01:06:31,740
It's a good exercise to do.

1344
01:06:31,740 --> 01:06:34,270
Take that home and try to find,
what is the break point?

1345
01:06:34,270 --> 01:06:37,100
And you'll find that although the break
point for positive rays is 2,

1346
01:06:37,100 --> 01:06:39,290
in this case the break
point is actually 3.

1347
01:06:39,290 --> 01:06:43,257
And the reason is that for two points,
now you can get everything because you

1348
01:06:43,257 --> 01:06:44,620
know the ray can be here.

1349
01:06:44,620 --> 01:06:46,030
So they are both minus.

1350
01:06:46,030 --> 01:06:47,030
The ray could be here.

1351
01:06:47,030 --> 01:06:48,080
They are both plus.

1352
01:06:48,080 --> 01:06:49,040
The ray could be here.

1353
01:06:49,040 --> 01:06:50,280
It's minus plus.

1354
01:06:50,280 --> 01:06:53,750
But now, use the negative ray
to get the +1, -1.

1355
01:06:53,750 --> 01:06:55,640
So now you can shatter two points.

1356
01:06:55,640 --> 01:06:58,000
And you would fail only for the three
points, when the middle guy is

1357
01:06:58,000 --> 01:07:00,330
different, because you cannot
get it this way.

1358
01:07:00,330 --> 01:07:02,060
So you will get-- and the
break point is 3.

1359
01:07:02,060 --> 01:07:04,390
When you do the break point of
3, you will get the bound,

1360
01:07:04,390 --> 01:07:05,450
the blue bound here.

1361
01:07:05,450 --> 01:07:06,720
You will get that to be squared.

1362
01:07:06,720 --> 01:07:09,370
Pretty much like here, because we have
a break point that corresponds

1363
01:07:09,370 --> 01:07:10,340
directly to squared.

1364
01:07:10,340 --> 01:07:13,520
I don't care whether the 3 is coming
from positive intervals, or coming from

1365
01:07:13,520 --> 01:07:15,190
positive and negative rays.

1366
01:07:15,190 --> 01:07:15,470
It's 3.

1367
01:07:15,470 --> 01:07:17,690
Therefore, the blue bound
is quadratic.

1368
01:07:17,690 --> 01:07:22,370
If you compute the number of dichotomies
you can get, which is the

1369
01:07:22,370 --> 01:07:24,620
growth function, it will
actually be linear.

1370
01:07:24,620 --> 01:07:27,730
So there will be a discrepancy between
linear for the exact estimate of the

1371
01:07:27,730 --> 01:07:30,320
growth function, to quadratic
of the bound.

1372
01:07:30,320 --> 01:07:31,520
So there are cases that
you can come up with, easily.

1373
01:07:31,520 --> 01:07:34,450
And as a matter of fact, this
is the exception on this,

1374
01:07:34,450 --> 01:07:35,330
rather than the rule.

1375
01:07:35,330 --> 01:07:37,140
In most of the cases, there
will be a slack.

1376
01:07:37,140 --> 01:07:39,770


1377
01:07:39,770 --> 01:07:43,710
MODERATOR: And this question drives
the point of the whole lecture.

1378
01:07:43,710 --> 01:07:43,720


1379
01:07:43,720 --> 01:07:49,555
It says, we have been focusing on
having E_in equal to E_out, or close

1380
01:07:49,555 --> 01:07:54,720
to E_out, not in the
actual value of E_in.

1381
01:07:54,720 --> 01:07:58,300
So using our hypotheses, there are just
as many percentage errors in the

1382
01:07:58,300 --> 01:07:59,850
training data as the real data.

1383
01:07:59,850 --> 01:08:02,090
Why is that?

1384
01:08:02,090 --> 01:08:04,880
PROFESSOR: This goes back to
separating the question of learning

1385
01:08:04,880 --> 01:08:06,620
into the two questions.

1386
01:08:06,620 --> 01:08:08,820
There was one question which
was addressed now.

1387
01:08:08,820 --> 01:08:11,850
We are trying to get E_in
to track E_out.

1388
01:08:11,850 --> 01:08:13,160
Why do I need that?

1389
01:08:13,160 --> 01:08:16,700
Because I don't know E_out, and
I will not know E_out.

1390
01:08:16,700 --> 01:08:19,270
That is simply an unknown
quantity for me.

1391
01:08:19,270 --> 01:08:21,260
And I want to work with
something to minimize.

1392
01:08:21,260 --> 01:08:23,520
I cannot minimize something
that I don't know.

1393
01:08:23,520 --> 01:08:28,340
So if the theoretical guarantees tell me
that E_in is a proxy for E_out, and

1394
01:08:28,340 --> 01:08:30,800
if I minimize E_in, E_out
will follow suit.

1395
01:08:30,800 --> 01:08:33,700
Then I can now work with a quantity
that I know, and do it.

1396
01:08:33,700 --> 01:08:35,939
That's the first part, that
they are tracking each other.

1397
01:08:35,939 --> 01:08:37,220
The second part is the practical.

1398
01:08:37,220 --> 01:08:40,569
Now, I am going to go and
try to minimize E_in.

1399
01:08:40,569 --> 01:08:45,140
This is the second part of it.

1400
01:08:45,140 --> 01:08:46,800
MODERATOR: Also, they're asking if--

1401
01:08:46,800 --> 01:08:52,220
can you clarify more, why
is the VC dimension useful?

1402
01:08:52,220 --> 01:08:54,630
PROFESSOR: The VC dimension,
as of now, is an unknown quantity.

1403
01:08:54,630 --> 01:08:56,390
I didn't say that word "VC
dimension" at all.

1404
01:08:56,390 --> 01:09:00,140
I said every building block that
will result in the definition.

1405
01:09:00,140 --> 01:09:02,999
However, the good news is, what is
the title of the next lecture?

1406
01:09:02,999 --> 01:09:03,660


1407
01:09:03,660 --> 01:09:04,790
The VC dimension.

1408
01:09:04,790 --> 01:09:09,460
You will be completely content with
everything you wanted to know about

1409
01:09:09,460 --> 01:09:12,410
the VC dimension, and weren't
afraid to ask!

1410
01:09:12,410 --> 01:09:15,890


1411
01:09:15,890 --> 01:09:17,140
OK?

1412
01:09:17,140 --> 01:09:19,290


1413
01:09:19,290 --> 01:09:21,450
MODERATOR: Yeah, the crowd is
saying that they're still

1414
01:09:21,450 --> 01:09:22,500
digesting the lecture.

1415
01:09:22,500 --> 01:09:23,609
PROFESSOR: OK.

1416
01:09:23,609 --> 01:09:27,300
As I mentioned before, if you didn't
follow this in real time, don't be

1417
01:09:27,300 --> 01:09:27,750
discouraged.

1418
01:09:27,750 --> 01:09:30,000
It's actually very sweet material.

1419
01:09:30,000 --> 01:09:31,830
And you can look at the lecture again.

1420
01:09:31,830 --> 01:09:33,210
And you can read the proof.

1421
01:09:33,210 --> 01:09:37,640
And you can do all of the homework,
until it settles in your mind.

1422
01:09:37,640 --> 01:09:40,410
This is the most abstract, or the
most theoretical, lecture

1423
01:09:40,410 --> 01:09:41,600
of the entire course.

1424
01:09:41,600 --> 01:09:44,200
And if you get through this one, and
you understand it well, you are in

1425
01:09:44,200 --> 01:09:45,740
good shape as far as the
rest of the course.

1426
01:09:45,740 --> 01:09:49,510
There will be mathematics, but it will
be more friendly mathematics.

1427
01:09:49,510 --> 01:09:50,910
Friendly, as in less abstract.

1428
01:09:50,910 --> 01:09:55,760
For someone who is not theoretically
inclined, the more abstract the

1429
01:09:55,760 --> 01:09:58,370
mathematics is, the less they
can follow it, because they

1430
01:09:58,370 --> 01:09:59,380
cannot relate to it.

1431
01:09:59,380 --> 01:10:01,110
So this one has the abstraction.

1432
01:10:01,110 --> 01:10:04,380
The other mathematics will be
much easier to relate to.

1433
01:10:04,380 --> 01:10:10,160
MODERATOR: What was wrong with the
"not quite" expression on the last slide?

1434
01:10:10,160 --> 01:10:10,170


1435
01:10:10,170 --> 01:10:11,420
PROFESSOR: OK.

1436
01:10:11,420 --> 01:10:15,380


1437
01:10:15,380 --> 01:10:19,800
Basically, the top statement
is simply false.

1438
01:10:19,800 --> 01:10:24,320
It was my way of relating
what I'm trying to do, to

1439
01:10:24,320 --> 01:10:25,370
what has already happened.

1440
01:10:25,370 --> 01:10:28,660
There used to be M in place
of the growth function.

1441
01:10:28,660 --> 01:10:32,170
So the growth function is here.

1442
01:10:32,170 --> 01:10:35,400
There used to be M. So the easiest
way for me to describe what is

1443
01:10:35,400 --> 01:10:37,770
happening with the theory, is to tell
you that you are going to take

1444
01:10:37,770 --> 01:10:40,000
M out, and replace it with this.

1445
01:10:40,000 --> 01:10:42,120
As usual, it's not that easy.

1446
01:10:42,120 --> 01:10:44,360
Even remember with the Hoeffding,
when I complained about the 2

1447
01:10:44,360 --> 01:10:45,840
here and the 2 here?

1448
01:10:45,840 --> 01:10:48,490
Well, you have to have them, in order
for the statement to be true.

1449
01:10:48,490 --> 01:10:51,870
So for the statement to be true, we
needed to do some technical stuff that

1450
01:10:51,870 --> 01:10:56,420
really didn't change the essence of
the statement here, but made it

1451
01:10:56,420 --> 01:10:58,660
a little bit different by changing
the constants.

1452
01:10:58,660 --> 01:11:00,980
And therefore, we have a proof
for it. It holds.

1453
01:11:00,980 --> 01:11:03,080
And it captures the essence of that.

1454
01:11:03,080 --> 01:11:06,180
I just didn't want to bother telling you
this because, if I told you this in

1455
01:11:06,180 --> 01:11:08,210
the first place, you would have
been completely lost.

1456
01:11:08,210 --> 01:11:08,830
Why 4?

1457
01:11:08,830 --> 01:11:09,240
Why 2?

1458
01:11:09,240 --> 01:11:10,620
What is this 1/8?

1459
01:11:10,620 --> 01:11:12,370
And forget about the essence.

1460
01:11:12,370 --> 01:11:14,370
So the easiest way to do it,
we are replacing it.

1461
01:11:14,370 --> 01:11:16,490
This is not the final form,
but we are replacing it.

1462
01:11:16,490 --> 01:11:19,010
Until you get the idea: indeed,
I can replace it.

1463
01:11:19,010 --> 01:11:21,770
But oh, in order to replace it,
I need to have a bigger sample

1464
01:11:21,770 --> 01:11:22,520
that we argued for.

1465
01:11:22,520 --> 01:11:23,660
So I need 2N.

1466
01:11:23,660 --> 01:11:27,570
Oh, and now the bigger samples are not
tracking to each other as well as each

1467
01:11:27,570 --> 01:11:30,900
of them is tracking the actual
out-of-sample error.

1468
01:11:30,900 --> 01:11:33,490
So I need to modify these
values, and so on.

1469
01:11:33,490 --> 01:11:35,400
So it becomes much easier to swallow.

1470
01:11:35,400 --> 01:11:39,230
The technicalities will come in, in order
to make the proof go through.

1471
01:11:39,230 --> 01:11:40,700
MODERATOR: OK.

1472
01:11:40,700 --> 01:11:43,804
Can you review the definition
of B of N and k?

1473
01:11:43,804 --> 01:11:48,070
PROFESSOR: B of N and k.

1474
01:11:48,070 --> 01:11:52,270
Assume you have N points, and assume
that k is a break point.

1475
01:11:52,270 --> 01:11:55,400
So you're assured that no
k points will have all

1476
01:11:55,400 --> 01:11:58,630
possible patterns on them.

1477
01:11:58,630 --> 01:12:01,490
After these two assumptions, make
no further assumptions.

1478
01:12:01,490 --> 01:12:03,010
You don't know where this came from.

1479
01:12:03,010 --> 01:12:04,560
You don't know what space
you are working with.

1480
01:12:04,560 --> 01:12:06,610
You don't know what the
hypothesis set is.

1481
01:12:06,610 --> 01:12:10,910
You just know that in your setup,
when you get N points--

1482
01:12:10,910 --> 01:12:11,830
that is the N here--

1483
01:12:11,830 --> 01:12:14,590
and the break point is
k-- that is k here.

1484
01:12:14,590 --> 01:12:18,420
Under those conditions, can you
bound the growth function?

1485
01:12:18,420 --> 01:12:20,320
Can you tell me that the growth
function can never

1486
01:12:20,320 --> 01:12:22,410
be bigger than something?

1487
01:12:22,410 --> 01:12:25,850
That something is what I am
calling B of N and k.

1488
01:12:25,850 --> 01:12:26,660
So what am I doing?

1489
01:12:26,660 --> 01:12:28,600
I'm taking the minimal conditions
you gave me.

1490
01:12:28,600 --> 01:12:30,540
I have N points, and k
is a break point.

1491
01:12:30,540 --> 01:12:34,820
And asking myself: what is the maximum
number of dichotomies you can possibly

1492
01:12:34,820 --> 01:12:38,580
have, under no other constraints,
in order to satisfy these two

1493
01:12:38,580 --> 01:12:39,390
constraints?

1494
01:12:39,390 --> 01:12:41,620
And I'm calling this B of N and k.

1495
01:12:41,620 --> 01:12:42,460
Why did I do it?

1496
01:12:42,460 --> 01:12:46,660
First, it's going to help, being an upper
bound for any hypothesis set

1497
01:12:46,660 --> 01:12:49,660
that has a break point k, because
it is the maximum.

1498
01:12:49,660 --> 01:12:53,140
The second one, it's a purely
combinatorial quantity.

1499
01:12:53,140 --> 01:12:56,920
So I have a much better chance of
analyzing it, without going through the

1500
01:12:56,920 --> 01:13:01,260
hairy details of input spaces, and
correlation between events, and so on.

1501
01:13:01,260 --> 01:13:03,770
And that is indeed, what ended
up being the case.

1502
01:13:03,770 --> 01:13:06,880
We had a very simple recursion on it,
and we found a formula for it.

1503
01:13:06,880 --> 01:13:09,820
And that formula now serves as
an upper bound for the more hairy

1504
01:13:09,820 --> 01:13:13,320
quantity, which is the growth function
that is very particular to a learning

1505
01:13:13,320 --> 01:13:16,310
situation, an input space,
and a hypothesis set.

1506
01:13:16,310 --> 01:13:20,010
MODERATOR: Also, a particular question
on the proof of B of N and k, the recursion.

1507
01:13:20,010 --> 01:13:20,020


1508
01:13:20,020 --> 01:13:21,270
Slide 5.

1509
01:13:21,270 --> 01:13:24,880


1510
01:13:24,880 --> 01:13:29,990
The question is, why does k not
change when going back from

1511
01:13:29,990 --> 01:13:32,750
N to N minus 1?

1512
01:13:32,750 --> 01:13:34,000
PROFESSOR: OK.

1513
01:13:34,000 --> 01:13:35,640


1514
01:13:35,640 --> 01:13:43,400
Here, if you look at x_1, x_2, up to
x_N, the disappearing x_N here, no k

1515
01:13:43,400 --> 01:13:46,290
columns can have all
possible patterns.

1516
01:13:46,290 --> 01:13:51,210
These k columns could involve the last
column, and could involve only the

1517
01:13:51,210 --> 01:13:52,960
first N minus 1 columns.

1518
01:13:52,960 --> 01:13:57,270
Just no k columns whatsoever can
have all possible patterns.

1519
01:13:57,270 --> 01:14:02,040
So when I look at the reduced one, N
minus 1, I know for a fact that no k

1520
01:14:02,040 --> 01:14:05,520
columns of these guys can have
all possible patterns.

1521
01:14:05,520 --> 01:14:09,170
Because that would qualify as
k columns of the bigger one.

1522
01:14:09,170 --> 01:14:11,930
So k doesn't really change.

1523
01:14:11,930 --> 01:14:17,010
The only time I had a different k
is when I had a nice argument

1524
01:14:17,010 --> 01:14:22,150
that, if you have k minus 1 points which
have all possible patterns on

1525
01:14:22,150 --> 01:14:25,500
the smaller set, then adding the
last column will get us in

1526
01:14:25,500 --> 01:14:28,270
trouble with k columns.

1527
01:14:28,270 --> 01:14:30,790
So for that, I needed an argument.

1528
01:14:30,790 --> 01:14:34,220
But in general, when I take the
statement on face value, k is fixed.

1529
01:14:34,220 --> 01:14:35,660
And the k columns could be anything.

1530
01:14:35,660 --> 01:14:39,180
Could be involving the last column, or
could be restricted to the first guy.

1531
01:14:39,180 --> 01:14:40,960
Could be the first k columns,
for all I care.

1532
01:14:40,960 --> 01:14:44,350


1533
01:14:44,350 --> 01:14:50,200
MODERATOR: How does this formalization
apply to, say, a regression problem?

1534
01:14:50,200 --> 01:14:50,210


1535
01:14:50,210 --> 01:14:52,390
PROFESSOR: Again, this
is all binary functions.

1536
01:14:52,390 --> 01:14:54,960
So the classification of
+1 and -1.

1537
01:14:54,960 --> 01:14:58,400
And as I mentioned, the entire analysis,
the VC analysis, can be

1538
01:14:58,400 --> 01:15:00,140
extended to real-valued functions.

1539
01:15:00,140 --> 01:15:04,560
It's a very technical extension that, in
my humble opinion, does not add to

1540
01:15:04,560 --> 01:15:05,620
the insight.

1541
01:15:05,620 --> 01:15:10,020
And therefore, instead of doing that and
going very technical, in order to

1542
01:15:10,020 --> 01:15:14,530
gain very little in terms of the
insight, I decided that when I get to

1543
01:15:14,530 --> 01:15:17,660
regression functions, I am going to
apply a completely different approach,

1544
01:15:17,660 --> 01:15:19,490
which is the bias-variance tradeoff.

1545
01:15:19,490 --> 01:15:22,800
It will give us another insight into
the situation, and will tackle

1546
01:15:22,800 --> 01:15:25,460
the real-valued functions directly,
the regression functions.

1547
01:15:25,460 --> 01:15:28,000
And therefore, I think we'll have both
the benefit of having another way of

1548
01:15:28,000 --> 01:15:32,170
looking at it, and covering
both types of functions.

1549
01:15:32,170 --> 01:15:36,060
MODERATOR: There's this person that
says, I feel silly asking this, but is

1550
01:15:36,060 --> 01:15:39,320
the bottom line that we can prove
learnability if the learning model

1551
01:15:39,320 --> 01:15:42,140
cannot learn everything?

1552
01:15:42,140 --> 01:15:44,410
PROFESSOR: OK.

1553
01:15:44,410 --> 01:15:49,120
We proved learnability under a condition
about the hypothesis set.

1554
01:15:49,120 --> 01:15:51,930
When you say learning everything,
you are really talking

1555
01:15:51,930 --> 01:15:54,250
about the target function.

1556
01:15:54,250 --> 01:15:56,080
So the target function is unknown.

1557
01:15:56,080 --> 01:15:59,540
What I am telling you here is that, if
you tell me that there is a break

1558
01:15:59,540 --> 01:16:04,460
point, I can tell you that if you have
enough examples, E_in will be close to

1559
01:16:04,460 --> 01:16:09,610
E_out for the hypothesis you pick,
whichever way you pick it.

1560
01:16:09,610 --> 01:16:14,550
It remains to be seen whether you are
going to be able to minimize E_in, to

1561
01:16:14,550 --> 01:16:16,080
a level that will make you happy.

1562
01:16:16,080 --> 01:16:18,740
I will never know that until
you start minimizing.

1563
01:16:18,740 --> 01:16:22,300
So if the target function happens to be
extremely difficult, or completely

1564
01:16:22,300 --> 01:16:25,000
random-- unlearnable, you are not
going to see this in the

1565
01:16:25,000 --> 01:16:26,380
generalization question.

1566
01:16:26,380 --> 01:16:29,520
The generalization question is
independent of the target function.

1567
01:16:29,520 --> 01:16:31,060
I didn't bring it up here at all.

1568
01:16:31,060 --> 01:16:34,240
It has to do with the
hypothesis set only.

1569
01:16:34,240 --> 01:16:38,590
The target function will come in--
if I get E_in to be small, E_out

1570
01:16:38,590 --> 01:16:39,090
will be small.

1571
01:16:39,090 --> 01:16:41,650
I know that from the generalization
argument that I made.

1572
01:16:41,650 --> 01:16:43,460
Can I get E_in to be small?

1573
01:16:43,460 --> 01:16:46,620
If the target function is random, you
will get a sample that that is

1574
01:16:46,620 --> 01:16:48,480
extremely difficult to fit.

1575
01:16:48,480 --> 01:16:51,320
And you are not going to be able
to get E_in to be small.

1576
01:16:51,320 --> 01:16:55,470
But at least, you will realize that
you could not learn, in

1577
01:16:55,470 --> 01:16:56,550
that particular case.

1578
01:16:56,550 --> 01:16:59,310
And in another target function, you will
realize that you can learn, because

1579
01:16:59,310 --> 01:17:01,000
E_in went down.

1580
01:17:01,000 --> 01:17:06,100
So the question of whether I can learn
or not, the generalization part of it

1581
01:17:06,100 --> 01:17:08,770
is independent of the target function.

1582
01:17:08,770 --> 01:17:12,470
The second question is very much
dependent on the target function, but

1583
01:17:12,470 --> 01:17:14,250
the good news is that it
happens in sample.

1584
01:17:14,250 --> 01:17:18,220
I can observe it, and realize how
well, or not so well, I learned.

1585
01:17:18,220 --> 01:17:21,000


1586
01:17:21,000 --> 01:17:25,950
MODERATOR: Also, going back to a previous
question, does this also generalize

1587
01:17:25,950 --> 01:17:27,200
to multi-class problems?

1588
01:17:27,200 --> 01:17:29,620


1589
01:17:29,620 --> 01:17:31,540
PROFESSOR: Basically, there
is no restriction on the

1590
01:17:31,540 --> 01:17:32,680
inputs or the outputs.

1591
01:17:32,680 --> 01:17:34,050
There is a counterpart.

1592
01:17:34,050 --> 01:17:36,560
And instead of saying break point,
what is a break point?

1593
01:17:36,560 --> 01:17:37,980
And dichotomies, they are
not really dichotomies.

1594
01:17:37,980 --> 01:17:38,980
You have real values.

1595
01:17:38,980 --> 01:17:41,710
You have no real values, so
there are technicalities to be done in

1596
01:17:41,710 --> 01:17:43,660
order to be able to reduce
them to this case.

1597
01:17:43,660 --> 01:17:46,850
But the same principle applies,
regardless of the type of

1598
01:17:46,850 --> 01:17:49,120
function you have.

1599
01:17:49,120 --> 01:17:50,090
MODERATOR: I think that's it.

1600
01:17:50,090 --> 01:17:50,520
PROFESSOR: Very good.

1601
01:17:50,520 --> 01:17:52,350
Thank you, and we'll
see you next week.

1602
01:17:52,350 --> 01:18:11,358

